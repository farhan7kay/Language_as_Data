{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bQpbxsW-CAYF"
   },
   "source": [
    "Course: Language as Data, University of Göttingen\n",
    "\n",
    "# Week 6: N-Gram Language Models\n",
    "\n",
    "In this lab, we learn how to build an n-gram based language model using the book [Emma](https://www.gutenberg.org/cache/epub/158/pg158.txt) as training data. The book was written by Jane Austen in the early 19th century and is made available by the Gutenberg project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0m4sCbcrB6hJ",
    "outputId": "f16b9237-a85c-4a57-ee52-e08b22393e9d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /home/jopi-lima/anaconda3/envs/lang3_9/lib/python3.9/site-packages (24.2)\n",
      "Collecting pip\n",
      "  Using cached pip-24.3.1-py3-none-any.whl.metadata (3.7 kB)\n",
      "Using cached pip-24.3.1-py3-none-any.whl (1.8 MB)\n",
      "Installing collected packages: pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 24.2\n",
      "    Uninstalling pip-24.2:\n",
      "      Successfully uninstalled pip-24.2\n",
      "Successfully installed pip-24.3.1\n",
      "Collecting nltk==3.4\n",
      "  Using cached nltk-3.4.zip (1.4 MB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: six in /home/jopi-lima/anaconda3/envs/lang3_9/lib/python3.9/site-packages (from nltk==3.4) (1.16.0)\n",
      "Collecting singledispatch (from nltk==3.4)\n",
      "  Using cached singledispatch-4.1.0-py2.py3-none-any.whl.metadata (3.8 kB)\n",
      "Using cached singledispatch-4.1.0-py2.py3-none-any.whl (6.7 kB)\n",
      "Building wheels for collected packages: nltk\n",
      "  Building wheel for nltk (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for nltk: filename=nltk-3.4-py3-none-any.whl size=1436383 sha256=87062b1c6e3eef71fb3a437cae4032ba1ea032bfb5e46088b1ab9790e3162b14\n",
      "  Stored in directory: /home/jopi-lima/.cache/pip/wheels/db/96/da/0a26fbd3f96b179cc14b813434a0c324a08c0684afdd524c73\n",
      "Successfully built nltk\n",
      "Installing collected packages: singledispatch, nltk\n",
      "Successfully installed nltk-3.4 singledispatch-4.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install -U pip\n",
    "!pip install -U nltk==3.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/jopi-lima/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "import io \n",
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "4LQOFfr96M7W",
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of characters: 879603\n",
      "\n",
      "VOLUME I\n",
      "\n",
      "CHAPTER I\n",
      "\n",
      "\n",
      "Emma Woodhouse, handsome, clever, and rich, with a comfortable home and\n",
      "happy disposition, seemed to unite some of the best blessings of\n",
      "existence; and had lived nearly twenty-one years in the world with very\n",
      "little to distress or vex her.\n",
      "\n",
      "She was the youngest of the two daughters of a most affectionate,\n",
      "indulgent father; and had, in consequence of her sister’s marriage,\n",
      "been mistress of his house from a very early period. Her mother had\n",
      "died too long ago for her to have \n"
     ]
    }
   ],
   "source": [
    "with open(\"jane_austen_emma.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    raw_text = f.read()\n",
    "    \n",
    "print(\"Total number of characters:\", len(raw_text))\n",
    "print(raw_text[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Pre-processing\n",
    "For your project, you will use the tokenizer you trained in the previous project. To keep the illustration simple, we use existing tokenizers here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['volume', 'i', 'chapter', 'i', 'emma', 'woodhouse', ',', 'handsome', ',', 'clever', ',', 'and', 'rich', ',', 'with', 'a', 'comfortable', 'home', 'and', 'happy', 'disposition', ',', 'seemed', 'to', 'unite', 'some', 'of', 'the', 'best', 'blessings', 'of', 'existence', ';', 'and', 'had', 'lived', 'nearly', 'twenty-one', 'years', 'in', 'the', 'world', 'with', 'very', 'little', 'to', 'distress', 'or', 'vex', 'her', '.'], ['she', 'was', 'the', 'youngest', 'of', 'the', 'two', 'daughters', 'of', 'a', 'most', 'affectionate', ',', 'indulgent', 'father', ';', 'and', 'had', ',', 'in', 'consequence', 'of', 'her', 'sister', '’', 's', 'marriage', ',', 'been', 'mistress', 'of', 'his', 'house', 'from', 'a', 'very', 'early', 'period', '.'], ['her', 'mother', 'had', 'died', 'too', 'long', 'ago', 'for', 'her', 'to', 'have', 'more', 'than', 'an', 'indistinct', 'remembrance', 'of', 'her', 'caresses', ';', 'and', 'her', 'place', 'had', 'been', 'supplied', 'by', 'an', 'excellent', 'woman', 'as', 'governess', ',', 'who', 'had', 'fallen', 'little', 'short', 'of', 'a', 'mother', 'in', 'affection', '.'], ['sixteen', 'years', 'had', 'miss', 'taylor', 'been', 'in', 'mr.', 'woodhouse', '’', 's', 'family', ',', 'less', 'as', 'a', 'governess', 'than', 'a', 'friend', ',', 'very', 'fond', 'of', 'both', 'daughters', ',', 'but', 'particularly', 'of', 'emma', '.'], ['between', '_them_', 'it', 'was', 'more', 'the', 'intimacy', 'of', 'sisters', '.']]\n"
     ]
    }
   ],
   "source": [
    "from nltk import word_tokenize, sent_tokenize \n",
    "tokenized_text = [list(map(str.lower, word_tokenize(sent))) \n",
    "                  for sent in sent_tokenize(raw_text)]\n",
    "print(tokenized_text[0:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zE-siRaQ7ALK"
   },
   "source": [
    "Then we preprocess the text. We use the *padded_everygram_pipeline* function from nltk. It pads the sentence and then makes so-called *everygrams*. Let's see what this looks like. **Make sure you understand what is meant by everygrams here. How does the padding change when you change n? How dow the n-grams change if you change n?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Lb8_v-Dq6sUt",
    "outputId": "897fc7bd-420f-456f-f3d4-9bd30bf4217a",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PADDING:\n",
      "['<s>', '<s>', 'volume', 'i', 'chapter', 'i', 'emma', 'woodhouse', ',', 'handsome', ',', 'clever', ',', 'and', 'rich', ',', 'with', 'a', 'comfortable', 'home', 'and', 'happy', 'disposition', ',', 'seemed', 'to', 'unite', 'some', 'of', 'the', 'best', 'blessings', 'of', 'existence', ';', 'and', 'had', 'lived', 'nearly', 'twenty-one', 'years', 'in', 'the', 'world', 'with', 'very', 'little', 'to', 'distress', 'or', 'vex', 'her', '.', '</s>', '</s>', '<s>', '<s>', 'she', 'was', 'the', 'youngest', 'of', 'the', 'two', 'daughters', 'of', 'a', 'most', 'affectionate', ',', 'indulgent', 'father', ';', 'and', 'had', ',', 'in', 'consequence', 'of', 'her', 'sister', '’', 's', 'marriage', ',', 'been', 'mistress', 'of', 'his', 'house', 'from', 'a', 'very', 'early', 'period', '.', '</s>', '</s>', '<s>', '<s>', 'her', 'mother', 'had', 'died', 'too', 'long', 'ago', 'for', 'her', 'to', 'have', 'more', 'than', 'an', 'indistinct', 'remembrance', 'of', 'her', 'caresses', ';', 'and', 'her', 'place', 'had', 'been', 'supplied', 'by', 'an', 'excellent', 'woman', 'as', 'governess', ',', 'who', 'had', 'fallen', 'little', 'short', 'of', 'a', 'mother', 'in', 'affection', '.', '</s>', '</s>', '<s>', '<s>', 'sixteen', 'years', 'had', 'miss', 'taylor', 'been', 'in', 'mr.', 'woodhouse', '’', 's', 'family', ',', 'less', 'as', 'a', 'governess', 'than', 'a', 'friend', ',', 'very', 'fond', 'of', 'both', 'daughters', ',', 'but', 'particularly', 'of', 'emma', '.', '</s>', '</s>', '<s>', '<s>', 'between', '_them_', 'it', 'was', 'more', 'the', 'intimacy', 'of', 'sisters', '.', '</s>', '</s>', '<s>', '<s>', 'even', 'before', 'miss', 'taylor', 'had', 'ceased', 'to', 'hold', 'the', 'nominal', 'office', 'of', 'governess', ',', 'the', 'mildness', 'of', 'her', 'temper', 'had', 'hardly', 'allowed', 'her', 'to', 'impose', 'any', 'restraint', ';', 'and', 'the', 'shadow', 'of', 'authority', 'being', 'now', 'long', 'passed', 'away', ',', 'they', 'had', 'been', 'living', 'together', 'as', 'friend', 'and', 'friend', 'very', 'mutually', 'attached', ',', 'and', 'emma', 'doing', 'just', 'what', 'she', 'liked', ';', 'highly', 'esteeming', 'miss', 'taylor', '’', 's', 'judgment', ',', 'but', 'directed', 'chiefly', 'by', 'her', 'own', '.', '</s>', '</s>', '<s>', '<s>', 'the', 'real', 'evils', ',', 'indeed', ',', 'of', 'emma', '’', 's', 'situation', 'were', 'the', 'power', 'of', 'having', 'rather', 'too', 'much', 'her', 'own', 'way', ',', 'and', 'a', 'disposition', 'to', 'think', 'a', 'little', 'too', 'well', 'of', 'herself', ';', 'these', 'were', 'the', 'disadvantages', 'which', 'threatened', 'alloy', 'to', 'her', 'many', 'enjoyments', '.', '</s>', '</s>', '<s>', '<s>', 'the', 'danger', ',', 'however', ',', 'was', 'at', 'present', 'so', 'unperceived', ',', 'that', 'they', 'did', 'not', 'by', 'any', 'means', 'rank', 'as', 'misfortunes', 'with', 'her', '.', '</s>', '</s>', '<s>', '<s>', 'sorrow', 'came—a', 'gentle', 'sorrow—but', 'not', 'at', 'all', 'in', 'the', 'shape', 'of', 'any', 'disagreeable', 'consciousness.—miss', 'taylor', 'married', '.', '</s>', '</s>', '<s>', '<s>', 'it', 'was', 'miss', 'taylor', '’', 's', 'loss', 'which', 'first', 'brought', 'grief', '.', '</s>', '</s>']\n",
      "\n",
      "\n",
      "NGRAMS:\n",
      "[('<s>',), ('<s>',), ('volume',), ('i',), ('chapter',), ('i',), ('emma',), ('woodhouse',), (',',), ('handsome',), (',',), ('clever',), (',',), ('and',), ('rich',), (',',), ('with',), ('a',), ('comfortable',), ('home',), ('and',), ('happy',), ('disposition',), (',',), ('seemed',), ('to',), ('unite',), ('some',), ('of',), ('the',), ('best',), ('blessings',), ('of',), ('existence',), (';',), ('and',), ('had',), ('lived',), ('nearly',), ('twenty-one',), ('years',), ('in',), ('the',), ('world',), ('with',), ('very',), ('little',), ('to',), ('distress',), ('or',), ('vex',), ('her',), ('.',), ('</s>',), ('</s>',), ('<s>', '<s>'), ('<s>', 'volume'), ('volume', 'i'), ('i', 'chapter'), ('chapter', 'i'), ('i', 'emma'), ('emma', 'woodhouse'), ('woodhouse', ','), (',', 'handsome'), ('handsome', ','), (',', 'clever'), ('clever', ','), (',', 'and'), ('and', 'rich'), ('rich', ','), (',', 'with'), ('with', 'a'), ('a', 'comfortable'), ('comfortable', 'home'), ('home', 'and'), ('and', 'happy'), ('happy', 'disposition'), ('disposition', ','), (',', 'seemed'), ('seemed', 'to'), ('to', 'unite'), ('unite', 'some'), ('some', 'of'), ('of', 'the'), ('the', 'best'), ('best', 'blessings'), ('blessings', 'of'), ('of', 'existence'), ('existence', ';'), (';', 'and'), ('and', 'had'), ('had', 'lived'), ('lived', 'nearly'), ('nearly', 'twenty-one'), ('twenty-one', 'years'), ('years', 'in'), ('in', 'the'), ('the', 'world'), ('world', 'with'), ('with', 'very'), ('very', 'little'), ('little', 'to'), ('to', 'distress'), ('distress', 'or'), ('or', 'vex'), ('vex', 'her'), ('her', '.'), ('.', '</s>'), ('</s>', '</s>'), ('<s>', '<s>', 'volume'), ('<s>', 'volume', 'i'), ('volume', 'i', 'chapter'), ('i', 'chapter', 'i'), ('chapter', 'i', 'emma'), ('i', 'emma', 'woodhouse'), ('emma', 'woodhouse', ','), ('woodhouse', ',', 'handsome'), (',', 'handsome', ','), ('handsome', ',', 'clever'), (',', 'clever', ','), ('clever', ',', 'and'), (',', 'and', 'rich'), ('and', 'rich', ','), ('rich', ',', 'with'), (',', 'with', 'a'), ('with', 'a', 'comfortable'), ('a', 'comfortable', 'home'), ('comfortable', 'home', 'and'), ('home', 'and', 'happy'), ('and', 'happy', 'disposition'), ('happy', 'disposition', ','), ('disposition', ',', 'seemed'), (',', 'seemed', 'to'), ('seemed', 'to', 'unite'), ('to', 'unite', 'some'), ('unite', 'some', 'of'), ('some', 'of', 'the'), ('of', 'the', 'best'), ('the', 'best', 'blessings'), ('best', 'blessings', 'of'), ('blessings', 'of', 'existence'), ('of', 'existence', ';'), ('existence', ';', 'and'), (';', 'and', 'had'), ('and', 'had', 'lived'), ('had', 'lived', 'nearly'), ('lived', 'nearly', 'twenty-one'), ('nearly', 'twenty-one', 'years'), ('twenty-one', 'years', 'in'), ('years', 'in', 'the'), ('in', 'the', 'world'), ('the', 'world', 'with'), ('world', 'with', 'very'), ('with', 'very', 'little'), ('very', 'little', 'to'), ('little', 'to', 'distress'), ('to', 'distress', 'or'), ('distress', 'or', 'vex'), ('or', 'vex', 'her'), ('vex', 'her', '.'), ('her', '.', '</s>'), ('.', '</s>', '</s>')]\n",
      "\n",
      "[('<s>',), ('<s>',), ('she',), ('was',), ('the',), ('youngest',), ('of',), ('the',), ('two',), ('daughters',), ('of',), ('a',), ('most',), ('affectionate',), (',',), ('indulgent',), ('father',), (';',), ('and',), ('had',), (',',), ('in',), ('consequence',), ('of',), ('her',), ('sister',), ('’',), ('s',), ('marriage',), (',',), ('been',), ('mistress',), ('of',), ('his',), ('house',), ('from',), ('a',), ('very',), ('early',), ('period',), ('.',), ('</s>',), ('</s>',), ('<s>', '<s>'), ('<s>', 'she'), ('she', 'was'), ('was', 'the'), ('the', 'youngest'), ('youngest', 'of'), ('of', 'the'), ('the', 'two'), ('two', 'daughters'), ('daughters', 'of'), ('of', 'a'), ('a', 'most'), ('most', 'affectionate'), ('affectionate', ','), (',', 'indulgent'), ('indulgent', 'father'), ('father', ';'), (';', 'and'), ('and', 'had'), ('had', ','), (',', 'in'), ('in', 'consequence'), ('consequence', 'of'), ('of', 'her'), ('her', 'sister'), ('sister', '’'), ('’', 's'), ('s', 'marriage'), ('marriage', ','), (',', 'been'), ('been', 'mistress'), ('mistress', 'of'), ('of', 'his'), ('his', 'house'), ('house', 'from'), ('from', 'a'), ('a', 'very'), ('very', 'early'), ('early', 'period'), ('period', '.'), ('.', '</s>'), ('</s>', '</s>'), ('<s>', '<s>', 'she'), ('<s>', 'she', 'was'), ('she', 'was', 'the'), ('was', 'the', 'youngest'), ('the', 'youngest', 'of'), ('youngest', 'of', 'the'), ('of', 'the', 'two'), ('the', 'two', 'daughters'), ('two', 'daughters', 'of'), ('daughters', 'of', 'a'), ('of', 'a', 'most'), ('a', 'most', 'affectionate'), ('most', 'affectionate', ','), ('affectionate', ',', 'indulgent'), (',', 'indulgent', 'father'), ('indulgent', 'father', ';'), ('father', ';', 'and'), (';', 'and', 'had'), ('and', 'had', ','), ('had', ',', 'in'), (',', 'in', 'consequence'), ('in', 'consequence', 'of'), ('consequence', 'of', 'her'), ('of', 'her', 'sister'), ('her', 'sister', '’'), ('sister', '’', 's'), ('’', 's', 'marriage'), ('s', 'marriage', ','), ('marriage', ',', 'been'), (',', 'been', 'mistress'), ('been', 'mistress', 'of'), ('mistress', 'of', 'his'), ('of', 'his', 'house'), ('his', 'house', 'from'), ('house', 'from', 'a'), ('from', 'a', 'very'), ('a', 'very', 'early'), ('very', 'early', 'period'), ('early', 'period', '.'), ('period', '.', '</s>'), ('.', '</s>', '</s>')]\n",
      "\n",
      "[('<s>',), ('<s>',), ('her',), ('mother',), ('had',), ('died',), ('too',), ('long',), ('ago',), ('for',), ('her',), ('to',), ('have',), ('more',), ('than',), ('an',), ('indistinct',), ('remembrance',), ('of',), ('her',), ('caresses',), (';',), ('and',), ('her',), ('place',), ('had',), ('been',), ('supplied',), ('by',), ('an',), ('excellent',), ('woman',), ('as',), ('governess',), (',',), ('who',), ('had',), ('fallen',), ('little',), ('short',), ('of',), ('a',), ('mother',), ('in',), ('affection',), ('.',), ('</s>',), ('</s>',), ('<s>', '<s>'), ('<s>', 'her'), ('her', 'mother'), ('mother', 'had'), ('had', 'died'), ('died', 'too'), ('too', 'long'), ('long', 'ago'), ('ago', 'for'), ('for', 'her'), ('her', 'to'), ('to', 'have'), ('have', 'more'), ('more', 'than'), ('than', 'an'), ('an', 'indistinct'), ('indistinct', 'remembrance'), ('remembrance', 'of'), ('of', 'her'), ('her', 'caresses'), ('caresses', ';'), (';', 'and'), ('and', 'her'), ('her', 'place'), ('place', 'had'), ('had', 'been'), ('been', 'supplied'), ('supplied', 'by'), ('by', 'an'), ('an', 'excellent'), ('excellent', 'woman'), ('woman', 'as'), ('as', 'governess'), ('governess', ','), (',', 'who'), ('who', 'had'), ('had', 'fallen'), ('fallen', 'little'), ('little', 'short'), ('short', 'of'), ('of', 'a'), ('a', 'mother'), ('mother', 'in'), ('in', 'affection'), ('affection', '.'), ('.', '</s>'), ('</s>', '</s>'), ('<s>', '<s>', 'her'), ('<s>', 'her', 'mother'), ('her', 'mother', 'had'), ('mother', 'had', 'died'), ('had', 'died', 'too'), ('died', 'too', 'long'), ('too', 'long', 'ago'), ('long', 'ago', 'for'), ('ago', 'for', 'her'), ('for', 'her', 'to'), ('her', 'to', 'have'), ('to', 'have', 'more'), ('have', 'more', 'than'), ('more', 'than', 'an'), ('than', 'an', 'indistinct'), ('an', 'indistinct', 'remembrance'), ('indistinct', 'remembrance', 'of'), ('remembrance', 'of', 'her'), ('of', 'her', 'caresses'), ('her', 'caresses', ';'), ('caresses', ';', 'and'), (';', 'and', 'her'), ('and', 'her', 'place'), ('her', 'place', 'had'), ('place', 'had', 'been'), ('had', 'been', 'supplied'), ('been', 'supplied', 'by'), ('supplied', 'by', 'an'), ('by', 'an', 'excellent'), ('an', 'excellent', 'woman'), ('excellent', 'woman', 'as'), ('woman', 'as', 'governess'), ('as', 'governess', ','), ('governess', ',', 'who'), (',', 'who', 'had'), ('who', 'had', 'fallen'), ('had', 'fallen', 'little'), ('fallen', 'little', 'short'), ('little', 'short', 'of'), ('short', 'of', 'a'), ('of', 'a', 'mother'), ('a', 'mother', 'in'), ('mother', 'in', 'affection'), ('in', 'affection', '.'), ('affection', '.', '</s>'), ('.', '</s>', '</s>')]\n",
      "\n",
      "[('<s>',), ('<s>',), ('sixteen',), ('years',), ('had',), ('miss',), ('taylor',), ('been',), ('in',), ('mr.',), ('woodhouse',), ('’',), ('s',), ('family',), (',',), ('less',), ('as',), ('a',), ('governess',), ('than',), ('a',), ('friend',), (',',), ('very',), ('fond',), ('of',), ('both',), ('daughters',), (',',), ('but',), ('particularly',), ('of',), ('emma',), ('.',), ('</s>',), ('</s>',), ('<s>', '<s>'), ('<s>', 'sixteen'), ('sixteen', 'years'), ('years', 'had'), ('had', 'miss'), ('miss', 'taylor'), ('taylor', 'been'), ('been', 'in'), ('in', 'mr.'), ('mr.', 'woodhouse'), ('woodhouse', '’'), ('’', 's'), ('s', 'family'), ('family', ','), (',', 'less'), ('less', 'as'), ('as', 'a'), ('a', 'governess'), ('governess', 'than'), ('than', 'a'), ('a', 'friend'), ('friend', ','), (',', 'very'), ('very', 'fond'), ('fond', 'of'), ('of', 'both'), ('both', 'daughters'), ('daughters', ','), (',', 'but'), ('but', 'particularly'), ('particularly', 'of'), ('of', 'emma'), ('emma', '.'), ('.', '</s>'), ('</s>', '</s>'), ('<s>', '<s>', 'sixteen'), ('<s>', 'sixteen', 'years'), ('sixteen', 'years', 'had'), ('years', 'had', 'miss'), ('had', 'miss', 'taylor'), ('miss', 'taylor', 'been'), ('taylor', 'been', 'in'), ('been', 'in', 'mr.'), ('in', 'mr.', 'woodhouse'), ('mr.', 'woodhouse', '’'), ('woodhouse', '’', 's'), ('’', 's', 'family'), ('s', 'family', ','), ('family', ',', 'less'), (',', 'less', 'as'), ('less', 'as', 'a'), ('as', 'a', 'governess'), ('a', 'governess', 'than'), ('governess', 'than', 'a'), ('than', 'a', 'friend'), ('a', 'friend', ','), ('friend', ',', 'very'), (',', 'very', 'fond'), ('very', 'fond', 'of'), ('fond', 'of', 'both'), ('of', 'both', 'daughters'), ('both', 'daughters', ','), ('daughters', ',', 'but'), (',', 'but', 'particularly'), ('but', 'particularly', 'of'), ('particularly', 'of', 'emma'), ('of', 'emma', '.'), ('emma', '.', '</s>'), ('.', '</s>', '</s>')]\n",
      "\n",
      "[('<s>',), ('<s>',), ('between',), ('_them_',), ('it',), ('was',), ('more',), ('the',), ('intimacy',), ('of',), ('sisters',), ('.',), ('</s>',), ('</s>',), ('<s>', '<s>'), ('<s>', 'between'), ('between', '_them_'), ('_them_', 'it'), ('it', 'was'), ('was', 'more'), ('more', 'the'), ('the', 'intimacy'), ('intimacy', 'of'), ('of', 'sisters'), ('sisters', '.'), ('.', '</s>'), ('</s>', '</s>'), ('<s>', '<s>', 'between'), ('<s>', 'between', '_them_'), ('between', '_them_', 'it'), ('_them_', 'it', 'was'), ('it', 'was', 'more'), ('was', 'more', 'the'), ('more', 'the', 'intimacy'), ('the', 'intimacy', 'of'), ('intimacy', 'of', 'sisters'), ('of', 'sisters', '.'), ('sisters', '.', '</s>'), ('.', '</s>', '</s>')]\n",
      "\n",
      "[('<s>',), ('<s>',), ('even',), ('before',), ('miss',), ('taylor',), ('had',), ('ceased',), ('to',), ('hold',), ('the',), ('nominal',), ('office',), ('of',), ('governess',), (',',), ('the',), ('mildness',), ('of',), ('her',), ('temper',), ('had',), ('hardly',), ('allowed',), ('her',), ('to',), ('impose',), ('any',), ('restraint',), (';',), ('and',), ('the',), ('shadow',), ('of',), ('authority',), ('being',), ('now',), ('long',), ('passed',), ('away',), (',',), ('they',), ('had',), ('been',), ('living',), ('together',), ('as',), ('friend',), ('and',), ('friend',), ('very',), ('mutually',), ('attached',), (',',), ('and',), ('emma',), ('doing',), ('just',), ('what',), ('she',), ('liked',), (';',), ('highly',), ('esteeming',), ('miss',), ('taylor',), ('’',), ('s',), ('judgment',), (',',), ('but',), ('directed',), ('chiefly',), ('by',), ('her',), ('own',), ('.',), ('</s>',), ('</s>',), ('<s>', '<s>'), ('<s>', 'even'), ('even', 'before'), ('before', 'miss'), ('miss', 'taylor'), ('taylor', 'had'), ('had', 'ceased'), ('ceased', 'to'), ('to', 'hold'), ('hold', 'the'), ('the', 'nominal'), ('nominal', 'office'), ('office', 'of'), ('of', 'governess'), ('governess', ','), (',', 'the'), ('the', 'mildness'), ('mildness', 'of'), ('of', 'her'), ('her', 'temper'), ('temper', 'had'), ('had', 'hardly'), ('hardly', 'allowed'), ('allowed', 'her'), ('her', 'to'), ('to', 'impose'), ('impose', 'any'), ('any', 'restraint'), ('restraint', ';'), (';', 'and'), ('and', 'the'), ('the', 'shadow'), ('shadow', 'of'), ('of', 'authority'), ('authority', 'being'), ('being', 'now'), ('now', 'long'), ('long', 'passed'), ('passed', 'away'), ('away', ','), (',', 'they'), ('they', 'had'), ('had', 'been'), ('been', 'living'), ('living', 'together'), ('together', 'as'), ('as', 'friend'), ('friend', 'and'), ('and', 'friend'), ('friend', 'very'), ('very', 'mutually'), ('mutually', 'attached'), ('attached', ','), (',', 'and'), ('and', 'emma'), ('emma', 'doing'), ('doing', 'just'), ('just', 'what'), ('what', 'she'), ('she', 'liked'), ('liked', ';'), (';', 'highly'), ('highly', 'esteeming'), ('esteeming', 'miss'), ('miss', 'taylor'), ('taylor', '’'), ('’', 's'), ('s', 'judgment'), ('judgment', ','), (',', 'but'), ('but', 'directed'), ('directed', 'chiefly'), ('chiefly', 'by'), ('by', 'her'), ('her', 'own'), ('own', '.'), ('.', '</s>'), ('</s>', '</s>'), ('<s>', '<s>', 'even'), ('<s>', 'even', 'before'), ('even', 'before', 'miss'), ('before', 'miss', 'taylor'), ('miss', 'taylor', 'had'), ('taylor', 'had', 'ceased'), ('had', 'ceased', 'to'), ('ceased', 'to', 'hold'), ('to', 'hold', 'the'), ('hold', 'the', 'nominal'), ('the', 'nominal', 'office'), ('nominal', 'office', 'of'), ('office', 'of', 'governess'), ('of', 'governess', ','), ('governess', ',', 'the'), (',', 'the', 'mildness'), ('the', 'mildness', 'of'), ('mildness', 'of', 'her'), ('of', 'her', 'temper'), ('her', 'temper', 'had'), ('temper', 'had', 'hardly'), ('had', 'hardly', 'allowed'), ('hardly', 'allowed', 'her'), ('allowed', 'her', 'to'), ('her', 'to', 'impose'), ('to', 'impose', 'any'), ('impose', 'any', 'restraint'), ('any', 'restraint', ';'), ('restraint', ';', 'and'), (';', 'and', 'the'), ('and', 'the', 'shadow'), ('the', 'shadow', 'of'), ('shadow', 'of', 'authority'), ('of', 'authority', 'being'), ('authority', 'being', 'now'), ('being', 'now', 'long'), ('now', 'long', 'passed'), ('long', 'passed', 'away'), ('passed', 'away', ','), ('away', ',', 'they'), (',', 'they', 'had'), ('they', 'had', 'been'), ('had', 'been', 'living'), ('been', 'living', 'together'), ('living', 'together', 'as'), ('together', 'as', 'friend'), ('as', 'friend', 'and'), ('friend', 'and', 'friend'), ('and', 'friend', 'very'), ('friend', 'very', 'mutually'), ('very', 'mutually', 'attached'), ('mutually', 'attached', ','), ('attached', ',', 'and'), (',', 'and', 'emma'), ('and', 'emma', 'doing'), ('emma', 'doing', 'just'), ('doing', 'just', 'what'), ('just', 'what', 'she'), ('what', 'she', 'liked'), ('she', 'liked', ';'), ('liked', ';', 'highly'), (';', 'highly', 'esteeming'), ('highly', 'esteeming', 'miss'), ('esteeming', 'miss', 'taylor'), ('miss', 'taylor', '’'), ('taylor', '’', 's'), ('’', 's', 'judgment'), ('s', 'judgment', ','), ('judgment', ',', 'but'), (',', 'but', 'directed'), ('but', 'directed', 'chiefly'), ('directed', 'chiefly', 'by'), ('chiefly', 'by', 'her'), ('by', 'her', 'own'), ('her', 'own', '.'), ('own', '.', '</s>'), ('.', '</s>', '</s>')]\n",
      "\n",
      "[('<s>',), ('<s>',), ('the',), ('real',), ('evils',), (',',), ('indeed',), (',',), ('of',), ('emma',), ('’',), ('s',), ('situation',), ('were',), ('the',), ('power',), ('of',), ('having',), ('rather',), ('too',), ('much',), ('her',), ('own',), ('way',), (',',), ('and',), ('a',), ('disposition',), ('to',), ('think',), ('a',), ('little',), ('too',), ('well',), ('of',), ('herself',), (';',), ('these',), ('were',), ('the',), ('disadvantages',), ('which',), ('threatened',), ('alloy',), ('to',), ('her',), ('many',), ('enjoyments',), ('.',), ('</s>',), ('</s>',), ('<s>', '<s>'), ('<s>', 'the'), ('the', 'real'), ('real', 'evils'), ('evils', ','), (',', 'indeed'), ('indeed', ','), (',', 'of'), ('of', 'emma'), ('emma', '’'), ('’', 's'), ('s', 'situation'), ('situation', 'were'), ('were', 'the'), ('the', 'power'), ('power', 'of'), ('of', 'having'), ('having', 'rather'), ('rather', 'too'), ('too', 'much'), ('much', 'her'), ('her', 'own'), ('own', 'way'), ('way', ','), (',', 'and'), ('and', 'a'), ('a', 'disposition'), ('disposition', 'to'), ('to', 'think'), ('think', 'a'), ('a', 'little'), ('little', 'too'), ('too', 'well'), ('well', 'of'), ('of', 'herself'), ('herself', ';'), (';', 'these'), ('these', 'were'), ('were', 'the'), ('the', 'disadvantages'), ('disadvantages', 'which'), ('which', 'threatened'), ('threatened', 'alloy'), ('alloy', 'to'), ('to', 'her'), ('her', 'many'), ('many', 'enjoyments'), ('enjoyments', '.'), ('.', '</s>'), ('</s>', '</s>'), ('<s>', '<s>', 'the'), ('<s>', 'the', 'real'), ('the', 'real', 'evils'), ('real', 'evils', ','), ('evils', ',', 'indeed'), (',', 'indeed', ','), ('indeed', ',', 'of'), (',', 'of', 'emma'), ('of', 'emma', '’'), ('emma', '’', 's'), ('’', 's', 'situation'), ('s', 'situation', 'were'), ('situation', 'were', 'the'), ('were', 'the', 'power'), ('the', 'power', 'of'), ('power', 'of', 'having'), ('of', 'having', 'rather'), ('having', 'rather', 'too'), ('rather', 'too', 'much'), ('too', 'much', 'her'), ('much', 'her', 'own'), ('her', 'own', 'way'), ('own', 'way', ','), ('way', ',', 'and'), (',', 'and', 'a'), ('and', 'a', 'disposition'), ('a', 'disposition', 'to'), ('disposition', 'to', 'think'), ('to', 'think', 'a'), ('think', 'a', 'little'), ('a', 'little', 'too'), ('little', 'too', 'well'), ('too', 'well', 'of'), ('well', 'of', 'herself'), ('of', 'herself', ';'), ('herself', ';', 'these'), (';', 'these', 'were'), ('these', 'were', 'the'), ('were', 'the', 'disadvantages'), ('the', 'disadvantages', 'which'), ('disadvantages', 'which', 'threatened'), ('which', 'threatened', 'alloy'), ('threatened', 'alloy', 'to'), ('alloy', 'to', 'her'), ('to', 'her', 'many'), ('her', 'many', 'enjoyments'), ('many', 'enjoyments', '.'), ('enjoyments', '.', '</s>'), ('.', '</s>', '</s>')]\n",
      "\n",
      "[('<s>',), ('<s>',), ('the',), ('danger',), (',',), ('however',), (',',), ('was',), ('at',), ('present',), ('so',), ('unperceived',), (',',), ('that',), ('they',), ('did',), ('not',), ('by',), ('any',), ('means',), ('rank',), ('as',), ('misfortunes',), ('with',), ('her',), ('.',), ('</s>',), ('</s>',), ('<s>', '<s>'), ('<s>', 'the'), ('the', 'danger'), ('danger', ','), (',', 'however'), ('however', ','), (',', 'was'), ('was', 'at'), ('at', 'present'), ('present', 'so'), ('so', 'unperceived'), ('unperceived', ','), (',', 'that'), ('that', 'they'), ('they', 'did'), ('did', 'not'), ('not', 'by'), ('by', 'any'), ('any', 'means'), ('means', 'rank'), ('rank', 'as'), ('as', 'misfortunes'), ('misfortunes', 'with'), ('with', 'her'), ('her', '.'), ('.', '</s>'), ('</s>', '</s>'), ('<s>', '<s>', 'the'), ('<s>', 'the', 'danger'), ('the', 'danger', ','), ('danger', ',', 'however'), (',', 'however', ','), ('however', ',', 'was'), (',', 'was', 'at'), ('was', 'at', 'present'), ('at', 'present', 'so'), ('present', 'so', 'unperceived'), ('so', 'unperceived', ','), ('unperceived', ',', 'that'), (',', 'that', 'they'), ('that', 'they', 'did'), ('they', 'did', 'not'), ('did', 'not', 'by'), ('not', 'by', 'any'), ('by', 'any', 'means'), ('any', 'means', 'rank'), ('means', 'rank', 'as'), ('rank', 'as', 'misfortunes'), ('as', 'misfortunes', 'with'), ('misfortunes', 'with', 'her'), ('with', 'her', '.'), ('her', '.', '</s>'), ('.', '</s>', '</s>')]\n",
      "\n",
      "[('<s>',), ('<s>',), ('sorrow',), ('came—a',), ('gentle',), ('sorrow—but',), ('not',), ('at',), ('all',), ('in',), ('the',), ('shape',), ('of',), ('any',), ('disagreeable',), ('consciousness.—miss',), ('taylor',), ('married',), ('.',), ('</s>',), ('</s>',), ('<s>', '<s>'), ('<s>', 'sorrow'), ('sorrow', 'came—a'), ('came—a', 'gentle'), ('gentle', 'sorrow—but'), ('sorrow—but', 'not'), ('not', 'at'), ('at', 'all'), ('all', 'in'), ('in', 'the'), ('the', 'shape'), ('shape', 'of'), ('of', 'any'), ('any', 'disagreeable'), ('disagreeable', 'consciousness.—miss'), ('consciousness.—miss', 'taylor'), ('taylor', 'married'), ('married', '.'), ('.', '</s>'), ('</s>', '</s>'), ('<s>', '<s>', 'sorrow'), ('<s>', 'sorrow', 'came—a'), ('sorrow', 'came—a', 'gentle'), ('came—a', 'gentle', 'sorrow—but'), ('gentle', 'sorrow—but', 'not'), ('sorrow—but', 'not', 'at'), ('not', 'at', 'all'), ('at', 'all', 'in'), ('all', 'in', 'the'), ('in', 'the', 'shape'), ('the', 'shape', 'of'), ('shape', 'of', 'any'), ('of', 'any', 'disagreeable'), ('any', 'disagreeable', 'consciousness.—miss'), ('disagreeable', 'consciousness.—miss', 'taylor'), ('consciousness.—miss', 'taylor', 'married'), ('taylor', 'married', '.'), ('married', '.', '</s>'), ('.', '</s>', '</s>')]\n",
      "\n",
      "[('<s>',), ('<s>',), ('it',), ('was',), ('miss',), ('taylor',), ('’',), ('s',), ('loss',), ('which',), ('first',), ('brought',), ('grief',), ('.',), ('</s>',), ('</s>',), ('<s>', '<s>'), ('<s>', 'it'), ('it', 'was'), ('was', 'miss'), ('miss', 'taylor'), ('taylor', '’'), ('’', 's'), ('s', 'loss'), ('loss', 'which'), ('which', 'first'), ('first', 'brought'), ('brought', 'grief'), ('grief', '.'), ('.', '</s>'), ('</s>', '</s>'), ('<s>', '<s>', 'it'), ('<s>', 'it', 'was'), ('it', 'was', 'miss'), ('was', 'miss', 'taylor'), ('miss', 'taylor', '’'), ('taylor', '’', 's'), ('’', 's', 'loss'), ('s', 'loss', 'which'), ('loss', 'which', 'first'), ('which', 'first', 'brought'), ('first', 'brought', 'grief'), ('brought', 'grief', '.'), ('grief', '.', '</s>'), ('.', '</s>', '</s>')]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from nltk.lm.preprocessing import padded_everygram_pipeline\n",
    "# Set the n-gram size\n",
    "n = 3\n",
    "\n",
    "# Check pre-processing on a subset: \n",
    "ngram_data, padded = padded_everygram_pipeline(n, tokenized_text[0:10])\n",
    "\n",
    "# What is the effect of padding? \n",
    "print(\"PADDING:\")\n",
    "print(list(padded))\n",
    "\n",
    "# Which ngrams do we get? \n",
    "print(\"\\n\\nNGRAMS:\")\n",
    "for ngrams in ngram_data: \n",
    "    print(list(ngrams))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dycjjid-77g4"
   },
   "source": [
    "## 2. Training the N-gram Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k0_YORmS8D6c"
   },
   "source": [
    "We can now train a model on the pre-processed data. We use a Maximum Likelihood Estimator (MLE) using trigrams as the maximum n-gram size. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JfseDQAZ8Fxa",
    "outputId": "217639d6-6fb8-4d84-c805-b3024fcc20e3"
   },
   "outputs": [],
   "source": [
    "from nltk.lm import MLE\n",
    "\n",
    "n=3\n",
    "\n",
    "# Train data is an iterator over the pre-processed input\n",
    "train_data, padded_sents = padded_everygram_pipeline(n, tokenized_text)\n",
    "\n",
    "model = MLE(n)\n",
    "model.fit(train_data, padded_sents)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Vocabulary with cutoff=1 unk_label='<UNK>' and 10144 items>\n",
      "\n",
      "[(',', 12018), ('<s>', 11700), ('</s>', 11700), ('to', 5137), ('.', 5128), ('the', 5120), ('and', 4541), ('of', 4258), ('a', 3060), ('i', 2919), ('was', 2373), ('her', 2367), (';', 2353), ('it', 2338), ('not', 2242), ('she', 2219), ('in', 2138), ('“', 2099), ('”', 2090), ('be', 1958), ('you', 1876), ('that', 1754), ('he', 1734), ('had', 1611), ('as', 1429), ('have', 1312), ('for', 1294), ('is', 1221), ('but', 1207), ('with', 1202), ('very', 1173), ('his', 1126), ('’', 1114), ('mr.', 1089), ('!', 1063), ('at', 1016), ('so', 929), ('s', 914), ('could', 825), ('all', 820), ('emma', 819), ('would', 809), ('been', 753), ('my', 719), ('him', 706), ('no', 684), ('on', 680), ('mrs.', 669), ('any', 652), ('?', 621)]\n",
      "\n",
      "[('vouch', 1), ('knightley—or', 1), ('churchills—or', 1), ('unbleached', 1), ('nobility', 1), ('liberally', 1), ('created', 1), ('—or', 1), ('regretted.—the', 1), ('gradual', 1), ('impair.—perhaps', 1), ('clergyman', 1), ('altar', 1), ('herself.—robert', 1), ('campbells.—the', 1), ('intermediate', 1), ('knightley.—they', 1), ('seaside', 1), ('plan.—john', 1), ('woodhouse—how', 1), ('sounded', 1), ('hopeless.—a', 1), ('pain.—he', 1), ('it—a', 1), ('resignation', 1), ('acquiesced', 1), ('hesitated—she', 1), ('befriended', 1), ('illumination', 1), ('way.—mrs', 1), ('poultry-house', 1), ('robbed', 1), ('turkeys—evidently', 1), ('poultry-yards', 1), ('suffered.—pilfering', 1), ('_housebreaking_', 1), ('fears.—he', 1), ('protected', 1), ('safe.—but', 1), ('wedding-day—and', 1), ('weddings', 1), ('detailed', 1), ('own.—', 1), ('satin', 1), ('veils', 1), ('stare', 1), ('deficiencies', 1), ('predictions', 1), ('band', 1), ('finis', 1)]\n"
     ]
    }
   ],
   "source": [
    "# Let's have a look at the vocabulary\n",
    "print(model.vocab)\n",
    "print()\n",
    "print(model.vocab.counts.most_common(50))\n",
    "print()\n",
    "print(model.vocab.counts.most_common()[-50:])\n",
    "\n",
    "# You can see that the text is much cleaner than the corpora that were crawled from the web"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jdSgORAY9aGg"
   },
   "source": [
    "# 3. Using the N-gram Language Model\n",
    "An ngram-based language model simply counts the frequency of n-grams during training and stores them in an easily accessible counter representation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pGyQdNB-9nIM",
    "outputId": "e4e27a37-2e07-47dc-c82b-1d5486173186"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<NgramCounter with 3 ngram orders and 612441 ngrams>\n",
      "2242\n",
      "161\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "print(model.counts)\n",
    "\n",
    "# counts for unigrams:\n",
    "print(model.counts['not']) # i.e. Count('not')\n",
    "# count for bigrams\n",
    "print(model.counts[['was']]['not']) # i.e. Count('not'|'was')\n",
    "# count for trigrams\n",
    "print(model.counts[['emma', 'was']]['not']) # i.e. Count('not'|'emma was')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kXkZUck6-C_C"
   },
   "source": [
    "Based on the ngram-frequencies, it calculates the probability of a word in a certain context. \n",
    "For the MLE model, the probability is calculated as the relative frequency. **Note that the model score is lower than the probability.** This has to do with the padding tokens. **Make sure you understand how the score is adjusted.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hKNUjQaJ-hY4",
    "outputId": "0101b56f-9468-467b-d414-74cbedfc924c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Probability of the word 'not'\n",
      "0.01068\n",
      "0.01202\n",
      "\n",
      "Adjust for padding tokens\n",
      "186597 23400\n",
      "0.01068\n",
      "\n",
      "Probabilities padding tokens\n",
      "0.05572\n",
      "0.05572\n"
     ]
    }
   ],
   "source": [
    "all_tokens = [tok for sent in tokenized_text for tok in sent]\n",
    "num_tokens = len(all_tokens)\n",
    "num_sentences = len(tokenized_text)\n",
    "\n",
    "model_score = model.score('not')\n",
    "probability = model.counts['not']/num_tokens\n",
    "                                    \n",
    "\n",
    "print(\"\\nProbability of the word 'not'\")\n",
    "print(\"{:.5f}\".format(model_score))\n",
    "print(\"{:.5f}\".format(probability))\n",
    "\n",
    "print(\"\\nAdjust for padding tokens\")\n",
    "all_padding_tokens = num_sentences * (n-1) * 2\n",
    "print(num_tokens, all_padding_tokens)\n",
    "\n",
    "adjusted_probability = model.counts['not']/(num_tokens + all_padding_tokens)\n",
    "print(\"{:.5f}\".format(adjusted_probability))\n",
    "\n",
    "print(\"\\nProbabilities padding tokens\")\n",
    "print(\"{:.5f}\".format(model.score('<s>')))\n",
    "print(\"{:.5f}\".format(model.score('</s>')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hKNUjQaJ-hY4",
    "outputId": "0101b56f-9468-467b-d414-74cbedfc924c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06784660766961652\n",
      "0.078125\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# We can also calculate the frequency for higher n-grams.\n",
    "# bigram\n",
    "print(model.score('not', ['was']))  # P('not'|'is')\n",
    "# trigram\n",
    "print(model.score('not', ['emma', 'was']))  # P('not'|'emma is')\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9HJqtRx8-3S8",
    "outputId": "489a440e-f1c5-4d71-ad7c-2f6682f2488f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.010230179028132993\n",
      "-6.611024797307352\n"
     ]
    }
   ],
   "source": [
    "# To avoid underflow when working with many small score values, we usually work with log probabilities instead. \n",
    "# This can be done with the `logscore` method.\n",
    "print(model.score('sure', ['very']))\n",
    "print(model.logscore('sure', ['very']))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. The Unknown Word Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u7NWQE2o8g36",
    "outputId": "1f939fbf-7a67-4108-83a9-4185f4890916"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('emma', 'did', 'not', 'feel', '<UNK>', 'at', 'all.')\n"
     ]
    }
   ],
   "source": [
    "# The vocabulary helps us handle words that have not occurred during training.\n",
    "# If we lookup the vocab on unseen sentences not from the training data, \n",
    "# it automatically replace words not in the vocabulary with `<UNK>`.\n",
    "print(model.vocab.lookup('emma did not feel challenged at all.'.split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The standard MLE language model has a problem with unknown words. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lL4cvl0v-sRH",
    "outputId": "df4beebf-6980-493e-e367-3af1f82a7217"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "0.0 -inf\n",
      "0.0 -inf\n"
     ]
    }
   ],
   "source": [
    "# Items that are not seen during training are mapped to the vocabulary's \"unknown label\" token.  This is \"<UNK>\" by default.\n",
    "print(model.score(\"<UNK>\") == model.score(\"challenged\"))\n",
    "\n",
    "# The MLE model does not apply any smoothing, so the probability for UNK is 0\n",
    "print(model.score(\"<UNK>\"),model.logscore(\"<UNK>\") )\n",
    "\n",
    "# As a consequence, the probability for a phrase containing an unknown word is also 0. \n",
    "print(model.score('challenged', ['not', 'feel']), model.logscore('challenged', ['not', 'feel']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This problem can be solved with more advanced smoothing techniques, for example Laplace smoothing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01018892437119846\n",
      "0.00043608414607001876\n",
      "9.850275807722617e-05\n",
      "\n",
      "-6.616854433290205\n",
      "-11.163105837655321\n",
      "-13.309476353841106\n"
     ]
    }
   ],
   "source": [
    "from nltk.lm import Laplace\n",
    "n = 3\n",
    "train_data, padded_sents = padded_everygram_pipeline(n, tokenized_text)\n",
    "smoothed_model_small =  Laplace(n)\n",
    "smoothed_model_small.fit(train_data, padded_sents)\n",
    "print(smoothed_model_small.score('not'))\n",
    "print(smoothed_model_small.score('feel'))\n",
    "print(smoothed_model_small.score('challenged', ['not', 'feel']))\n",
    "print()\n",
    "print(smoothed_model_small.logscore('not'))\n",
    "print(smoothed_model_small.logscore('feel'))\n",
    "print(smoothed_model_small.logscore('challenged', ['not', 'feel']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['afraid', '.', '</s>']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smoothed_model_small.generate(text_seed=[\"I\", \"did\", \"not\", \"feel\"], num_words=3, random_seed=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Ngram_LM.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
