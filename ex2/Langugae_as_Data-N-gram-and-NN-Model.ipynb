{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [],
      "dockerImageVersionId": 30805,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Importing Libraries and packages"
      ],
      "metadata": {
        "id": "6yxGyxj9kM1l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install tokenizers scikit-learn\n",
        "! pip install hazm\n",
        "! pip install tiktoken\n",
        "\n",
        "from tokenizers import Tokenizer\n",
        "from tokenizers import trainers\n",
        "from tokenizers.normalizers import StripAccents, Lowercase, Sequence\n",
        "from tokenizers.pre_tokenizers import Whitespace\n",
        "from tokenizers.trainers import BpeTrainer, UnigramTrainer\n",
        "from tokenizers.models import BPE, Unigram\n",
        "\n",
        "from transformers import pipeline, AutoTokenizer, GPT2LMHeadModel\n",
        "\n",
        "from collections import Counter\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tokenizers\n",
        "\n",
        "import re\n",
        "from hazm import *\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt_tab')\n",
        "from nltk import word_tokenize\n",
        "from nltk.lm import MLE\n",
        "from nltk.lm.preprocessing import pad_both_ends, padded_everygram_pipeline\n",
        "from nltk.lm.preprocessing import padded_everygram_pipeline\n",
        "from nltk import ngrams\n",
        "\n",
        "import tiktoken\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "from importlib.metadata import version\n",
        "import math\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "execution": {
          "iopub.status.busy": "2024-12-13T10:26:06.624471Z",
          "iopub.execute_input": "2024-12-13T10:26:06.625243Z"
        },
        "trusted": true,
        "id": "3sxyNjnykM1n",
        "outputId": "469735d9-ba4e-4e59-ec69-47ed7f5d3e18"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Requirement already satisfied: tokenizers in /opt/conda/lib/python3.10/site-packages (0.20.3)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (1.2.2)\nRequirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /opt/conda/lib/python3.10/site-packages (from tokenizers) (0.26.2)\nRequirement already satisfied: numpy>=1.17.3 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.26.4)\nRequirement already satisfied: scipy>=1.3.2 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.14.1)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (3.5.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (3.15.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (2024.6.0)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (6.0.2)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (2.32.3)\nRequirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (4.66.4)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface-hub<1.0,>=0.16.4->tokenizers) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers) (2024.6.2)\nCollecting hazm\n  Downloading hazm-0.10.0-py3-none-any.whl.metadata (11 kB)\nCollecting fasttext-wheel<0.10.0,>=0.9.2 (from hazm)\n  Downloading fasttext_wheel-0.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\nCollecting flashtext<3.0,>=2.7 (from hazm)\n  Downloading flashtext-2.7.tar.gz (14 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: gensim<5.0.0,>=4.3.1 in /opt/conda/lib/python3.10/site-packages (from hazm) (4.3.3)\nCollecting nltk<4.0.0,>=3.8.1 (from hazm)\n  Downloading nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\nCollecting numpy==1.24.3 (from hazm)\n  Downloading numpy-1.24.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\nCollecting python-crfsuite<0.10.0,>=0.9.9 (from hazm)\n  Downloading python_crfsuite-0.9.11-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.3 kB)\nRequirement already satisfied: scikit-learn<2.0.0,>=1.2.2 in /opt/conda/lib/python3.10/site-packages (from hazm) (1.2.2)\nRequirement already satisfied: pybind11>=2.2 in /opt/conda/lib/python3.10/site-packages (from fasttext-wheel<0.10.0,>=0.9.2->hazm) (2.13.6)\nRequirement already satisfied: setuptools>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from fasttext-wheel<0.10.0,>=0.9.2->hazm) (70.0.0)\nCollecting scipy<1.14.0,>=1.7.0 (from gensim<5.0.0,>=4.3.1->hazm)\n  Downloading scipy-1.13.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: smart-open>=1.8.1 in /opt/conda/lib/python3.10/site-packages (from gensim<5.0.0,>=4.3.1->hazm) (7.0.4)\nRequirement already satisfied: click in /opt/conda/lib/python3.10/site-packages (from nltk<4.0.0,>=3.8.1->hazm) (8.1.7)\nRequirement already satisfied: joblib in /opt/conda/lib/python3.10/site-packages (from nltk<4.0.0,>=3.8.1->hazm) (1.4.2)\nRequirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.10/site-packages (from nltk<4.0.0,>=3.8.1->hazm) (2024.5.15)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from nltk<4.0.0,>=3.8.1->hazm) (4.66.4)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn<2.0.0,>=1.2.2->hazm) (3.5.0)\nRequirement already satisfied: wrapt in /opt/conda/lib/python3.10/site-packages (from smart-open>=1.8.1->gensim<5.0.0,>=4.3.1->hazm) (1.16.0)\nDownloading hazm-0.10.0-py3-none-any.whl (892 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m892.6/892.6 kB\u001b[0m \u001b[31m31.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading numpy-1.24.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m90.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading fasttext_wheel-0.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m77.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading nltk-3.9.1-py3-none-any.whl (1.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m62.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading python_crfsuite-0.9.11-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m52.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading scipy-1.13.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.6/38.6 MB\u001b[0m \u001b[31m47.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: flashtext\n  Building wheel for flashtext (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for flashtext: filename=flashtext-2.7-py2.py3-none-any.whl size=9296 sha256=1f4f08a7fbaa87fff9de3cc14b8ac2fa72f24a8ddb191fc72a828ca5eeed747d\n  Stored in directory: /root/.cache/pip/wheels/bc/be/39/c37ad168eb2ff644c9685f52554440372129450f0b8ed203dd\nSuccessfully built flashtext\nInstalling collected packages: flashtext, python-crfsuite, numpy, nltk, scipy, fasttext-wheel, hazm\n  Attempting uninstall: numpy\n    Found existing installation: numpy 1.26.4\n    Uninstalling numpy-1.26.4:\n      Successfully uninstalled numpy-1.26.4\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing dataset"
      ],
      "metadata": {
        "id": "6m7MZBxTkM1p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://downloads.wortschatz-leipzig.de/corpora/fas_news_2020_100K.tar.gz\n",
        "!tar --gunzip --extract --verbose --file=fas_news_2020_100K.tar.gz\n",
        "persian_text_path = \"/kaggle/working/fas_news_2020_100K/fas_news_2020_100K-sentences.txt\""
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-12-13T10:26:43.452291Z",
          "iopub.execute_input": "2024-12-13T10:26:43.452537Z",
          "iopub.status.idle": "2024-12-13T10:26:51.723172Z",
          "shell.execute_reply.started": "2024-12-13T10:26:43.452509Z",
          "shell.execute_reply": "2024-12-13T10:26:51.722112Z"
        },
        "trusted": true,
        "id": "dhThuVKgkM1p",
        "outputId": "fc4d8d0d-4871-4c02-d158-02046f3df933"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "--2024-12-13 10:26:44--  https://downloads.wortschatz-leipzig.de/corpora/fas_news_2020_100K.tar.gz\nResolving downloads.wortschatz-leipzig.de (downloads.wortschatz-leipzig.de)... 139.18.2.68\nConnecting to downloads.wortschatz-leipzig.de (downloads.wortschatz-leipzig.de)|139.18.2.68|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 31227186 (30M) [application/x-gzip]\nSaving to: 'fas_news_2020_100K.tar.gz'\n\nfas_news_2020_100K. 100%[===================>]  29.78M  6.94MB/s    in 4.3s    \n\n2024-12-13 10:26:50 (6.94 MB/s) - 'fas_news_2020_100K.tar.gz' saved [31227186/31227186]\n\nfas_news_2020_100K/\nfas_news_2020_100K/fas_news_2020_100K-inv_w.txt\nfas_news_2020_100K/fas_news_2020_100K-sources.txt\nfas_news_2020_100K/fas_news_2020_100K-co_n.txt\nfas_news_2020_100K/fas_news_2020_100K-import.sql\nfas_news_2020_100K/fas_news_2020_100K-sentences.txt\nfas_news_2020_100K/fas_news_2020_100K-co_s.txt\nfas_news_2020_100K/fas_news_2020_100K-words.txt\nfas_news_2020_100K/fas_news_2020_100K-inv_so.txt\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing dataset"
      ],
      "metadata": {
        "id": "pFzk8uhnkM1p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Punctuations and Separators\n",
        "punc = '''()-[]{};،:'\"\\\\, <>./?@#$%^&*_~.'''\n",
        "seperator = ['\\xad', '\\u200e', '\\u200f', '\\u200d', '\\u200c', '\\n']\n",
        "\n",
        "# Hazm Normalizer and Stemmer\n",
        "hazm_normalizer = Normalizer()\n",
        "hazm_stemmer = Stemmer()\n",
        "\n",
        "# Read corpus\n",
        "with open(persian_text_path, \"r\") as f:\n",
        "    sentences = f.readlines()\n",
        "\n",
        "def preprocess_text_with_hazm(text):\n",
        "    # Normalize using Hazm e.g. اصلاح نويسه ها -> اصلاح نویسه‌ها\n",
        "    text = hazm_normalizer.normalize(text)\n",
        "\n",
        "    # Remove unwanted separators\n",
        "    for sep in seperator:\n",
        "        text = text.replace(sep, \" \")\n",
        "\n",
        "    # Remove all punctuation\n",
        "    text = re.sub(r'[^\\u0600-\\u06FF0-9\\s]+', '', text)\n",
        "    text = text.replace(',', '')\n",
        "    text = text.replace('،', '')\n",
        "    text = re.sub(r\"^\\d+\\s*\", \"\", text)\n",
        "\n",
        "    # Tokenize using Hazm for more accurate Persian tokenization\n",
        "    tokens = word_tokenize(text)\n",
        "\n",
        "    # Add <s> and </s> tags to the sentence\n",
        "    # tokens = ['<s>'] + tokens + ['</s>']\n",
        "\n",
        "    # Stemming using hazm e.g  کتاب‌ها -> کتاب‌\n",
        "    # tokens = [hazm_stemmer.stem(token) for token in tokens]\n",
        "\n",
        "    return tokens\n",
        "\n",
        "# Preprocess all sentences\n",
        "cleaned_sentences = [preprocess_text_with_hazm(sentence) for sentence in sentences]\n",
        "\n",
        "# Split into training, validation, and testing datasets (80%, 10%, 10%)\n",
        "train_corpus, temp_corpus = train_test_split(cleaned_sentences, test_size=0.2, random_state=42)\n",
        "val_corpus, test_corpus = train_test_split(temp_corpus, test_size=0.5, random_state=42)\n",
        "\n",
        "# Example\n",
        "print(\"Training Data Example:\", train_corpus[0])\n",
        "print(\"Validation Data Example:\", val_corpus[0])\n",
        "print(\"Test Data Example:\", test_corpus[0])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-12-12T08:21:57.017781Z",
          "iopub.execute_input": "2024-12-12T08:21:57.018164Z",
          "iopub.status.idle": "2024-12-12T08:22:31.348168Z",
          "shell.execute_reply.started": "2024-12-12T08:21:57.018136Z",
          "shell.execute_reply": "2024-12-12T08:22:31.347196Z"
        },
        "trusted": true,
        "id": "3MtFh8l-kM1p",
        "outputId": "3d97afb2-af1c-4422-8f73-d4c3498b8281"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Training Data Example: ['گفتم', 'نه', 'حاجی', 'شما', 'هم', 'بروید', 'دیگر', 'کسی', 'نیست']\nValidation Data Example: ['در', 'این', 'خصوص', 'مدیرکل', 'دفتر', 'پیشگیری', 'از', 'قاچاق', 'کالا', 'و', 'ارز', 'در', 'واکنش', 'به', 'اعلام', 'آمار', 'قاچاق', 'سیگار', 'در', 'کشور', 'توسط', 'برخی', 'دستگاه', 'ها', 'گفت', 'اعلام', 'رسمی', 'آمار', 'قاچاق', 'سیگار', 'در', 'کشور', 'بر', 'عهده', 'ستاد', 'مبارزه', 'با', 'قاچاق', 'کالا', 'و', 'ارز', 'است']\nTest Data Example: ['نشان', 'به', 'آن', 'نشان', 'که', 'در', 'حدود', 'کمتر', 'از', '۳۰', 'سال', 'خدمتش', 'همه', 'کیفها', 'پولها', 'چکهای', 'حامل', 'و', 'گوشیهای', 'همراهی', 'که', 'پیدا', 'کرده', 'با', 'پیجویی', 'تمام', 'به', 'صاحبانش', 'برگردانده', 'است']\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# N-gram Model"
      ],
      "metadata": {
        "id": "5Wtl9sQzkM1q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def ngram_counts(corpus, n, i):\n",
        "    ngram_list = []\n",
        "\n",
        "    stopwords = ['به', 'از', 'را', 'و', 'برای', 'این', 'که', 'با', 'در', 'چون', 'اگر', 'ها', 'نه', 'اینکه', 'یا', 'هم', 'تا', 'که', 'آن', 'باید', 'شده', 'چرا', 'همچنین', 'کردن', 'شد', 'می']\n",
        "    filtered_corpus = [\n",
        "        [word for word in sentence if word not in stopwords]\n",
        "        for sentence in corpus\n",
        "    ]\n",
        "\n",
        "    for sentence in filtered_corpus:\n",
        "        sentence_ngrams = list(ngrams(sentence, n))\n",
        "        ngram_list.extend(sentence_ngrams)\n",
        "\n",
        "    ngram_counts = Counter(ngram_list)\n",
        "\n",
        "    most_common_ngrams = ngram_counts.most_common(i)\n",
        "\n",
        "    print(f\"\\nMost common {n}-grams:\")\n",
        "    for ngram, count in most_common_ngrams:\n",
        "        print(f\"{ngram}: {count}\")\n",
        "\n",
        "print(ngram_counts(train_corpus, 3, 10))\n",
        "print(ngram_counts(train_corpus, 2, 20))"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-11T15:53:24.927537Z",
          "iopub.status.busy": "2024-12-11T15:53:24.927193Z",
          "iopub.status.idle": "2024-12-11T15:53:26.927386Z",
          "shell.execute_reply": "2024-12-11T15:53:26.926474Z",
          "shell.execute_reply.started": "2024-12-11T15:53:24.927507Z"
        },
        "trusted": true,
        "id": "fYNrj5kzkM1q",
        "outputId": "de1ee898-b652-4be3-eaad-a8e115aeac51"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Most common 3-grams:\n",
            "('گزارش', 'همشهری', 'آنلاین'): 1115\n",
            "('همشهری', 'آنلاین', 'نقل'): 770\n",
            "('وی', 'ادامه', 'داد'): 510\n",
            "('دانشگاه', 'علوم', 'پزشکی'): 397\n",
            "('مجلس', 'شورای', 'اسلامی'): 384\n",
            "('جمهوری', 'اسلامی', 'ایران'): 284\n",
            "('شیوع', 'ویروس', 'کرونا'): 271\n",
            "('۲۴', 'ساعت', 'گذشته'): 253\n",
            "('جان', 'خود', 'دست'): 172\n",
            "('خبر', 'داد', 'گفت'): 165\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# The n-gram size\n",
        "n = 3\n",
        "\n",
        "ngram_data, padded = padded_everygram_pipeline(n, train_corpus[0:10])\n",
        "\n",
        "# Padding adds special tokens (start symbol <s>) and (end symbol </s>) to the text to signify sentence boundaries.\n",
        "# This ensures that n-grams near the edges of a sentence (e.g., start or end) still form complete n-grams\n",
        "\n",
        "print(\"PADDING:\")\n",
        "print(list(padded))\n",
        "\n",
        "# Unigrams: Individual words or tokens, e.g., ('<s>',), ('i',).\n",
        "# Bigrams: Pairs of tokens, e.g., ('<s>', '<s>'), ('<s>', 'i').\n",
        "# Trigrams: Groups of three tokens, e.g., ('<s>', '<s>', 'i'), ('<s>', 'i', 'j').\n",
        "# Padding ensures valid n-grams even at sentence start/end.\n",
        "\n",
        "print(\"\\n\\nNGRAMS:\")\n",
        "for ngrams in ngram_data:\n",
        "    print(list(ngrams))\n",
        "    print()"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-11T15:53:29.233205Z",
          "iopub.status.busy": "2024-12-11T15:53:29.232937Z",
          "iopub.status.idle": "2024-12-11T15:53:29.240738Z",
          "shell.execute_reply": "2024-12-11T15:53:29.239893Z",
          "shell.execute_reply.started": "2024-12-11T15:53:29.233179Z"
        },
        "trusted": true,
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "x5SbPwFBkM1q",
        "outputId": "e3adb57c-0074-4755-acaa-07c2059024cf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PADDING:\n",
            "['<s>', '<s>', 'گفتم', 'نه', 'حاجی', 'شما', 'هم', 'بروید', 'دیگر', 'کسی', 'نیست', '</s>', '</s>', '<s>', '<s>', 'در', 'این', 'غربال', 'گری', 'ها', 'کیس', 'های', 'مشکوکی', 'با', 'علامت', 'تب', 'داشتیم', 'که', 'خدا', 'را', 'شکر', 'ورزشکاری', 'نبود', 'که', 'با', 'کرونا', 'درگیر', 'باشد', 'اما', 'در', 'بین', 'همکاران', 'بودند', 'کسانی', 'که', 'مبتلا', 'شدند', '</s>', '</s>', '<s>', '<s>', 'حضرت', 'رسول', 'در', 'حلقه', 'اصحاب', 'نشسته_بودند', '</s>', '</s>', '<s>', '<s>', 'این', 'اتفاق', 'باعث', 'شد', 'تا', 'نقش', 'ایالات', 'متحده', 'به', 'عنوان', 'جایگزین', 'طالبان', 'در', 'افغانستان', 'حذف', 'و', 'جای', 'آن', 'را', 'دولتی', 'بگیرد', 'که', 'بومی', 'و', 'از', 'میان', 'سیاستمداران', 'افغان', 'انتخاب', 'شده_است', '</s>', '</s>', '<s>', '<s>', 'وی', 'اضافه', 'کرد', 'همه', 'بخشهای', 'سازمان', 'در', 'مقابله', 'با', 'کرونا', 'و', 'حفظ', 'آرامش', 'مردم', 'از', 'هیچ', 'چیز', 'دریغ', 'نمی', 'کنند', 'و', 'تلاش', 'دارند', 'تا', 'آخرین', 'لحظه', 'کار', 'کنند', 'و', 'حتی', 'از', 'جان', 'خود', 'هم', 'می', 'گذرند', '</s>', '</s>', '<s>', '<s>', 'در', 'روایات', 'ما', 'به', 'طور', 'مکرر', 'از', 'دو', 'غیبت', 'آن', 'حضرت', 'سخن', 'به', 'میان', 'آمده', 'و', 'از', 'سالها', 'پیش', 'از', 'تولد', 'امام', 'مهدی', 'ع', 'بر', 'این', 'موضوع', 'تصریح', 'شده_است', 'که', 'حضرتش', 'دو', 'غیبت', 'خواهند_داشت', 'که', 'هر', 'یک', 'با', 'دیگری', 'متفاوت', 'است', '</s>', '</s>', '<s>', '<s>', 'نکته', 'مهم', 'این', 'است', 'که', 'نباید', 'انتظار', 'کار', 'ویژهای', 'را', 'در', 'مدت', 'کوتاه', 'داشت', 'اما', 'این', 'ریلگذاری', 'ما', 'را', 'به', 'نقطه', 'خوبی', 'خواهد_رساند', '</s>', '</s>', '<s>', '<s>', 'ارتفاع', 'پست', 'ابراهیم', 'حاتمیکیا', 'هم', 'پسزمینه', 'جنگ', 'دارد', 'و', 'پیامدهای', 'جنگ', 'را', 'بر', 'زندگی', 'مردم', 'خوزستان', 'روایت', 'می', 'کند', 'و', 'سرانجام', 'بمب', '؛', 'یک', 'عاشقانه', 'پیمان', 'معادی', 'که', 'داستان', 'آن', 'در', 'دوران', 'موشکباران', 'شهرها', 'روایت', 'می', 'شود', '</s>', '</s>', '<s>', '<s>', 'وی', 'ادامه', 'داد', 'این', 'مسیر', 'به', 'علت', 'پایین', 'آمدن', 'چند', 'قطعه', 'سنگ', 'بزرگ', 'بر', 'اثر', 'برخورد', 'صاعقه', 'با', 'کوه', 'مسدود', 'شده_است', 'و', 'در', 'سایه', 'تلاش', 'راهدارای', 'و', 'جابهجایی', 'سنگهای', 'کوچک', 'این', 'راه', 'روستایی', 'به', 'صورت', 'موقت', 'و', 'کنارگذر', 'بازگشایی', 'شده_است', '</s>', '</s>', '<s>', '<s>', 'اساسا', 'حمایت', 'از', 'بخش', 'کشاورزی', 'و', 'غذا', 'به', 'لحاظ', 'مبانی', 'تئوریک', 'اجتناب', 'ناپذیر', 'است', '</s>', '</s>']\n",
            "\n",
            "\n",
            "NGRAMS:\n",
            "[('<s>',), ('<s>', '<s>'), ('<s>', '<s>', 'گفتم'), ('<s>',), ('<s>', 'گفتم'), ('<s>', 'گفتم', 'نه'), ('گفتم',), ('گفتم', 'نه'), ('گفتم', 'نه', 'حاجی'), ('نه',), ('نه', 'حاجی'), ('نه', 'حاجی', 'شما'), ('حاجی',), ('حاجی', 'شما'), ('حاجی', 'شما', 'هم'), ('شما',), ('شما', 'هم'), ('شما', 'هم', 'بروید'), ('هم',), ('هم', 'بروید'), ('هم', 'بروید', 'دیگر'), ('بروید',), ('بروید', 'دیگر'), ('بروید', 'دیگر', 'کسی'), ('دیگر',), ('دیگر', 'کسی'), ('دیگر', 'کسی', 'نیست'), ('کسی',), ('کسی', 'نیست'), ('کسی', 'نیست', '</s>'), ('نیست',), ('نیست', '</s>'), ('نیست', '</s>', '</s>'), ('</s>',), ('</s>', '</s>'), ('</s>',)]\n",
            "\n",
            "[('<s>',), ('<s>', '<s>'), ('<s>', '<s>', 'در'), ('<s>',), ('<s>', 'در'), ('<s>', 'در', 'این'), ('در',), ('در', 'این'), ('در', 'این', 'غربال'), ('این',), ('این', 'غربال'), ('این', 'غربال', 'گری'), ('غربال',), ('غربال', 'گری'), ('غربال', 'گری', 'ها'), ('گری',), ('گری', 'ها'), ('گری', 'ها', 'کیس'), ('ها',), ('ها', 'کیس'), ('ها', 'کیس', 'های'), ('کیس',), ('کیس', 'های'), ('کیس', 'های', 'مشکوکی'), ('های',), ('های', 'مشکوکی'), ('های', 'مشکوکی', 'با'), ('مشکوکی',), ('مشکوکی', 'با'), ('مشکوکی', 'با', 'علامت'), ('با',), ('با', 'علامت'), ('با', 'علامت', 'تب'), ('علامت',), ('علامت', 'تب'), ('علامت', 'تب', 'داشتیم'), ('تب',), ('تب', 'داشتیم'), ('تب', 'داشتیم', 'که'), ('داشتیم',), ('داشتیم', 'که'), ('داشتیم', 'که', 'خدا'), ('که',), ('که', 'خدا'), ('که', 'خدا', 'را'), ('خدا',), ('خدا', 'را'), ('خدا', 'را', 'شکر'), ('را',), ('را', 'شکر'), ('را', 'شکر', 'ورزشکاری'), ('شکر',), ('شکر', 'ورزشکاری'), ('شکر', 'ورزشکاری', 'نبود'), ('ورزشکاری',), ('ورزشکاری', 'نبود'), ('ورزشکاری', 'نبود', 'که'), ('نبود',), ('نبود', 'که'), ('نبود', 'که', 'با'), ('که',), ('که', 'با'), ('که', 'با', 'کرونا'), ('با',), ('با', 'کرونا'), ('با', 'کرونا', 'درگیر'), ('کرونا',), ('کرونا', 'درگیر'), ('کرونا', 'درگیر', 'باشد'), ('درگیر',), ('درگیر', 'باشد'), ('درگیر', 'باشد', 'اما'), ('باشد',), ('باشد', 'اما'), ('باشد', 'اما', 'در'), ('اما',), ('اما', 'در'), ('اما', 'در', 'بین'), ('در',), ('در', 'بین'), ('در', 'بین', 'همکاران'), ('بین',), ('بین', 'همکاران'), ('بین', 'همکاران', 'بودند'), ('همکاران',), ('همکاران', 'بودند'), ('همکاران', 'بودند', 'کسانی'), ('بودند',), ('بودند', 'کسانی'), ('بودند', 'کسانی', 'که'), ('کسانی',), ('کسانی', 'که'), ('کسانی', 'که', 'مبتلا'), ('که',), ('که', 'مبتلا'), ('که', 'مبتلا', 'شدند'), ('مبتلا',), ('مبتلا', 'شدند'), ('مبتلا', 'شدند', '</s>'), ('شدند',), ('شدند', '</s>'), ('شدند', '</s>', '</s>'), ('</s>',), ('</s>', '</s>'), ('</s>',)]\n",
            "\n",
            "[('<s>',), ('<s>', '<s>'), ('<s>', '<s>', 'حضرت'), ('<s>',), ('<s>', 'حضرت'), ('<s>', 'حضرت', 'رسول'), ('حضرت',), ('حضرت', 'رسول'), ('حضرت', 'رسول', 'در'), ('رسول',), ('رسول', 'در'), ('رسول', 'در', 'حلقه'), ('در',), ('در', 'حلقه'), ('در', 'حلقه', 'اصحاب'), ('حلقه',), ('حلقه', 'اصحاب'), ('حلقه', 'اصحاب', 'نشسته_بودند'), ('اصحاب',), ('اصحاب', 'نشسته_بودند'), ('اصحاب', 'نشسته_بودند', '</s>'), ('نشسته_بودند',), ('نشسته_بودند', '</s>'), ('نشسته_بودند', '</s>', '</s>'), ('</s>',), ('</s>', '</s>'), ('</s>',)]\n",
            "\n",
            "[('<s>',), ('<s>', '<s>'), ('<s>', '<s>', 'این'), ('<s>',), ('<s>', 'این'), ('<s>', 'این', 'اتفاق'), ('این',), ('این', 'اتفاق'), ('این', 'اتفاق', 'باعث'), ('اتفاق',), ('اتفاق', 'باعث'), ('اتفاق', 'باعث', 'شد'), ('باعث',), ('باعث', 'شد'), ('باعث', 'شد', 'تا'), ('شد',), ('شد', 'تا'), ('شد', 'تا', 'نقش'), ('تا',), ('تا', 'نقش'), ('تا', 'نقش', 'ایالات'), ('نقش',), ('نقش', 'ایالات'), ('نقش', 'ایالات', 'متحده'), ('ایالات',), ('ایالات', 'متحده'), ('ایالات', 'متحده', 'به'), ('متحده',), ('متحده', 'به'), ('متحده', 'به', 'عنوان'), ('به',), ('به', 'عنوان'), ('به', 'عنوان', 'جایگزین'), ('عنوان',), ('عنوان', 'جایگزین'), ('عنوان', 'جایگزین', 'طالبان'), ('جایگزین',), ('جایگزین', 'طالبان'), ('جایگزین', 'طالبان', 'در'), ('طالبان',), ('طالبان', 'در'), ('طالبان', 'در', 'افغانستان'), ('در',), ('در', 'افغانستان'), ('در', 'افغانستان', 'حذف'), ('افغانستان',), ('افغانستان', 'حذف'), ('افغانستان', 'حذف', 'و'), ('حذف',), ('حذف', 'و'), ('حذف', 'و', 'جای'), ('و',), ('و', 'جای'), ('و', 'جای', 'آن'), ('جای',), ('جای', 'آن'), ('جای', 'آن', 'را'), ('آن',), ('آن', 'را'), ('آن', 'را', 'دولتی'), ('را',), ('را', 'دولتی'), ('را', 'دولتی', 'بگیرد'), ('دولتی',), ('دولتی', 'بگیرد'), ('دولتی', 'بگیرد', 'که'), ('بگیرد',), ('بگیرد', 'که'), ('بگیرد', 'که', 'بومی'), ('که',), ('که', 'بومی'), ('که', 'بومی', 'و'), ('بومی',), ('بومی', 'و'), ('بومی', 'و', 'از'), ('و',), ('و', 'از'), ('و', 'از', 'میان'), ('از',), ('از', 'میان'), ('از', 'میان', 'سیاستمداران'), ('میان',), ('میان', 'سیاستمداران'), ('میان', 'سیاستمداران', 'افغان'), ('سیاستمداران',), ('سیاستمداران', 'افغان'), ('سیاستمداران', 'افغان', 'انتخاب'), ('افغان',), ('افغان', 'انتخاب'), ('افغان', 'انتخاب', 'شده_است'), ('انتخاب',), ('انتخاب', 'شده_است'), ('انتخاب', 'شده_است', '</s>'), ('شده_است',), ('شده_است', '</s>'), ('شده_است', '</s>', '</s>'), ('</s>',), ('</s>', '</s>'), ('</s>',)]\n",
            "\n",
            "[('<s>',), ('<s>', '<s>'), ('<s>', '<s>', 'وی'), ('<s>',), ('<s>', 'وی'), ('<s>', 'وی', 'اضافه'), ('وی',), ('وی', 'اضافه'), ('وی', 'اضافه', 'کرد'), ('اضافه',), ('اضافه', 'کرد'), ('اضافه', 'کرد', 'همه'), ('کرد',), ('کرد', 'همه'), ('کرد', 'همه', 'بخشهای'), ('همه',), ('همه', 'بخشهای'), ('همه', 'بخشهای', 'سازمان'), ('بخشهای',), ('بخشهای', 'سازمان'), ('بخشهای', 'سازمان', 'در'), ('سازمان',), ('سازمان', 'در'), ('سازمان', 'در', 'مقابله'), ('در',), ('در', 'مقابله'), ('در', 'مقابله', 'با'), ('مقابله',), ('مقابله', 'با'), ('مقابله', 'با', 'کرونا'), ('با',), ('با', 'کرونا'), ('با', 'کرونا', 'و'), ('کرونا',), ('کرونا', 'و'), ('کرونا', 'و', 'حفظ'), ('و',), ('و', 'حفظ'), ('و', 'حفظ', 'آرامش'), ('حفظ',), ('حفظ', 'آرامش'), ('حفظ', 'آرامش', 'مردم'), ('آرامش',), ('آرامش', 'مردم'), ('آرامش', 'مردم', 'از'), ('مردم',), ('مردم', 'از'), ('مردم', 'از', 'هیچ'), ('از',), ('از', 'هیچ'), ('از', 'هیچ', 'چیز'), ('هیچ',), ('هیچ', 'چیز'), ('هیچ', 'چیز', 'دریغ'), ('چیز',), ('چیز', 'دریغ'), ('چیز', 'دریغ', 'نمی'), ('دریغ',), ('دریغ', 'نمی'), ('دریغ', 'نمی', 'کنند'), ('نمی',), ('نمی', 'کنند'), ('نمی', 'کنند', 'و'), ('کنند',), ('کنند', 'و'), ('کنند', 'و', 'تلاش'), ('و',), ('و', 'تلاش'), ('و', 'تلاش', 'دارند'), ('تلاش',), ('تلاش', 'دارند'), ('تلاش', 'دارند', 'تا'), ('دارند',), ('دارند', 'تا'), ('دارند', 'تا', 'آخرین'), ('تا',), ('تا', 'آخرین'), ('تا', 'آخرین', 'لحظه'), ('آخرین',), ('آخرین', 'لحظه'), ('آخرین', 'لحظه', 'کار'), ('لحظه',), ('لحظه', 'کار'), ('لحظه', 'کار', 'کنند'), ('کار',), ('کار', 'کنند'), ('کار', 'کنند', 'و'), ('کنند',), ('کنند', 'و'), ('کنند', 'و', 'حتی'), ('و',), ('و', 'حتی'), ('و', 'حتی', 'از'), ('حتی',), ('حتی', 'از'), ('حتی', 'از', 'جان'), ('از',), ('از', 'جان'), ('از', 'جان', 'خود'), ('جان',), ('جان', 'خود'), ('جان', 'خود', 'هم'), ('خود',), ('خود', 'هم'), ('خود', 'هم', 'می'), ('هم',), ('هم', 'می'), ('هم', 'می', 'گذرند'), ('می',), ('می', 'گذرند'), ('می', 'گذرند', '</s>'), ('گذرند',), ('گذرند', '</s>'), ('گذرند', '</s>', '</s>'), ('</s>',), ('</s>', '</s>'), ('</s>',)]\n",
            "\n",
            "[('<s>',), ('<s>', '<s>'), ('<s>', '<s>', 'در'), ('<s>',), ('<s>', 'در'), ('<s>', 'در', 'روایات'), ('در',), ('در', 'روایات'), ('در', 'روایات', 'ما'), ('روایات',), ('روایات', 'ما'), ('روایات', 'ما', 'به'), ('ما',), ('ما', 'به'), ('ما', 'به', 'طور'), ('به',), ('به', 'طور'), ('به', 'طور', 'مکرر'), ('طور',), ('طور', 'مکرر'), ('طور', 'مکرر', 'از'), ('مکرر',), ('مکرر', 'از'), ('مکرر', 'از', 'دو'), ('از',), ('از', 'دو'), ('از', 'دو', 'غیبت'), ('دو',), ('دو', 'غیبت'), ('دو', 'غیبت', 'آن'), ('غیبت',), ('غیبت', 'آن'), ('غیبت', 'آن', 'حضرت'), ('آن',), ('آن', 'حضرت'), ('آن', 'حضرت', 'سخن'), ('حضرت',), ('حضرت', 'سخن'), ('حضرت', 'سخن', 'به'), ('سخن',), ('سخن', 'به'), ('سخن', 'به', 'میان'), ('به',), ('به', 'میان'), ('به', 'میان', 'آمده'), ('میان',), ('میان', 'آمده'), ('میان', 'آمده', 'و'), ('آمده',), ('آمده', 'و'), ('آمده', 'و', 'از'), ('و',), ('و', 'از'), ('و', 'از', 'سالها'), ('از',), ('از', 'سالها'), ('از', 'سالها', 'پیش'), ('سالها',), ('سالها', 'پیش'), ('سالها', 'پیش', 'از'), ('پیش',), ('پیش', 'از'), ('پیش', 'از', 'تولد'), ('از',), ('از', 'تولد'), ('از', 'تولد', 'امام'), ('تولد',), ('تولد', 'امام'), ('تولد', 'امام', 'مهدی'), ('امام',), ('امام', 'مهدی'), ('امام', 'مهدی', 'ع'), ('مهدی',), ('مهدی', 'ع'), ('مهدی', 'ع', 'بر'), ('ع',), ('ع', 'بر'), ('ع', 'بر', 'این'), ('بر',), ('بر', 'این'), ('بر', 'این', 'موضوع'), ('این',), ('این', 'موضوع'), ('این', 'موضوع', 'تصریح'), ('موضوع',), ('موضوع', 'تصریح'), ('موضوع', 'تصریح', 'شده_است'), ('تصریح',), ('تصریح', 'شده_است'), ('تصریح', 'شده_است', 'که'), ('شده_است',), ('شده_است', 'که'), ('شده_است', 'که', 'حضرتش'), ('که',), ('که', 'حضرتش'), ('که', 'حضرتش', 'دو'), ('حضرتش',), ('حضرتش', 'دو'), ('حضرتش', 'دو', 'غیبت'), ('دو',), ('دو', 'غیبت'), ('دو', 'غیبت', 'خواهند_داشت'), ('غیبت',), ('غیبت', 'خواهند_داشت'), ('غیبت', 'خواهند_داشت', 'که'), ('خواهند_داشت',), ('خواهند_داشت', 'که'), ('خواهند_داشت', 'که', 'هر'), ('که',), ('که', 'هر'), ('که', 'هر', 'یک'), ('هر',), ('هر', 'یک'), ('هر', 'یک', 'با'), ('یک',), ('یک', 'با'), ('یک', 'با', 'دیگری'), ('با',), ('با', 'دیگری'), ('با', 'دیگری', 'متفاوت'), ('دیگری',), ('دیگری', 'متفاوت'), ('دیگری', 'متفاوت', 'است'), ('متفاوت',), ('متفاوت', 'است'), ('متفاوت', 'است', '</s>'), ('است',), ('است', '</s>'), ('است', '</s>', '</s>'), ('</s>',), ('</s>', '</s>'), ('</s>',)]\n",
            "\n",
            "[('<s>',), ('<s>', '<s>'), ('<s>', '<s>', 'نکته'), ('<s>',), ('<s>', 'نکته'), ('<s>', 'نکته', 'مهم'), ('نکته',), ('نکته', 'مهم'), ('نکته', 'مهم', 'این'), ('مهم',), ('مهم', 'این'), ('مهم', 'این', 'است'), ('این',), ('این', 'است'), ('این', 'است', 'که'), ('است',), ('است', 'که'), ('است', 'که', 'نباید'), ('که',), ('که', 'نباید'), ('که', 'نباید', 'انتظار'), ('نباید',), ('نباید', 'انتظار'), ('نباید', 'انتظار', 'کار'), ('انتظار',), ('انتظار', 'کار'), ('انتظار', 'کار', 'ویژهای'), ('کار',), ('کار', 'ویژهای'), ('کار', 'ویژهای', 'را'), ('ویژهای',), ('ویژهای', 'را'), ('ویژهای', 'را', 'در'), ('را',), ('را', 'در'), ('را', 'در', 'مدت'), ('در',), ('در', 'مدت'), ('در', 'مدت', 'کوتاه'), ('مدت',), ('مدت', 'کوتاه'), ('مدت', 'کوتاه', 'داشت'), ('کوتاه',), ('کوتاه', 'داشت'), ('کوتاه', 'داشت', 'اما'), ('داشت',), ('داشت', 'اما'), ('داشت', 'اما', 'این'), ('اما',), ('اما', 'این'), ('اما', 'این', 'ریلگذاری'), ('این',), ('این', 'ریلگذاری'), ('این', 'ریلگذاری', 'ما'), ('ریلگذاری',), ('ریلگذاری', 'ما'), ('ریلگذاری', 'ما', 'را'), ('ما',), ('ما', 'را'), ('ما', 'را', 'به'), ('را',), ('را', 'به'), ('را', 'به', 'نقطه'), ('به',), ('به', 'نقطه'), ('به', 'نقطه', 'خوبی'), ('نقطه',), ('نقطه', 'خوبی'), ('نقطه', 'خوبی', 'خواهد_رساند'), ('خوبی',), ('خوبی', 'خواهد_رساند'), ('خوبی', 'خواهد_رساند', '</s>'), ('خواهد_رساند',), ('خواهد_رساند', '</s>'), ('خواهد_رساند', '</s>', '</s>'), ('</s>',), ('</s>', '</s>'), ('</s>',)]\n",
            "\n",
            "[('<s>',), ('<s>', '<s>'), ('<s>', '<s>', 'ارتفاع'), ('<s>',), ('<s>', 'ارتفاع'), ('<s>', 'ارتفاع', 'پست'), ('ارتفاع',), ('ارتفاع', 'پست'), ('ارتفاع', 'پست', 'ابراهیم'), ('پست',), ('پست', 'ابراهیم'), ('پست', 'ابراهیم', 'حاتمیکیا'), ('ابراهیم',), ('ابراهیم', 'حاتمیکیا'), ('ابراهیم', 'حاتمیکیا', 'هم'), ('حاتمیکیا',), ('حاتمیکیا', 'هم'), ('حاتمیکیا', 'هم', 'پسزمینه'), ('هم',), ('هم', 'پسزمینه'), ('هم', 'پسزمینه', 'جنگ'), ('پسزمینه',), ('پسزمینه', 'جنگ'), ('پسزمینه', 'جنگ', 'دارد'), ('جنگ',), ('جنگ', 'دارد'), ('جنگ', 'دارد', 'و'), ('دارد',), ('دارد', 'و'), ('دارد', 'و', 'پیامدهای'), ('و',), ('و', 'پیامدهای'), ('و', 'پیامدهای', 'جنگ'), ('پیامدهای',), ('پیامدهای', 'جنگ'), ('پیامدهای', 'جنگ', 'را'), ('جنگ',), ('جنگ', 'را'), ('جنگ', 'را', 'بر'), ('را',), ('را', 'بر'), ('را', 'بر', 'زندگی'), ('بر',), ('بر', 'زندگی'), ('بر', 'زندگی', 'مردم'), ('زندگی',), ('زندگی', 'مردم'), ('زندگی', 'مردم', 'خوزستان'), ('مردم',), ('مردم', 'خوزستان'), ('مردم', 'خوزستان', 'روایت'), ('خوزستان',), ('خوزستان', 'روایت'), ('خوزستان', 'روایت', 'می'), ('روایت',), ('روایت', 'می'), ('روایت', 'می', 'کند'), ('می',), ('می', 'کند'), ('می', 'کند', 'و'), ('کند',), ('کند', 'و'), ('کند', 'و', 'سرانجام'), ('و',), ('و', 'سرانجام'), ('و', 'سرانجام', 'بمب'), ('سرانجام',), ('سرانجام', 'بمب'), ('سرانجام', 'بمب', '؛'), ('بمب',), ('بمب', '؛'), ('بمب', '؛', 'یک'), ('؛',), ('؛', 'یک'), ('؛', 'یک', 'عاشقانه'), ('یک',), ('یک', 'عاشقانه'), ('یک', 'عاشقانه', 'پیمان'), ('عاشقانه',), ('عاشقانه', 'پیمان'), ('عاشقانه', 'پیمان', 'معادی'), ('پیمان',), ('پیمان', 'معادی'), ('پیمان', 'معادی', 'که'), ('معادی',), ('معادی', 'که'), ('معادی', 'که', 'داستان'), ('که',), ('که', 'داستان'), ('که', 'داستان', 'آن'), ('داستان',), ('داستان', 'آن'), ('داستان', 'آن', 'در'), ('آن',), ('آن', 'در'), ('آن', 'در', 'دوران'), ('در',), ('در', 'دوران'), ('در', 'دوران', 'موشکباران'), ('دوران',), ('دوران', 'موشکباران'), ('دوران', 'موشکباران', 'شهرها'), ('موشکباران',), ('موشکباران', 'شهرها'), ('موشکباران', 'شهرها', 'روایت'), ('شهرها',), ('شهرها', 'روایت'), ('شهرها', 'روایت', 'می'), ('روایت',), ('روایت', 'می'), ('روایت', 'می', 'شود'), ('می',), ('می', 'شود'), ('می', 'شود', '</s>'), ('شود',), ('شود', '</s>'), ('شود', '</s>', '</s>'), ('</s>',), ('</s>', '</s>'), ('</s>',)]\n",
            "\n",
            "[('<s>',), ('<s>', '<s>'), ('<s>', '<s>', 'وی'), ('<s>',), ('<s>', 'وی'), ('<s>', 'وی', 'ادامه'), ('وی',), ('وی', 'ادامه'), ('وی', 'ادامه', 'داد'), ('ادامه',), ('ادامه', 'داد'), ('ادامه', 'داد', 'این'), ('داد',), ('داد', 'این'), ('داد', 'این', 'مسیر'), ('این',), ('این', 'مسیر'), ('این', 'مسیر', 'به'), ('مسیر',), ('مسیر', 'به'), ('مسیر', 'به', 'علت'), ('به',), ('به', 'علت'), ('به', 'علت', 'پایین'), ('علت',), ('علت', 'پایین'), ('علت', 'پایین', 'آمدن'), ('پایین',), ('پایین', 'آمدن'), ('پایین', 'آمدن', 'چند'), ('آمدن',), ('آمدن', 'چند'), ('آمدن', 'چند', 'قطعه'), ('چند',), ('چند', 'قطعه'), ('چند', 'قطعه', 'سنگ'), ('قطعه',), ('قطعه', 'سنگ'), ('قطعه', 'سنگ', 'بزرگ'), ('سنگ',), ('سنگ', 'بزرگ'), ('سنگ', 'بزرگ', 'بر'), ('بزرگ',), ('بزرگ', 'بر'), ('بزرگ', 'بر', 'اثر'), ('بر',), ('بر', 'اثر'), ('بر', 'اثر', 'برخورد'), ('اثر',), ('اثر', 'برخورد'), ('اثر', 'برخورد', 'صاعقه'), ('برخورد',), ('برخورد', 'صاعقه'), ('برخورد', 'صاعقه', 'با'), ('صاعقه',), ('صاعقه', 'با'), ('صاعقه', 'با', 'کوه'), ('با',), ('با', 'کوه'), ('با', 'کوه', 'مسدود'), ('کوه',), ('کوه', 'مسدود'), ('کوه', 'مسدود', 'شده_است'), ('مسدود',), ('مسدود', 'شده_است'), ('مسدود', 'شده_است', 'و'), ('شده_است',), ('شده_است', 'و'), ('شده_است', 'و', 'در'), ('و',), ('و', 'در'), ('و', 'در', 'سایه'), ('در',), ('در', 'سایه'), ('در', 'سایه', 'تلاش'), ('سایه',), ('سایه', 'تلاش'), ('سایه', 'تلاش', 'راهدارای'), ('تلاش',), ('تلاش', 'راهدارای'), ('تلاش', 'راهدارای', 'و'), ('راهدارای',), ('راهدارای', 'و'), ('راهدارای', 'و', 'جابهجایی'), ('و',), ('و', 'جابهجایی'), ('و', 'جابهجایی', 'سنگهای'), ('جابهجایی',), ('جابهجایی', 'سنگهای'), ('جابهجایی', 'سنگهای', 'کوچک'), ('سنگهای',), ('سنگهای', 'کوچک'), ('سنگهای', 'کوچک', 'این'), ('کوچک',), ('کوچک', 'این'), ('کوچک', 'این', 'راه'), ('این',), ('این', 'راه'), ('این', 'راه', 'روستایی'), ('راه',), ('راه', 'روستایی'), ('راه', 'روستایی', 'به'), ('روستایی',), ('روستایی', 'به'), ('روستایی', 'به', 'صورت'), ('به',), ('به', 'صورت'), ('به', 'صورت', 'موقت'), ('صورت',), ('صورت', 'موقت'), ('صورت', 'موقت', 'و'), ('موقت',), ('موقت', 'و'), ('موقت', 'و', 'کنارگذر'), ('و',), ('و', 'کنارگذر'), ('و', 'کنارگذر', 'بازگشایی'), ('کنارگذر',), ('کنارگذر', 'بازگشایی'), ('کنارگذر', 'بازگشایی', 'شده_است'), ('بازگشایی',), ('بازگشایی', 'شده_است'), ('بازگشایی', 'شده_است', '</s>'), ('شده_است',), ('شده_است', '</s>'), ('شده_است', '</s>', '</s>'), ('</s>',), ('</s>', '</s>'), ('</s>',)]\n",
            "\n",
            "[('<s>',), ('<s>', '<s>'), ('<s>', '<s>', 'اساسا'), ('<s>',), ('<s>', 'اساسا'), ('<s>', 'اساسا', 'حمایت'), ('اساسا',), ('اساسا', 'حمایت'), ('اساسا', 'حمایت', 'از'), ('حمایت',), ('حمایت', 'از'), ('حمایت', 'از', 'بخش'), ('از',), ('از', 'بخش'), ('از', 'بخش', 'کشاورزی'), ('بخش',), ('بخش', 'کشاورزی'), ('بخش', 'کشاورزی', 'و'), ('کشاورزی',), ('کشاورزی', 'و'), ('کشاورزی', 'و', 'غذا'), ('و',), ('و', 'غذا'), ('و', 'غذا', 'به'), ('غذا',), ('غذا', 'به'), ('غذا', 'به', 'لحاظ'), ('به',), ('به', 'لحاظ'), ('به', 'لحاظ', 'مبانی'), ('لحاظ',), ('لحاظ', 'مبانی'), ('لحاظ', 'مبانی', 'تئوریک'), ('مبانی',), ('مبانی', 'تئوریک'), ('مبانی', 'تئوریک', 'اجتناب'), ('تئوریک',), ('تئوریک', 'اجتناب'), ('تئوریک', 'اجتناب', 'ناپذیر'), ('اجتناب',), ('اجتناب', 'ناپذیر'), ('اجتناب', 'ناپذیر', 'است'), ('ناپذیر',), ('ناپذیر', 'است'), ('ناپذیر', 'است', '</s>'), ('است',), ('است', '</s>'), ('است', '</s>', '</s>'), ('</s>',), ('</s>', '</s>'), ('</s>',)]\n",
            "\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "n=3\n",
        "\n",
        "# Train data is an iterator over the pre-processed input\n",
        "train_data, padded_sents = padded_everygram_pipeline(n, train_corpus)\n",
        "\n",
        "model = MLE(n)\n",
        "model.fit(train_data, padded_sents)"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-11T15:53:29.242050Z",
          "iopub.status.busy": "2024-12-11T15:53:29.241799Z",
          "iopub.status.idle": "2024-12-11T15:54:02.224218Z",
          "shell.execute_reply": "2024-12-11T15:54:02.223189Z",
          "shell.execute_reply.started": "2024-12-11T15:53:29.242025Z"
        },
        "trusted": true,
        "id": "0HgY7n8rkM1r"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"\\nVocabulary:{model.vocab}\\n\")\n",
        "print(f\"\\nMost Common Vocabs:{model.vocab.counts.most_common(50)}\\n\")\n",
        "print(f\"\\nLeast Common Vocabs:{model.vocab.counts.most_common()[-50:]}\\n\")"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-11T15:54:02.225683Z",
          "iopub.status.busy": "2024-12-11T15:54:02.225412Z",
          "iopub.status.idle": "2024-12-11T15:54:02.265202Z",
          "shell.execute_reply": "2024-12-11T15:54:02.264194Z",
          "shell.execute_reply.started": "2024-12-11T15:54:02.225656Z"
        },
        "trusted": true,
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "Ft6RCl4nkM1r",
        "outputId": "78bccee6-156b-412f-e6a7-4e7adad7c9ef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Vocabulary:<Vocabulary with cutoff=1 unk_label='<UNK>' and 55596 items>\n",
            "\n",
            "\n",
            "Most Common Vocabs:[('<s>', 160000), ('</s>', 160000), ('و', 80719), ('در', 68527), ('به', 57179), ('از', 46674), ('این', 36084), ('که', 35697), ('می', 30555), ('را', 28863), ('با', 27374), ('است', 18993), ('برای', 13186), ('کرد', 10405), ('های', 9607), ('شود', 9191), ('یک', 8464), ('هم', 8270), ('آن', 7960), ('تا', 7281), ('گفت', 7094), ('شد', 7079), ('خود', 6456), ('بر', 6087), ('کند', 5926), ('وی', 5505), ('ایران', 5451), ('ما', 5314), ('سال', 5265), ('کشور', 5088), ('ها', 5024), ('نیز', 4921), ('باید', 4874), ('اما', 4793), ('دارد', 4758), ('کنند', 4755), ('کرونا', 4622), ('بود', 4471), ('او', 4449), ('؟', 4187), ('شده', 4133), ('مردم', 4115), ('داد', 4090), ('استان', 3984), ('قرار', 3791), ('روز', 3528), ('یا', 3503), ('اینکه', 3433), ('آنها', 3430), ('نمی', 3360)]\n",
            "\n",
            "\n",
            "Least Common Vocabs:[('ورشوه', 1), ('چکارمیکنن', 1), ('روچه', 1), ('روو', 1), ('آمادگیاش', 1), ('بوردو', 1), ('۶۱۳', 1), ('نینوی', 1), ('سرطانزادیی', 1), ('چاپگرهای', 1), ('حقا', 1), ('جهانپوری', 1), ('مقابلت', 1), ('سیداحد', 1), ('یوزباشی', 1), ('آبرومندانهتر', 1), ('سرگیرند', 1), ('کوچولوهای', 1), ('بهانهگیر', 1), ('دزدیده_شد', 1), ('پایگاهایش', 1), ('حتیالامکان', 1), ('کنگیها', 1), ('گچپزان', 1), ('بسته_نشد', 1), ('گزارشهایشان', 1), ('رسمیتر', 1), ('علنیتر', 1), ('دفترآیتالله', 1), ('دشنام', 1), ('نامتناسب', 1), ('غیرقابلتصور', 1), ('پایانناپذیر', 1), ('ادعاهایمان', 1), ('پران', 1), ('نگرشهای', 1), ('خواهد_نقش', 1), ('۰۲۵۳۷۸۴۱۱۳۰', 1), ('۰۲۵۳۷۸۴۱۱۳۱', 1), ('سوختکی', 1), ('پرسشگر', 1), ('ایولین', 1), ('دروازهبانان', 1), ('نفعمان', 1), ('کاردستیمان', 1), ('پرچمهایی', 1), ('تورات', 1), ('ونژاد', 1), ('علیفر', 1), ('نفروشد', 1)]\n",
            "\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.counts)\n",
        "#('دانشگاه', 'علوم', 'پزشکی'): 397\n",
        "\n",
        "# counts for unigrams:\n",
        "print(model.counts['پزشکی']) # i.e. Count('not')\n",
        "\n",
        "# count for bigrams\n",
        "print(model.counts[['علوم']]['پزشکی']) # i.e. Count('not'|'was')\n",
        "\n",
        "# count for trigrams\n",
        "print(model.counts[['دانشگاه', 'علوم']]['پزشکی']) # i.e. Count('not'|'emma was')"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-09T18:52:59.569574Z",
          "iopub.status.busy": "2024-12-09T18:52:59.569242Z",
          "iopub.status.idle": "2024-12-09T18:52:59.902485Z",
          "shell.execute_reply": "2024-12-09T18:52:59.901588Z",
          "shell.execute_reply.started": "2024-12-09T18:52:59.569547Z"
        },
        "trusted": true,
        "id": "nZQQ_nRmkM1r",
        "outputId": "0fdb485b-5a60-4104-ae58-8507a902aa70"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<NgramCounter with 3 ngram orders and 6485628 ngrams>\n",
            "1033\n",
            "475\n",
            "397\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "all_tokens = [tok for sent in train_corpus for tok in sent]\n",
        "num_tokens = len(all_tokens)\n",
        "num_sentences = len(train_corpus)\n",
        "\n",
        "model_score = model.score('دانشگاه')\n",
        "probability = model.counts['دانشگاه']/num_tokens\n",
        "\n",
        "\n",
        "print(\"\\nProbability of the word 'دانشگاه'\")\n",
        "print(\"{:.5f}\".format(model_score))\n",
        "print(\"{:.5f}\".format(probability))\n",
        "\n",
        "print(\"\\nAdjust for padding tokens\")\n",
        "all_padding_tokens = num_sentences * (n-1) * 2\n",
        "print(num_tokens, all_padding_tokens)\n",
        "\n",
        "adjusted_probability = model.counts['دانشگاه']/(num_tokens + all_padding_tokens)\n",
        "print(\"{:.5f}\".format(adjusted_probability))\n",
        "\n",
        "print(\"\\nProbabilities padding tokens\")\n",
        "print(\"{:.5f}\".format(model.score('<s>')))\n",
        "print(\"{:.5f}\".format(model.score('</s>')))"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-11T19:13:08.731069Z",
          "iopub.status.busy": "2024-12-11T19:13:08.730398Z",
          "iopub.status.idle": "2024-12-11T19:13:08.970854Z",
          "shell.execute_reply": "2024-12-11T19:13:08.969900Z",
          "shell.execute_reply.started": "2024-12-11T19:13:08.731026Z"
        },
        "trusted": true,
        "id": "s89XTuzwkM1r",
        "outputId": "e9983099-44e4-4f57-b324-d8f399f7d983"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'train_corpus' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m all_tokens \u001b[38;5;241m=\u001b[39m [tok \u001b[38;5;28;01mfor\u001b[39;00m sent \u001b[38;5;129;01min\u001b[39;00m \u001b[43mtrain_corpus\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m tok \u001b[38;5;129;01min\u001b[39;00m sent]\n\u001b[1;32m      2\u001b[0m num_tokens \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(all_tokens)\n\u001b[1;32m      3\u001b[0m num_sentences \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(train_corpus)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_corpus' is not defined"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# bigram\n",
        "print(model.score('پزشکی', ['علوم']))  # P('not'|'is')\n",
        "\n",
        "# trigram\n",
        "print(model.score('پزشکی', ['دانشگاه', 'علوم']))  # P('not'|'emma is')"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-11T19:13:13.882267Z",
          "iopub.status.busy": "2024-12-11T19:13:13.881932Z",
          "iopub.status.idle": "2024-12-11T19:13:13.900927Z",
          "shell.execute_reply": "2024-12-11T19:13:13.899784Z",
          "shell.execute_reply.started": "2024-12-11T19:13:13.882237Z"
        },
        "trusted": true,
        "id": "-y_dl5qUkM1s",
        "outputId": "a72b670e-2a93-4c74-d48e-1547bd78782d"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'model' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# bigram\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mscore(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mپزشکی\u001b[39m\u001b[38;5;124m'\u001b[39m, [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mعلوم\u001b[39m\u001b[38;5;124m'\u001b[39m]))  \u001b[38;5;66;03m# P('not'|'is')\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# trigram\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(model\u001b[38;5;241m.\u001b[39mscore(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mپزشکی\u001b[39m\u001b[38;5;124m'\u001b[39m, [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mدانشگاه\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mعلوم\u001b[39m\u001b[38;5;124m'\u001b[39m]))  \u001b[38;5;66;03m# P('not'|'emma is')\u001b[39;00m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# To avoid underflow when working with many small score values, we usually work with log probabilities instead.\n",
        "# This can be done with the `logscore` method.\n",
        "\n",
        "#('هزار', 'نفر'): 690\n",
        "print(model.score('نفر', ['هزار']))\n",
        "print(model.logscore('نفر', ['هزار']))"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-09T18:53:00.071091Z",
          "iopub.status.busy": "2024-12-09T18:53:00.070838Z",
          "iopub.status.idle": "2024-12-09T18:53:00.079399Z",
          "shell.execute_reply": "2024-12-09T18:53:00.078664Z",
          "shell.execute_reply.started": "2024-12-09T18:53:00.071067Z"
        },
        "trusted": true,
        "id": "RPIyks-ikM1s",
        "outputId": "2dc4940a-4146-4dc1-f000-c6422da621cc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.09771689497716896\n",
            "-3.3552481680873885\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# The vocabulary helps us handle words that have not occurred during training.\n",
        "# If we lookup the vocab on unseen sentences not from the training data,\n",
        "# it automatically replace words not in the vocabulary with `<UNK>`.\n",
        "\n",
        "print(model.vocab.lookup('در دانشگاه علوم پزشکی موژان قدم می زند'.split()))"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-11T19:13:23.666480Z",
          "iopub.status.busy": "2024-12-11T19:13:23.665889Z",
          "iopub.status.idle": "2024-12-11T19:13:23.683363Z",
          "shell.execute_reply": "2024-12-11T19:13:23.682257Z",
          "shell.execute_reply.started": "2024-12-11T19:13:23.666445Z"
        },
        "trusted": true,
        "id": "_pqzt0j1kM1s",
        "outputId": "145efc84-4409-43ad-8adc-23ad60c0697e"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'model' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[3], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# The vocabulary helps us handle words that have not occurred during training.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# If we lookup the vocab on unseen sentences not from the training data,\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# it automatically replace words not in the vocabulary with `<UNK>`.\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mvocab\u001b[38;5;241m.\u001b[39mlookup(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mدر دانشگاه علوم پزشکی موژان قدم می زند\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39msplit()))\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Items that are not seen during training are mapped to the vocabulary's \"unknown label\" token.  This is \"<UNK>\" by default.\n",
        "print(model.score(\"<UNK>\") == model.score(\"موژان\"))\n",
        "\n",
        "# The MLE model does not apply any smoothing, so the probability for UNK is 0\n",
        "print(model.score(\"<UNK>\"),model.logscore(\"<UNK>\") )\n",
        "\n",
        "# As a consequence, the probability for a phrase containing an unknown word is also 0.\n",
        "print(model.score('موژان', ['علوم', 'پزشکی']), model.logscore('موژان', ['علوم', 'پزشکی']))"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-09T18:53:00.090995Z",
          "iopub.status.busy": "2024-12-09T18:53:00.090754Z",
          "iopub.status.idle": "2024-12-09T18:53:00.103989Z",
          "shell.execute_reply": "2024-12-09T18:53:00.103265Z",
          "shell.execute_reply.started": "2024-12-09T18:53:00.090971Z"
        },
        "trusted": true,
        "id": "BZ543bGikM1s",
        "outputId": "e4e7bcd4-2990-41da-e250-873364277f2e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True\n",
            "0.0 -inf\n",
            "0.0 -inf\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.lm import Laplace\n",
        "n = 5\n",
        "train_data, padded_sents = padded_everygram_pipeline(n, train_corpus)\n",
        "smoothed_model_small =  Laplace(n)\n",
        "smoothed_model_small.fit(train_data, padded_sents)\n",
        "\n",
        "print(smoothed_model_small.score('علوم'))\n",
        "print(smoothed_model_small.score('پزشکی'))\n",
        "print(smoothed_model_small.score('موژان', ['علوم', 'پزشکی']))\n",
        "print()\n",
        "print(smoothed_model_small.logscore('علوم'))\n",
        "print(smoothed_model_small.logscore('پزشکی'))\n",
        "print(smoothed_model_small.logscore('موژان', ['علوم', 'پزشکی']))"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-09T18:53:00.105229Z",
          "iopub.status.busy": "2024-12-09T18:53:00.104900Z",
          "iopub.status.idle": "2024-12-09T18:54:20.173357Z",
          "shell.execute_reply": "2024-12-09T18:54:20.172448Z",
          "shell.execute_reply.started": "2024-12-09T18:53:00.105190Z"
        },
        "trusted": true,
        "id": "E7vQX7YokM1s",
        "outputId": "35a2b58b-c350-4e66-c953-1ab1fd3c0f64"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.00025673627072228473\n",
            "0.0003950376546530393\n",
            "1.7834531219346898e-05\n",
            "\n",
            "-11.927425250778018\n",
            "-11.305722203241844\n",
            "-15.774967179372865\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# generating text with n-gram model\n",
        "smoothed_model_small.generate(text_seed=[\"در\", \"دانشگاه\", \"علوم\", \"پزشکی\"], num_words=40, random_seed=5)"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-09T18:54:20.175014Z",
          "iopub.status.busy": "2024-12-09T18:54:20.174622Z",
          "iopub.status.idle": "2024-12-09T18:54:20.182616Z",
          "shell.execute_reply": "2024-12-09T18:54:20.181745Z",
          "shell.execute_reply.started": "2024-12-09T18:54:20.174972Z"
        },
        "trusted": true,
        "id": "W9nLawX7kM1t",
        "outputId": "801f7191-7c13-4170-a4fb-bf2472aeca81"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['شیراز',\n",
              " 'در',\n",
              " 'پاسخ',\n",
              " 'به',\n",
              " 'پرسش',\n",
              " 'یکی',\n",
              " 'از',\n",
              " 'دانشجویان',\n",
              " 'مبنی',\n",
              " 'بر',\n",
              " 'آنکه',\n",
              " 'آیا',\n",
              " 'شما',\n",
              " 'هویدا',\n",
              " 'را',\n",
              " 'پیش',\n",
              " 'از',\n",
              " 'محاکمه',\n",
              " 'زدید',\n",
              " 'گفت',\n",
              " 'این',\n",
              " 'دروغ',\n",
              " 'است',\n",
              " '</s>',\n",
              " '</s>',\n",
              " '</s>',\n",
              " '</s>',\n",
              " '</s>',\n",
              " '</s>',\n",
              " '</s>',\n",
              " '</s>',\n",
              " '</s>',\n",
              " '</s>',\n",
              " '</s>',\n",
              " '</s>',\n",
              " '</s>',\n",
              " '</s>',\n",
              " '</s>',\n",
              " '</s>',\n",
              " '</s>']"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# perplexity of n-gram model\n",
        "test_data, _ = padded_everygram_pipeline(n, val_corpus)\n",
        "\n",
        "perplexity = []\n",
        "for test in test_data:\n",
        "  perplexity.append(smoothed_model_small.perplexity(test))\n",
        "\n",
        "values = []\n",
        "for i in range(len(perplexity)):\n",
        "  if not np.isinf(perplexity[i]):\n",
        "    values.append(i)\n",
        "\n",
        "valid_perplexity = [perplexity[i] for i in values]\n",
        "idx = np.argpartition(valid_perplexity, 10)\n",
        "\n",
        "min = np.argmin(valid_perplexity)\n",
        "print(perplexity[min])\n",
        "print(val_corpus[min])"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-09T18:54:20.184040Z",
          "iopub.status.busy": "2024-12-09T18:54:20.183746Z",
          "iopub.status.idle": "2024-12-09T18:54:30.868406Z",
          "shell.execute_reply": "2024-12-09T18:54:30.867573Z",
          "shell.execute_reply.started": "2024-12-09T18:54:20.184013Z"
        },
        "trusted": true,
        "id": "du9zY6QhkM1t",
        "outputId": "b0556868-551d-49c0-b667-e52c26b5e3ce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "136.84879397221403\n",
            "['بیشتر', 'استفاده', 'شود']\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the list to a NumPy array\n",
        "values_array = np.array(perplexity)\n",
        "\n",
        "# Get the indices that would sort the array\n",
        "sorted_indices = np.argsort(values_array)\n",
        "\n",
        "# Get the first 10 indices of the smallest values\n",
        "top_20_indices = sorted_indices[:20]"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-09T18:54:30.870236Z",
          "iopub.status.busy": "2024-12-09T18:54:30.869603Z",
          "iopub.status.idle": "2024-12-09T18:54:30.875039Z",
          "shell.execute_reply": "2024-12-09T18:54:30.874111Z",
          "shell.execute_reply.started": "2024-12-09T18:54:30.870195Z"
        },
        "trusted": true,
        "id": "i3QVJSZUkM1t"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "for i in top_20_indices:\n",
        "  print(\"({0}):{1}\".format(val_corpus[i], perplexity[i]))"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-09T18:54:30.876318Z",
          "iopub.status.busy": "2024-12-09T18:54:30.876066Z",
          "iopub.status.idle": "2024-12-09T18:54:30.889969Z",
          "shell.execute_reply": "2024-12-09T18:54:30.889229Z",
          "shell.execute_reply.started": "2024-12-09T18:54:30.876293Z"
        },
        "trusted": true,
        "id": "TlWEZNG9kM1t",
        "outputId": "0abf1a58-dd5d-4ad9-e980-4fa2ea66931c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(['بیشتر', 'استفاده', 'شود']):136.84879397221403\n",
            "(['۴', 'درصد', 'بوده_است']):137.37757536063077\n",
            "(['در', 'نظر', 'گرفتهایم']):155.21181914518752\n",
            "(['۲', 'درصد', 'اعلام', 'شد']):159.41539629904034\n",
            "(['۹', 'درصد', 'افزایش', 'است']):167.88098852565022\n",
            "(['۸', 'درصد', 'افزایش', 'داشته_است']):175.70886198671326\n",
            "(['۹', 'درصد', 'اعلام', 'شد']):183.26984989234003\n",
            "(['به', 'گزارش', 'همشهری', 'آنلاین', 'به', 'نقل', 'از', 'نشریه', 'آ']):188.5691340823012\n",
            "(['اینجا', 'چطور', 'است', '؟']):193.56459410705116\n",
            "(['آن', 'را', 'پیدا', 'کنید']):193.70443425101107\n",
            "(['۶', 'درصد', 'افزایش', 'داشته_است']):200.6723100682942\n",
            "(['این', 'سیاست', 'استکباری', 'است']):201.01668563197362\n",
            "(['۶', 'درصد', 'رشد', 'داشته_است']):204.0636579908888\n",
            "(['این', 'خسارت', 'همچنان', 'ادامه', 'دارد']):204.44801120950063\n",
            "(['در', 'همین', 'رابطه', 'بخوانید', '؛']):206.89433492071743\n",
            "(['۵', 'درصد', 'رشد', 'نشان', 'می', 'دهد']):212.98259222906185\n",
            "(['این', 'زمان', 'زیادی', 'نیست']):214.94726810950934\n",
            "(['در', 'جلسات', 'اطلاعاتی', 'مطرح', 'می', 'شود']):216.3339858482399\n",
            "(['۶', 'درصد', 'برآورد', 'شده_است']):218.54417523894674\n",
            "(['۵', 'متقاضی', 'وجود', 'دارد']):218.71649941201267\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# NN model"
      ],
      "metadata": {
        "id": "kb63rn4vkM1t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# formatted text is the preprocessed text in the format of raw text\n",
        "# but it does not work (change it if you can :))\n",
        "formatted_text = \"\\n\".join([f\"{i+1}\\t{' '.join(sentence)}\" for i, sentence in enumerate(cleaned_sentences)])\n",
        "\n",
        "print(\"Total number of character:\", len(formatted_text))\n",
        "print(type(formatted_text))\n",
        "print(formatted_text[:1000])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-12-12T08:22:41.707456Z",
          "iopub.execute_input": "2024-12-12T08:22:41.708307Z",
          "iopub.status.idle": "2024-12-12T08:22:42.150532Z",
          "shell.execute_reply.started": "2024-12-12T08:22:41.708273Z",
          "shell.execute_reply": "2024-12-12T08:22:42.149608Z"
        },
        "trusted": true,
        "id": "F4IYNq1hkM1u",
        "outputId": "1f224b72-990b-45ed-bbf4-607aea1e3504"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Total number of character: 19998594\n<class 'str'>\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "with open(persian_text_path, \"r\", encoding=\"utf-8\") as f:\n",
        "    raw_text = f.read()\n",
        "print((raw_text[:1000]))"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-12T08:25:44.165586Z",
          "iopub.execute_input": "2024-12-12T08:25:44.166291Z",
          "iopub.status.idle": "2024-12-12T08:25:44.254159Z",
          "shell.execute_reply.started": "2024-12-12T08:25:44.166254Z",
          "shell.execute_reply": "2024-12-12T08:25:44.253238Z"
        },
        "id": "f9iQi-J_kM1u",
        "outputId": "9ebb300d-f64f-4a4b-cac1-7bb2651b3a47"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "1\t۰۰۰ پرس غذا برگزار خواهد گردید که با توجه به شرایط کرونایی کشور همه این غذاها در سطح شهر و مناطق محروم توزیع خواهد گردید.\n2\t۰۰۰ تن تجهیزات و متریال، بیش از ۱۱۰ کیلومتر کابلکشی و ۵۰ کیلومتر لولهکشی در سایزهای مختلف برشمرد که نشاندهنده وسعت این طرح ملی است.\n3\t۰۰۰ ریال بابت خرید ۱۲.\n4\t۰۰۰ ریال) تجاوز ننماید، با رعایت مقررات بند (۱-۴) ماده (۴۱) آئین نامه اجرایی موضوع ماده (۲۱۹) قانون مالیاتهای مستقیم نسبت به محاسبه و مطالبه مابه التفاوت مالیات متعلقه با رعایت مقررات اقدام خواهد شد.\n5\t۰۰۰ ریال تسویه شده است.\n6\t۰۰۰ریال را میگفتن ۱۰۰.\n7\t۰۰۰) ریال که در حال بازپرداخت اقساط باشند.\n8\t۰۰۰ نفر استقبال کردند.\"\n9\t۰۱۶ یوان چین اعلام شد.\n10\t۰۱ درصد سهم سبد سوخت کشور کرده است که با توجه به تولید فعلی سالانه ۱۷ میلیون تن LPG و شرایط تحریم و عدم صادرات کامل تولید مازاد بر مصرف، چارهای جز مصرف LPG در خودرو و مصرف در پتروشیمیهای PDH نیست.\n11\t۰۱) مجاز بوده و بخشنامه جدید جایگزین بخشنامه های متناظر قبلی کارمزدهای خدمات بانکی ریالی و الکترونیکی می شود.\n12\t۰۲ درصد افزایش به ۱۰۵.\n13\t۰۳ دلار کاهش ۱۸۹۲.\n14\t۰۴ ه\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the tokenizer\n",
        "# tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "\n",
        "# bolbolzaban is a persian tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained('bolbolzaban/gpt2-persian')\n",
        "\n",
        "# Tokenize the text\n",
        "token_ids = tokenizer.encode(raw_text)\n",
        "\n",
        "print(\"Total number of tokens:\", len(token_ids))\n",
        "print(\"First 10 tokens:\", token_ids[:10])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-12-12T07:47:11.114635Z",
          "iopub.execute_input": "2024-12-12T07:47:11.115485Z",
          "iopub.status.idle": "2024-12-12T07:47:29.437147Z",
          "shell.execute_reply.started": "2024-12-12T07:47:11.115445Z",
          "shell.execute_reply": "2024-12-12T07:47:29.436219Z"
        },
        "trusted": true,
        "id": "UOV_LS4_kM1u",
        "outputId": "11d42699-0773-4c14-b7d1-a457c90cd4da"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Total number of tokens: 3456103\nFirst 10 tokens: [5, 43, 24935, 17, 17, 17, 4961, 1626, 383, 137]\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "class GPTDataset(Dataset):\n",
        "    def __init__(self, txt, tokenizer, context_length):\n",
        "        self.input_ids = []\n",
        "        self.target_ids = []\n",
        "\n",
        "        # Tokenize the entire text\n",
        "        token_ids = tokenizer.encode(txt)\n",
        "\n",
        "        # Use a sliding window to chunk the book into overlapping sequences of context_length\n",
        "        for i in range(0, len(token_ids) - context_length):\n",
        "            input_sequence = token_ids[i:i + context_length]\n",
        "\n",
        "            #shift to the right\n",
        "            target_sequence = token_ids[i + 1: i + context_length + 1]\n",
        "\n",
        "            # input and output are represented as tensors\n",
        "            self.input_ids.append(torch.tensor(input_sequence))\n",
        "            self.target_ids.append(torch.tensor(target_sequence))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.input_ids)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.input_ids[idx], self.target_ids[idx]\n",
        "\n",
        "def create_dataloader(txt, batch_size=8, context_length=4, shuffle=True, drop_last=True,\n",
        "                         num_workers=0):\n",
        "\n",
        "    # Initialize the tokenizer\n",
        "    # tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "    tokenizer = AutoTokenizer.from_pretrained('bolbolzaban/gpt2-persian')\n",
        "\n",
        "    # Create dataset\n",
        "    dataset = GPTDataset(txt, tokenizer, context_length)\n",
        "    train, dev, test = torch.utils.data.random_split(dataset, [0.8,0.1,0.1])\n",
        "\n",
        "    # Create dataloader\n",
        "    train_dataloader = DataLoader(\n",
        "        train,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=shuffle,\n",
        "        drop_last=drop_last,\n",
        "        num_workers=num_workers\n",
        "    )\n",
        "\n",
        "    dev_dataloader = DataLoader(\n",
        "        dev,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=shuffle,\n",
        "        drop_last=drop_last,\n",
        "        num_workers=num_workers\n",
        "    )\n",
        "    test_dataloader = DataLoader(\n",
        "        test,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=shuffle,\n",
        "        drop_last=drop_last,\n",
        "        num_workers=num_workers\n",
        "    )\n",
        "    return train_dataloader, dev_dataloader, test_dataloader"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-12-12T07:48:01.402764Z",
          "iopub.execute_input": "2024-12-12T07:48:01.403137Z",
          "iopub.status.idle": "2024-12-12T07:48:01.412337Z",
          "shell.execute_reply.started": "2024-12-12T07:48:01.403108Z",
          "shell.execute_reply": "2024-12-12T07:48:01.411393Z"
        },
        "trusted": true,
        "id": "xjR7klwkkM1u"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## simple nn model"
      ],
      "metadata": {
        "id": "xvkgTQiQkM1v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleLanguageModel(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, context_length):\n",
        "        super(SimpleLanguageModel, self).__init__()\n",
        "        self.token_embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.position_embedding = nn.Embedding(context_length, embedding_dim)\n",
        "        self.linear = nn.Linear(embedding_dim, vocab_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        positions = torch.arange(0, x.size(1), device=x.device).unsqueeze(0)\n",
        "        token_embeds = self.token_embedding(x)\n",
        "        position_embeds = self.position_embedding(positions)\n",
        "\n",
        "        embeddings = token_embeds + position_embeds\n",
        "        logits = self.linear(embeddings)\n",
        "        return logits"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-09T18:54:51.958205Z",
          "iopub.status.busy": "2024-12-09T18:54:51.957946Z",
          "iopub.status.idle": "2024-12-09T18:54:51.974124Z",
          "shell.execute_reply": "2024-12-09T18:54:51.973528Z",
          "shell.execute_reply.started": "2024-12-09T18:54:51.958180Z"
        },
        "trusted": true,
        "id": "P3-z5NufkM1v"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## regularized nn model"
      ],
      "metadata": {
        "id": "dmmPPYUakM1v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RegularizedLanguageModel(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, context_length, dropout=0.2):\n",
        "        super(RegularizedLanguageModel, self).__init__()\n",
        "        self.token_embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.position_embedding = nn.Embedding(context_length, embedding_dim)\n",
        "        # This is new!\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.linear = nn.Linear(embedding_dim, vocab_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        positions = torch.arange(0, x.size(1), device=x.device).unsqueeze(0)\n",
        "        token_embeds = self.token_embedding(x)\n",
        "        position_embeds = self.position_embedding(positions)\n",
        "\n",
        "        embeddings = token_embeds + position_embeds\n",
        "        embeddings = self.dropout(embeddings)\n",
        "        logits = self.linear(embeddings)\n",
        "        return logits"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-11T13:41:52.081912Z",
          "iopub.status.busy": "2024-12-11T13:41:52.081560Z",
          "iopub.status.idle": "2024-12-11T13:41:52.088396Z",
          "shell.execute_reply": "2024-12-11T13:41:52.087414Z",
          "shell.execute_reply.started": "2024-12-11T13:41:52.081882Z"
        },
        "trusted": true,
        "id": "1HMZryLukM1v"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## setting up hyperparameters"
      ],
      "metadata": {
        "id": "2fEmJjZbmZuU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "# Parameters\n",
        "batch_size = 128\n",
        "context_length = 32  # Context size for training\n",
        "# vocab_size = tokenizer.n_vocab\n",
        "vocab_size = 30000\n",
        "embedding_dim = 128\n",
        "\n",
        "# Create the DataLoader\n",
        "train_dataloader, dev_dataloader, test_dataloader = create_dataloader(\n",
        "    raw_text[:9999297], batch_size=batch_size,\n",
        "    context_length=context_length, shuffle=True\n",
        ")"
      ],
      "metadata": {
        "id": "zjYW3poLl8CJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## If you want to see the result for any of the models below. Select the cell with the name of the model and run it, then run other cells below."
      ],
      "metadata": {
        "id": "hvDOS8VUnz8G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## setting up and training the simple model"
      ],
      "metadata": {
        "id": "nOTzrMv4nP4M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the model\n",
        "model = SimpleLanguageModel(vocab_size, embedding_dim, context_length).to(device)\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Training loop parameters\n",
        "num_epochs = 1"
      ],
      "metadata": {
        "id": "aWcNbinYnKVl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## setting up and training the regularized model"
      ],
      "metadata": {
        "id": "DMt__AqvkM1w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the model\n",
        "model = RegularizedLanguageModel(vocab_size, embedding_dim, context_length).to(device)\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Training loop parameters\n",
        "num_epochs = 1"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-12-12T07:52:21.077059Z",
          "iopub.execute_input": "2024-12-12T07:52:21.077410Z"
        },
        "trusted": true,
        "id": "9FZESFcdkM1w"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plotting the Loss and Perplexity"
      ],
      "metadata": {
        "id": "jZt7uzBBkM1w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_losses = []\n",
        "perplexities = []\n",
        "\n",
        "# Go through learning epochs\n",
        "for epoch in range(num_epochs):\n",
        "    total_loss = 0\n",
        "    model.train()\n",
        "\n",
        "    # Read in data in batches\n",
        "    for batch_idx, (x, y) in enumerate(train_dataloader):\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "\n",
        "        # Reset the gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Apply the forward pass\n",
        "        logits = model(x)\n",
        "\n",
        "        # Reshape logits and labels\n",
        "        token_logits = logits.view(-1, vocab_size)\n",
        "        token_labels = y.view(-1)\n",
        "\n",
        "        # To understand what is happening during reshaping, print out logits.shape and token_logits.shape\n",
        "        # and the same for y\n",
        "        # print(logits.shape, token_logits.shape)\n",
        "        # print(y.shape, token_labels.shape)\n",
        "        # print(y[0])\n",
        "        # print(token_labels[0:10])\n",
        "\n",
        "        # Calculate the loss\n",
        "        loss = criterion(token_logits,token_labels)\n",
        "\n",
        "        # Apply the backward step (calculate the gradients)\n",
        "        loss.backward()\n",
        "\n",
        "        # Adjust the weights\n",
        "        optimizer.step()\n",
        "\n",
        "        # Accumulate the loss over batches\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Monitor progress every twenty batches\n",
        "        if batch_idx % 20 == 0:\n",
        "            print(f\"Epoch [{epoch+1}/{num_epochs}], Step [{batch_idx}/{len(train_dataloader)}], Loss: {loss.item():.4f}\")\n",
        "\n",
        "    # Calculate average cross-entropy loss and perplexity\n",
        "    avg_loss = total_loss / len(train_dataloader)\n",
        "    perplexity = math.exp(avg_loss)\n",
        "\n",
        "    # Monitor developments over learning process\n",
        "    train_losses.append(avg_loss)\n",
        "    perplexities.append(perplexity)\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}] Average Loss: {avg_loss:.4f}, Perplexity: {perplexity:.2f}\")"
      ],
      "metadata": {
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2024-12-11T13:45:47.359870Z",
          "iopub.status.busy": "2024-12-11T13:45:47.359515Z",
          "iopub.status.idle": "2024-12-11T13:50:01.450481Z",
          "shell.execute_reply": "2024-12-11T13:50:01.449288Z",
          "shell.execute_reply.started": "2024-12-11T13:45:47.359842Z"
        },
        "jupyter": {
          "outputs_hidden": true
        },
        "trusted": true,
        "id": "3iRETgGJkM1w"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(train_losses, label='Training Loss', linestyle='dashed', marker=\"o\")\n",
        "plt.title('Simple Model - Training Loss over Epochs')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(perplexities, label='Perplexity', linestyle='dashed', marker=\"o\")\n",
        "plt.title('Simple Model - Perplexity over Epochs')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Perplexity')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2024-12-11T13:50:08.470450Z",
          "iopub.status.busy": "2024-12-11T13:50:08.470064Z",
          "iopub.status.idle": "2024-12-11T13:50:08.897922Z",
          "shell.execute_reply": "2024-12-11T13:50:08.897046Z",
          "shell.execute_reply.started": "2024-12-11T13:50:08.470416Z"
        },
        "jupyter": {
          "outputs_hidden": true
        },
        "trusted": true,
        "id": "DArhdN7tkM1w",
        "outputId": "8d5dad40-462e-4f67-a27c-9c94bdefcf79"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1200x500 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "total_loss = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for x, y in dev_dataloader:\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "        logits = model(x)\n",
        "        loss = criterion(logits.view(-1, vocab_size), y.view(-1))\n",
        "        total_loss += loss.item()\n",
        "\n",
        "avg_loss = total_loss / len(dev_dataloader)\n",
        "perplexity_simple = math.exp(avg_loss)\n",
        "print(f\"Perplexity of base model: {perplexity_simple:.2f}\")"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-11T13:50:11.766030Z",
          "iopub.status.busy": "2024-12-11T13:50:11.765419Z",
          "iopub.status.idle": "2024-12-11T13:51:04.573927Z",
          "shell.execute_reply": "2024-12-11T13:51:04.572950Z",
          "shell.execute_reply.started": "2024-12-11T13:50:11.765996Z"
        },
        "jupyter": {
          "source_hidden": true
        },
        "trusted": true,
        "id": "a2KNCMYrkM1w",
        "outputId": "c0fe89d2-5212-4967-9c26-c2982d85793b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Perplexity of base model: 6.25\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## generating text"
      ],
      "metadata": {
        "id": "5vzM3L6LkUca"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text(model, tokenizer, start_text, context_length=15, temperature=1.0):\n",
        "    model.eval()\n",
        "    generated = tokenizer.encode(start_text)\n",
        "    context = torch.tensor(generated, dtype=torch.long, device=device).unsqueeze(0)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for _ in range(context_length):\n",
        "            if context.size(1) >= context_length:\n",
        "                break\n",
        "            logits = model(context)\n",
        "            next_token_logits = logits[0, -1, :] / temperature\n",
        "            probabilities = torch.softmax(next_token_logits, dim=-1)\n",
        "            next_token_id = torch.multinomial(probabilities, num_samples=1)\n",
        "            context = torch.cat([context, next_token_id.unsqueeze(0)], dim=1)\n",
        "\n",
        "    generated_text = tokenizer.decode(context[0].tolist())\n",
        "    return generated_text\n",
        "\n",
        "start_text = \" من در راه\"\n",
        "generated_text = generate_text(model, tokenizer, start_text, context_length=20)\n",
        "print(\"Generated Text:\\n\")\n",
        "print(generated_text)"
      ],
      "metadata": {
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2024-12-11T15:44:20.367200Z",
          "iopub.status.busy": "2024-12-11T15:44:20.366870Z",
          "iopub.status.idle": "2024-12-11T15:44:20.450297Z",
          "shell.execute_reply": "2024-12-11T15:44:20.449049Z",
          "shell.execute_reply.started": "2024-12-11T15:44:20.367173Z"
        },
        "jupyter": {
          "source_hidden": true,
          "outputs_hidden": true
        },
        "trusted": true,
        "id": "R5vpTD2kkM1x",
        "outputId": "9228cdb2-7d32-4c4d-f567-9ab51c80cb98"
      },
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "tuple indices must be integers or slices, not tuple",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[56], line 20\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m generated_text\n\u001b[1;32m     19\u001b[0m start_text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m من در راه\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 20\u001b[0m generated_text \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_text\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGenerated Text:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(generated_text)\n",
            "Cell \u001b[0;32mIn[56], line 11\u001b[0m, in \u001b[0;36mgenerate_text\u001b[0;34m(model, tokenizer, start_text, context_length, temperature)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m     10\u001b[0m logits \u001b[38;5;241m=\u001b[39m model(context)\n\u001b[0;32m---> 11\u001b[0m next_token_logits \u001b[38;5;241m=\u001b[39m \u001b[43mlogits\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m/\u001b[39m temperature\n\u001b[1;32m     12\u001b[0m probabilities \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msoftmax(next_token_logits, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     13\u001b[0m next_token_id \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmultinomial(probabilities, num_samples\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
            "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/utils/generic.py:433\u001b[0m, in \u001b[0;36mModelOutput.__getitem__\u001b[0;34m(self, k)\u001b[0m\n\u001b[1;32m    431\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m inner_dict[k]\n\u001b[1;32m    432\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 433\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_tuple\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\n",
            "\u001b[0;31mTypeError\u001b[0m: tuple indices must be integers or slices, not tuple"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# cnn model"
      ],
      "metadata": {
        "id": "OYj8BlenkYSa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ConvolutionalLanguageModel(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, context_length, num_heads=4, num_layers=2, dropout=0.2):\n",
        "        super(ConvolutionalLanguageModel, self).__init__()\n",
        "        self.token_embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.position_embedding = nn.Embedding(context_length, embedding_dim)\n",
        "\n",
        "        # Convolutional block\n",
        "        self.conv1 = nn.Conv1d(in_channels=embedding_dim, out_channels=embedding_dim, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv1d(in_channels=embedding_dim, out_channels=embedding_dim, kernel_size=5, padding=2)\n",
        "        self.batch_norm = nn.BatchNorm1d(embedding_dim)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "        # Transformer encoder\n",
        "        encoder_layer = nn.TransformerEncoderLayer(\n",
        "            d_model=embedding_dim,\n",
        "            nhead=num_heads,\n",
        "            dim_feedforward=embedding_dim * 4,\n",
        "            dropout=dropout,\n",
        "            batch_first=True,\n",
        "        )\n",
        "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
        "\n",
        "        self.layer_norm = nn.LayerNorm(embedding_dim)\n",
        "        self.linear = nn.Linear(embedding_dim, vocab_size)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        positions = torch.arange(0, x.size(1), device=x.device).unsqueeze(0)\n",
        "        token_embeds = self.token_embedding(x)\n",
        "        position_embeds = self.position_embedding(positions)\n",
        "\n",
        "        embeddings = token_embeds + position_embeds\n",
        "        embeddings = self.dropout(embeddings)\n",
        "\n",
        "        # Convolutional processing\n",
        "        embeddings = embeddings.transpose(1, 2)  # Convert to [batch_size, embedding_dim, seq_len]\n",
        "        embeddings = self.conv1(embeddings)\n",
        "        embeddings = self.relu(self.batch_norm(embeddings))\n",
        "        embeddings = self.conv2(embeddings)\n",
        "        embeddings = embeddings.transpose(1, 2)  # Convert back to [batch_size, seq_len, embedding_dim]\n",
        "\n",
        "        # Transformer processing\n",
        "        embeddings = self.layer_norm(embeddings)\n",
        "        transformer_output = self.transformer(embeddings)\n",
        "        logits = self.linear(transformer_output)\n",
        "        return logits"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-11T13:56:42.671833Z",
          "iopub.status.busy": "2024-12-11T13:56:42.671467Z",
          "iopub.status.idle": "2024-12-11T13:56:42.707464Z",
          "shell.execute_reply": "2024-12-11T13:56:42.706673Z",
          "shell.execute_reply.started": "2024-12-11T13:56:42.671798Z"
        },
        "trusted": true,
        "id": "PFtj67LxkM1x"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## setting up and training cnn model"
      ],
      "metadata": {
        "id": "mDqj6WrnkwkG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the model\n",
        "model = ConvolutionalLanguageModel(vocab_size, embedding_dim, context_length).to(device)\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Training loop parameters\n",
        "num_epochs = 1"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-11T15:44:57.354177Z",
          "iopub.status.busy": "2024-12-11T15:44:57.353827Z",
          "iopub.status.idle": "2024-12-11T15:44:57.430443Z",
          "shell.execute_reply": "2024-12-11T15:44:57.429571Z",
          "shell.execute_reply.started": "2024-12-11T15:44:57.354146Z"
        },
        "trusted": true,
        "id": "_dzY0H7vkM1x",
        "outputId": "a71f5ed9-a69c-4360-ad23-3efbe22380a0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "train_losses = []\n",
        "perplexities = []\n",
        "\n",
        "# Go through learning epochs\n",
        "for epoch in range(num_epochs):\n",
        "    total_loss = 0\n",
        "    model.train()\n",
        "\n",
        "    # Read in data in batches\n",
        "    for batch_idx, (x, y) in enumerate(train_dataloader):\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "\n",
        "        # Reset the gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Apply the forward pass\n",
        "        logits = model(x)\n",
        "\n",
        "        # Reshape logits and labels\n",
        "        token_logits = logits.view(-1, vocab_size)\n",
        "        token_labels = y.view(-1)\n",
        "\n",
        "        # To understand what is happening during reshaping, print out logits.shape and token_logits.shape\n",
        "        # and the same for y\n",
        "        # print(logits.shape, token_logits.shape)\n",
        "        # print(y.shape, token_labels.shape)\n",
        "        # print(y[0])\n",
        "        # print(token_labels[0:10])\n",
        "\n",
        "        # Calculate the loss\n",
        "        loss = criterion(token_logits,token_labels)\n",
        "\n",
        "        # Apply the backward step (calculate the gradients)\n",
        "        loss.backward()\n",
        "\n",
        "        # Adjust the weights\n",
        "        optimizer.step()\n",
        "\n",
        "        # Accumulate the loss over batches\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Monitor progress every twenty batches\n",
        "        if batch_idx % 20 == 0:\n",
        "            print(f\"Epoch [{epoch+1}/{num_epochs}], Step [{batch_idx}/{len(train_dataloader)}], Loss: {loss.item():.4f}\")\n",
        "\n",
        "    # Calculate average cross-entropy loss and perplexity\n",
        "    avg_loss = total_loss / len(train_dataloader)\n",
        "    perplexity = math.exp(avg_loss)\n",
        "\n",
        "    # Monitor developments over learning process\n",
        "    train_losses.append(avg_loss)\n",
        "    perplexities.append(perplexity)\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}] Average Loss: {avg_loss:.4f}, Perplexity: {perplexity:.2f}\")"
      ],
      "metadata": {
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2024-12-11T15:45:01.450906Z",
          "iopub.status.busy": "2024-12-11T15:45:01.450104Z",
          "iopub.status.idle": "2024-12-11T15:45:47.939599Z",
          "shell.execute_reply": "2024-12-11T15:45:47.938458Z",
          "shell.execute_reply.started": "2024-12-11T15:45:01.450870Z"
        },
        "jupyter": {
          "outputs_hidden": true
        },
        "trusted": true,
        "id": "-O0ivSr2kM1x",
        "outputId": "a849700a-5a0e-43d0-cbf9-2f60d4876d67"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/1], Step [0/43387], Loss: 10.2914, Token Logits: torch.Size([4096, 30000]), Token Labels: torch.Size([4096]), y: torch.Size([128, 32]), logits: torch.Size([128, 32, 30000])\n",
            "Epoch [1/1], Step [20/43387], Loss: 3.5169, Token Logits: torch.Size([4096, 30000]), Token Labels: torch.Size([4096]), y: torch.Size([128, 32]), logits: torch.Size([128, 32, 30000])\n",
            "Epoch [1/1], Step [40/43387], Loss: 2.0791, Token Logits: torch.Size([4096, 30000]), Token Labels: torch.Size([4096]), y: torch.Size([128, 32]), logits: torch.Size([128, 32, 30000])\n",
            "Epoch [1/1], Step [60/43387], Loss: 1.8317, Token Logits: torch.Size([4096, 30000]), Token Labels: torch.Size([4096]), y: torch.Size([128, 32]), logits: torch.Size([128, 32, 30000])\n",
            "Epoch [1/1], Step [80/43387], Loss: 1.6235, Token Logits: torch.Size([4096, 30000]), Token Labels: torch.Size([4096]), y: torch.Size([128, 32]), logits: torch.Size([128, 32, 30000])\n",
            "Epoch [1/1], Step [100/43387], Loss: 1.3843, Token Logits: torch.Size([4096, 30000]), Token Labels: torch.Size([4096]), y: torch.Size([128, 32]), logits: torch.Size([128, 32, 30000])\n",
            "Epoch [1/1], Step [120/43387], Loss: 1.1859, Token Logits: torch.Size([4096, 30000]), Token Labels: torch.Size([4096]), y: torch.Size([128, 32]), logits: torch.Size([128, 32, 30000])\n",
            "Epoch [1/1], Step [140/43387], Loss: 1.0123, Token Logits: torch.Size([4096, 30000]), Token Labels: torch.Size([4096]), y: torch.Size([128, 32]), logits: torch.Size([128, 32, 30000])\n",
            "Epoch [1/1], Step [160/43387], Loss: 0.9671, Token Logits: torch.Size([4096, 30000]), Token Labels: torch.Size([4096]), y: torch.Size([128, 32]), logits: torch.Size([128, 32, 30000])\n",
            "Epoch [1/1], Step [180/43387], Loss: 0.7730, Token Logits: torch.Size([4096, 30000]), Token Labels: torch.Size([4096]), y: torch.Size([128, 32]), logits: torch.Size([128, 32, 30000])\n",
            "Epoch [1/1], Step [200/43387], Loss: 0.7273, Token Logits: torch.Size([4096, 30000]), Token Labels: torch.Size([4096]), y: torch.Size([128, 32]), logits: torch.Size([128, 32, 30000])\n",
            "Epoch [1/1], Step [220/43387], Loss: 0.6005, Token Logits: torch.Size([4096, 30000]), Token Labels: torch.Size([4096]), y: torch.Size([128, 32]), logits: torch.Size([128, 32, 30000])\n",
            "Epoch [1/1], Step [240/43387], Loss: 0.5760, Token Logits: torch.Size([4096, 30000]), Token Labels: torch.Size([4096]), y: torch.Size([128, 32]), logits: torch.Size([128, 32, 30000])\n",
            "Epoch [1/1], Step [260/43387], Loss: 0.5046, Token Logits: torch.Size([4096, 30000]), Token Labels: torch.Size([4096]), y: torch.Size([128, 32]), logits: torch.Size([128, 32, 30000])\n",
            "Epoch [1/1], Step [280/43387], Loss: 0.4228, Token Logits: torch.Size([4096, 30000]), Token Labels: torch.Size([4096]), y: torch.Size([128, 32]), logits: torch.Size([128, 32, 30000])\n",
            "Epoch [1/1], Step [300/43387], Loss: 0.3972, Token Logits: torch.Size([4096, 30000]), Token Labels: torch.Size([4096]), y: torch.Size([128, 32]), logits: torch.Size([128, 32, 30000])\n",
            "Epoch [1/1], Step [320/43387], Loss: 0.3279, Token Logits: torch.Size([4096, 30000]), Token Labels: torch.Size([4096]), y: torch.Size([128, 32]), logits: torch.Size([128, 32, 30000])\n",
            "Epoch [1/1], Step [340/43387], Loss: 0.3430, Token Logits: torch.Size([4096, 30000]), Token Labels: torch.Size([4096]), y: torch.Size([128, 32]), logits: torch.Size([128, 32, 30000])\n",
            "Epoch [1/1], Step [360/43387], Loss: 0.2715, Token Logits: torch.Size([4096, 30000]), Token Labels: torch.Size([4096]), y: torch.Size([128, 32]), logits: torch.Size([128, 32, 30000])\n",
            "Epoch [1/1], Step [380/43387], Loss: 0.2643, Token Logits: torch.Size([4096, 30000]), Token Labels: torch.Size([4096]), y: torch.Size([128, 32]), logits: torch.Size([128, 32, 30000])\n",
            "Epoch [1/1], Step [400/43387], Loss: 0.2357, Token Logits: torch.Size([4096, 30000]), Token Labels: torch.Size([4096]), y: torch.Size([128, 32]), logits: torch.Size([128, 32, 30000])\n",
            "Epoch [1/1], Step [420/43387], Loss: 0.2350, Token Logits: torch.Size([4096, 30000]), Token Labels: torch.Size([4096]), y: torch.Size([128, 32]), logits: torch.Size([128, 32, 30000])\n",
            "Epoch [1/1], Step [440/43387], Loss: 0.2287, Token Logits: torch.Size([4096, 30000]), Token Labels: torch.Size([4096]), y: torch.Size([128, 32]), logits: torch.Size([128, 32, 30000])\n",
            "Epoch [1/1], Step [460/43387], Loss: 0.2044, Token Logits: torch.Size([4096, 30000]), Token Labels: torch.Size([4096]), y: torch.Size([128, 32]), logits: torch.Size([128, 32, 30000])\n",
            "Epoch [1/1], Step [480/43387], Loss: 0.1997, Token Logits: torch.Size([4096, 30000]), Token Labels: torch.Size([4096]), y: torch.Size([128, 32]), logits: torch.Size([128, 32, 30000])\n",
            "Epoch [1/1], Step [500/43387], Loss: 0.1399, Token Logits: torch.Size([4096, 30000]), Token Labels: torch.Size([4096]), y: torch.Size([128, 32]), logits: torch.Size([128, 32, 30000])\n",
            "Epoch [1/1], Step [520/43387], Loss: 0.1642, Token Logits: torch.Size([4096, 30000]), Token Labels: torch.Size([4096]), y: torch.Size([128, 32]), logits: torch.Size([128, 32, 30000])\n",
            "Epoch [1/1], Step [540/43387], Loss: 0.1377, Token Logits: torch.Size([4096, 30000]), Token Labels: torch.Size([4096]), y: torch.Size([128, 32]), logits: torch.Size([128, 32, 30000])\n",
            "Epoch [1/1], Step [560/43387], Loss: 0.1476, Token Logits: torch.Size([4096, 30000]), Token Labels: torch.Size([4096]), y: torch.Size([128, 32]), logits: torch.Size([128, 32, 30000])\n",
            "Epoch [1/1], Step [580/43387], Loss: 0.1566, Token Logits: torch.Size([4096, 30000]), Token Labels: torch.Size([4096]), y: torch.Size([128, 32]), logits: torch.Size([128, 32, 30000])\n",
            "Epoch [1/1], Step [600/43387], Loss: 0.1430, Token Logits: torch.Size([4096, 30000]), Token Labels: torch.Size([4096]), y: torch.Size([128, 32]), logits: torch.Size([128, 32, 30000])\n",
            "Epoch [1/1], Step [620/43387], Loss: 0.1016, Token Logits: torch.Size([4096, 30000]), Token Labels: torch.Size([4096]), y: torch.Size([128, 32]), logits: torch.Size([128, 32, 30000])\n",
            "Epoch [1/1], Step [640/43387], Loss: 0.1158, Token Logits: torch.Size([4096, 30000]), Token Labels: torch.Size([4096]), y: torch.Size([128, 32]), logits: torch.Size([128, 32, 30000])\n",
            "Epoch [1/1], Step [660/43387], Loss: 0.0979, Token Logits: torch.Size([4096, 30000]), Token Labels: torch.Size([4096]), y: torch.Size([128, 32]), logits: torch.Size([128, 32, 30000])\n",
            "Epoch [1/1], Step [680/43387], Loss: 0.1016, Token Logits: torch.Size([4096, 30000]), Token Labels: torch.Size([4096]), y: torch.Size([128, 32]), logits: torch.Size([128, 32, 30000])\n",
            "Epoch [1/1], Step [700/43387], Loss: 0.1023, Token Logits: torch.Size([4096, 30000]), Token Labels: torch.Size([4096]), y: torch.Size([128, 32]), logits: torch.Size([128, 32, 30000])\n",
            "Epoch [1/1], Step [720/43387], Loss: 0.1152, Token Logits: torch.Size([4096, 30000]), Token Labels: torch.Size([4096]), y: torch.Size([128, 32]), logits: torch.Size([128, 32, 30000])\n",
            "Epoch [1/1], Step [740/43387], Loss: 0.0887, Token Logits: torch.Size([4096, 30000]), Token Labels: torch.Size([4096]), y: torch.Size([128, 32]), logits: torch.Size([128, 32, 30000])\n",
            "Epoch [1/1], Step [760/43387], Loss: 0.0798, Token Logits: torch.Size([4096, 30000]), Token Labels: torch.Size([4096]), y: torch.Size([128, 32]), logits: torch.Size([128, 32, 30000])\n",
            "Epoch [1/1], Step [780/43387], Loss: 0.1128, Token Logits: torch.Size([4096, 30000]), Token Labels: torch.Size([4096]), y: torch.Size([128, 32]), logits: torch.Size([128, 32, 30000])\n",
            "Epoch [1/1], Step [800/43387], Loss: 0.0945, Token Logits: torch.Size([4096, 30000]), Token Labels: torch.Size([4096]), y: torch.Size([128, 32]), logits: torch.Size([128, 32, 30000])\n",
            "Epoch [1/1], Step [820/43387], Loss: 0.0966, Token Logits: torch.Size([4096, 30000]), Token Labels: torch.Size([4096]), y: torch.Size([128, 32]), logits: torch.Size([128, 32, 30000])\n",
            "Epoch [1/1], Step [840/43387], Loss: 0.0787, Token Logits: torch.Size([4096, 30000]), Token Labels: torch.Size([4096]), y: torch.Size([128, 32]), logits: torch.Size([128, 32, 30000])\n",
            "Epoch [1/1], Step [860/43387], Loss: 0.0697, Token Logits: torch.Size([4096, 30000]), Token Labels: torch.Size([4096]), y: torch.Size([128, 32]), logits: torch.Size([128, 32, 30000])\n",
            "Epoch [1/1], Step [880/43387], Loss: 0.0880, Token Logits: torch.Size([4096, 30000]), Token Labels: torch.Size([4096]), y: torch.Size([128, 32]), logits: torch.Size([128, 32, 30000])\n",
            "Epoch [1/1], Step [900/43387], Loss: 0.0640, Token Logits: torch.Size([4096, 30000]), Token Labels: torch.Size([4096]), y: torch.Size([128, 32]), logits: torch.Size([128, 32, 30000])\n",
            "Epoch [1/1], Step [920/43387], Loss: 0.0582, Token Logits: torch.Size([4096, 30000]), Token Labels: torch.Size([4096]), y: torch.Size([128, 32]), logits: torch.Size([128, 32, 30000])\n",
            "Epoch [1/1], Step [940/43387], Loss: 0.0950, Token Logits: torch.Size([4096, 30000]), Token Labels: torch.Size([4096]), y: torch.Size([128, 32]), logits: torch.Size([128, 32, 30000])\n",
            "Epoch [1/1], Step [960/43387], Loss: 0.0736, Token Logits: torch.Size([4096, 30000]), Token Labels: torch.Size([4096]), y: torch.Size([128, 32]), logits: torch.Size([128, 32, 30000])\n",
            "Epoch [1/1], Step [980/43387], Loss: 0.0824, Token Logits: torch.Size([4096, 30000]), Token Labels: torch.Size([4096]), y: torch.Size([128, 32]), logits: torch.Size([128, 32, 30000])\n",
            "Epoch [1/1], Step [1000/43387], Loss: 0.0771, Token Logits: torch.Size([4096, 30000]), Token Labels: torch.Size([4096]), y: torch.Size([128, 32]), logits: torch.Size([128, 32, 30000])\n",
            "Epoch [1/1], Step [1020/43387], Loss: 0.0829, Token Logits: torch.Size([4096, 30000]), Token Labels: torch.Size([4096]), y: torch.Size([128, 32]), logits: torch.Size([128, 32, 30000])\n",
            "Epoch [1/1], Step [1040/43387], Loss: 0.0683, Token Logits: torch.Size([4096, 30000]), Token Labels: torch.Size([4096]), y: torch.Size([128, 32]), logits: torch.Size([128, 32, 30000])\n",
            "Epoch [1/1], Step [1060/43387], Loss: 0.0921, Token Logits: torch.Size([4096, 30000]), Token Labels: torch.Size([4096]), y: torch.Size([128, 32]), logits: torch.Size([128, 32, 30000])\n",
            "Epoch [1/1], Step [1080/43387], Loss: 0.0733, Token Logits: torch.Size([4096, 30000]), Token Labels: torch.Size([4096]), y: torch.Size([128, 32]), logits: torch.Size([128, 32, 30000])\n",
            "Epoch [1/1], Step [1100/43387], Loss: 0.0789, Token Logits: torch.Size([4096, 30000]), Token Labels: torch.Size([4096]), y: torch.Size([128, 32]), logits: torch.Size([128, 32, 30000])\n",
            "Epoch [1/1], Step [1120/43387], Loss: 0.0704, Token Logits: torch.Size([4096, 30000]), Token Labels: torch.Size([4096]), y: torch.Size([128, 32]), logits: torch.Size([128, 32, 30000])\n",
            "Epoch [1/1], Step [1140/43387], Loss: 0.0769, Token Logits: torch.Size([4096, 30000]), Token Labels: torch.Size([4096]), y: torch.Size([128, 32]), logits: torch.Size([128, 32, 30000])\n",
            "Epoch [1/1], Step [1160/43387], Loss: 0.0609, Token Logits: torch.Size([4096, 30000]), Token Labels: torch.Size([4096]), y: torch.Size([128, 32]), logits: torch.Size([128, 32, 30000])\n",
            "Epoch [1/1], Step [1180/43387], Loss: 0.0627, Token Logits: torch.Size([4096, 30000]), Token Labels: torch.Size([4096]), y: torch.Size([128, 32]), logits: torch.Size([128, 32, 30000])\n",
            "Epoch [1/1], Step [1200/43387], Loss: 0.0682, Token Logits: torch.Size([4096, 30000]), Token Labels: torch.Size([4096]), y: torch.Size([128, 32]), logits: torch.Size([128, 32, 30000])\n",
            "Epoch [1/1], Step [1220/43387], Loss: 0.0748, Token Logits: torch.Size([4096, 30000]), Token Labels: torch.Size([4096]), y: torch.Size([128, 32]), logits: torch.Size([128, 32, 30000])\n",
            "Epoch [1/1], Step [1240/43387], Loss: 0.0570, Token Logits: torch.Size([4096, 30000]), Token Labels: torch.Size([4096]), y: torch.Size([128, 32]), logits: torch.Size([128, 32, 30000])\n",
            "Epoch [1/1], Step [1260/43387], Loss: 0.0646, Token Logits: torch.Size([4096, 30000]), Token Labels: torch.Size([4096]), y: torch.Size([128, 32]), logits: torch.Size([128, 32, 30000])\n",
            "Epoch [1/1], Step [1280/43387], Loss: 0.0541, Token Logits: torch.Size([4096, 30000]), Token Labels: torch.Size([4096]), y: torch.Size([128, 32]), logits: torch.Size([128, 32, 30000])\n",
            "Epoch [1/1], Step [1300/43387], Loss: 0.0700, Token Logits: torch.Size([4096, 30000]), Token Labels: torch.Size([4096]), y: torch.Size([128, 32]), logits: torch.Size([128, 32, 30000])\n",
            "Epoch [1/1], Step [1320/43387], Loss: 0.0468, Token Logits: torch.Size([4096, 30000]), Token Labels: torch.Size([4096]), y: torch.Size([128, 32]), logits: torch.Size([128, 32, 30000])\n",
            "Epoch [1/1], Step [1340/43387], Loss: 0.0753, Token Logits: torch.Size([4096, 30000]), Token Labels: torch.Size([4096]), y: torch.Size([128, 32]), logits: torch.Size([128, 32, 30000])\n",
            "Epoch [1/1], Step [1360/43387], Loss: 0.0574, Token Logits: torch.Size([4096, 30000]), Token Labels: torch.Size([4096]), y: torch.Size([128, 32]), logits: torch.Size([128, 32, 30000])\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[58], line 44\u001b[0m\n\u001b[1;32m     41\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# Accumulate the loss over batches\u001b[39;00m\n\u001b[0;32m---> 44\u001b[0m total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;66;03m# Monitor progress every twenty batches\u001b[39;00m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_idx \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m20\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## loss and perplexity (cnn model)"
      ],
      "metadata": {
        "id": "ppOBpYMIlQHE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "total_loss = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for x, y in dev_dataloader:\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "        logits = model(x)\n",
        "        loss = criterion(logits.view(-1, vocab_size), y.view(-1))\n",
        "        total_loss += loss.item()\n",
        "\n",
        "avg_loss = total_loss / len(dev_dataloader)\n",
        "perplexity_simple = math.exp(avg_loss)\n",
        "print(f\"Perplexity of base model: {perplexity_simple:.2f}\")"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-11T15:45:54.097637Z",
          "iopub.status.busy": "2024-12-11T15:45:54.096801Z",
          "iopub.status.idle": "2024-12-11T15:46:57.323511Z",
          "shell.execute_reply": "2024-12-11T15:46:57.322527Z",
          "shell.execute_reply.started": "2024-12-11T15:45:54.097600Z"
        },
        "trusted": true,
        "id": "MJO7_RK0kM1x",
        "outputId": "b075d0a9-c0e6-47e1-9054-46b57b926bb4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Perplexity of base model: 1.06\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## generating text (cnn model)"
      ],
      "metadata": {
        "id": "V9BEnG1FlZCH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text(model, tokenizer, start_text, context_length=15, temperature=1.0):\n",
        "    model.eval()\n",
        "    generated = tokenizer.encode(start_text)\n",
        "    context = torch.tensor(generated, dtype=torch.long, device=device).unsqueeze(0)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for _ in range(context_length):\n",
        "            if context.size(1) >= context_length:\n",
        "                break\n",
        "            logits = model(context)\n",
        "            next_token_logits = logits[0, -1, :] / temperature\n",
        "            probabilities = torch.softmax(next_token_logits, dim=-1)\n",
        "            next_token_id = torch.multinomial(probabilities, num_samples=1)\n",
        "            context = torch.cat([context, next_token_id.unsqueeze(0)], dim=1)\n",
        "            # print(f\"next_token_logits: {next_token_logits}, probabilities: {probabilities}, next_token_id: {next_token_id}, context: {context}\")\n",
        "\n",
        "\n",
        "    generated_text = tokenizer.decode(context[0].tolist())\n",
        "    return generated_text\n",
        "\n",
        "start_text = \" من در راه\"\n",
        "generated_text = generate_text(model, tokenizer, start_text, context_length=20)\n",
        "print(\"Generated Text:\\n\")\n",
        "print(generated_text)"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-11T15:48:52.819419Z",
          "iopub.status.busy": "2024-12-11T15:48:52.818548Z",
          "iopub.status.idle": "2024-12-11T15:48:52.884789Z",
          "shell.execute_reply": "2024-12-11T15:48:52.883916Z",
          "shell.execute_reply.started": "2024-12-11T15:48:52.819380Z"
        },
        "trusted": true,
        "collapsed": true,
        "id": "LI90850kkM1y",
        "outputId": "edea5b57-aec2-4ad1-bf40-8b6a1be201eb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "next_token_logits: tensor([ 4.3275, -5.4783, -7.5729,  ..., -6.8719, -5.1250, -6.9073],\n",
            "       device='cuda:0'), probabilities: tensor([1.2609e-03, 6.9508e-08, 8.5581e-09,  ..., 1.7252e-08, 9.8970e-08,\n",
            "        1.6651e-08], device='cuda:0'), next_token_id: tensor([24943], device='cuda:0'), context: tensor([[    5,    78,    46,   167,     3, 24943]], device='cuda:0')\n",
            "next_token_logits: tensor([ 3.1330, -5.4079, -6.6491,  ..., -7.7862, -4.7720, -6.5186],\n",
            "       device='cuda:0'), probabilities: tensor([1.6268e-04, 3.1775e-08, 9.1840e-09,  ..., 2.9458e-09, 6.0012e-08,\n",
            "        1.0464e-08], device='cuda:0'), next_token_id: tensor([43], device='cuda:0'), context: tensor([[    5,    78,    46,   167,     3, 24943,    43]], device='cuda:0')\n",
            "next_token_logits: tensor([ 0.1055, -4.6321, -5.2862,  ..., -5.6402, -2.8663, -4.8546],\n",
            "       device='cuda:0'), probabilities: tensor([2.8401e-07, 2.4878e-09, 1.2935e-09,  ..., 9.0783e-10, 1.4545e-08,\n",
            "        1.9915e-09], device='cuda:0'), next_token_id: tensor([24940], device='cuda:0'), context: tensor([[    5,    78,    46,   167,     3, 24943,    43, 24940]],\n",
            "       device='cuda:0')\n",
            "next_token_logits: tensor([ 3.3240, -5.2526, -8.3216,  ..., -6.6782, -5.1706, -7.1684],\n",
            "       device='cuda:0'), probabilities: tensor([4.9648e-06, 9.3570e-10, 4.3481e-11,  ..., 2.2491e-10, 1.0157e-09,\n",
            "        1.3777e-10], device='cuda:0'), next_token_id: tensor([24941], device='cuda:0'), context: tensor([[    5,    78,    46,   167,     3, 24943,    43, 24940, 24941]],\n",
            "       device='cuda:0')\n",
            "next_token_logits: tensor([-2.8222, -6.6183, -7.3264,  ..., -7.6336, -5.5160, -6.5274],\n",
            "       device='cuda:0'), probabilities: tensor([4.7043e-06, 1.0565e-07, 5.2041e-08,  ..., 3.8275e-08, 3.1813e-07,\n",
            "        1.1570e-07], device='cuda:0'), next_token_id: tensor([2072], device='cuda:0'), context: tensor([[    5,    78,    46,   167,     3, 24943,    43, 24940, 24941,  2072]],\n",
            "       device='cuda:0')\n",
            "next_token_logits: tensor([ 0.0626, -5.3548, -7.3845,  ..., -6.7888, -5.7764, -6.7187],\n",
            "       device='cuda:0'), probabilities: tensor([6.5214e-05, 2.8945e-07, 3.8029e-08,  ..., 6.8992e-08, 1.8988e-07,\n",
            "        7.4000e-08], device='cuda:0'), next_token_id: tensor([24941], device='cuda:0'), context: tensor([[    5,    78,    46,   167,     3, 24943,    43, 24940, 24941,  2072,\n",
            "         24941]], device='cuda:0')\n",
            "next_token_logits: tensor([-1.9916, -4.4655, -6.7230,  ..., -5.9018, -3.5018, -5.3119],\n",
            "       device='cuda:0'), probabilities: tensor([1.7535e-08, 1.4774e-09, 1.5455e-10,  ..., 3.5134e-10, 3.8728e-09,\n",
            "        6.3377e-10], device='cuda:0'), next_token_id: tensor([24980], device='cuda:0'), context: tensor([[    5,    78,    46,   167,     3, 24943,    43, 24940, 24941,  2072,\n",
            "         24941, 24980]], device='cuda:0')\n",
            "next_token_logits: tensor([ 0.4979, -4.8970, -5.7556,  ..., -6.7394, -5.3779, -6.2984],\n",
            "       device='cuda:0'), probabilities: tensor([1.5072e-07, 6.8417e-10, 2.8992e-10,  ..., 1.0841e-10, 4.2299e-10,\n",
            "        1.6848e-10], device='cuda:0'), next_token_id: tensor([43], device='cuda:0'), context: tensor([[    5,    78,    46,   167,     3, 24943,    43, 24940, 24941,  2072,\n",
            "         24941, 24980,    43]], device='cuda:0')\n",
            "next_token_logits: tensor([ 3.0569, -4.8404, -8.5381,  ..., -6.1974, -5.2147, -7.2286],\n",
            "       device='cuda:0'), probabilities: tensor([1.9696e-06, 7.3216e-10, 1.8145e-11,  ..., 1.8849e-10, 5.0360e-10,\n",
            "        6.7211e-11], device='cuda:0'), next_token_id: tensor([24941], device='cuda:0'), context: tensor([[    5,    78,    46,   167,     3, 24943,    43, 24940, 24941,  2072,\n",
            "         24941, 24980,    43, 24941]], device='cuda:0')\n",
            "next_token_logits: tensor([-1.4949, -6.2812, -7.3413,  ..., -6.9811, -5.4213, -6.6031],\n",
            "       device='cuda:0'), probabilities: tensor([2.0982e-05, 1.7506e-07, 6.0643e-08,  ..., 8.6937e-08, 4.1364e-07,\n",
            "        1.2687e-07], device='cuda:0'), next_token_id: tensor([15706], device='cuda:0'), context: tensor([[    5,    78,    46,   167,     3, 24943,    43, 24940, 24941,  2072,\n",
            "         24941, 24980,    43, 24941, 15706]], device='cuda:0')\n",
            "next_token_logits: tensor([ 1.1932, -6.0818, -7.9121,  ..., -7.4337, -6.4437, -6.7658],\n",
            "       device='cuda:0'), probabilities: tensor([4.0914e-04, 2.8338e-07, 4.5447e-08,  ..., 7.3331e-08, 1.9734e-07,\n",
            "        1.4299e-07], device='cuda:0'), next_token_id: tensor([3180], device='cuda:0'), context: tensor([[    5,    78,    46,   167,     3, 24943,    43, 24940, 24941,  2072,\n",
            "         24941, 24980,    43, 24941, 15706,  3180]], device='cuda:0')\n",
            "next_token_logits: tensor([ 3.8506, -5.9499, -7.6331,  ..., -7.4360, -5.7900, -7.3472],\n",
            "       device='cuda:0'), probabilities: tensor([2.9028e-03, 1.6087e-07, 2.9886e-08,  ..., 3.6399e-08, 1.8877e-07,\n",
            "        3.9780e-08], device='cuda:0'), next_token_id: tensor([505], device='cuda:0'), context: tensor([[    5,    78,    46,   167,     3, 24943,    43, 24940, 24941,  2072,\n",
            "         24941, 24980,    43, 24941, 15706,  3180,   505]], device='cuda:0')\n",
            "next_token_logits: tensor([ 2.5004, -5.2977, -7.9402,  ..., -7.8604, -5.9039, -6.9548],\n",
            "       device='cuda:0'), probabilities: tensor([9.4182e-05, 3.8662e-08, 2.7523e-09,  ..., 2.9807e-09, 2.1089e-08,\n",
            "        7.3730e-09], device='cuda:0'), next_token_id: tensor([24941], device='cuda:0'), context: tensor([[    5,    78,    46,   167,     3, 24943,    43, 24940, 24941,  2072,\n",
            "         24941, 24980,    43, 24941, 15706,  3180,   505, 24941]],\n",
            "       device='cuda:0')\n",
            "next_token_logits: tensor([-0.4718, -4.3377, -6.5978,  ..., -5.9653, -3.3261, -5.5735],\n",
            "       device='cuda:0'), probabilities: tensor([6.3923e-08, 1.3387e-09, 1.3969e-10,  ..., 2.6293e-10, 3.6816e-09,\n",
            "        3.8905e-10], device='cuda:0'), next_token_id: tensor([24980], device='cuda:0'), context: tensor([[    5,    78,    46,   167,     3, 24943,    43, 24940, 24941,  2072,\n",
            "         24941, 24980,    43, 24941, 15706,  3180,   505, 24941, 24980]],\n",
            "       device='cuda:0')\n",
            "next_token_logits: tensor([ 0.2137, -5.1247, -5.6140,  ..., -6.8269, -5.2022, -6.0652],\n",
            "       device='cuda:0'), probabilities: tensor([5.2827e-08, 2.5374e-10, 1.5556e-10,  ..., 4.6255e-11, 2.3483e-10,\n",
            "        9.9071e-11], device='cuda:0'), next_token_id: tensor([43], device='cuda:0'), context: tensor([[    5,    78,    46,   167,     3, 24943,    43, 24940, 24941,  2072,\n",
            "         24941, 24980,    43, 24941, 15706,  3180,   505, 24941, 24980,    43]],\n",
            "       device='cuda:0')\n",
            "Generated Text:\n",
            "\n",
            "[CLS] من در راه[SEP]5 ['این', 'هستندفیکه', \n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# a pretrained model from hugging face"
      ],
      "metadata": {
        "id": "AV6285XflpZC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline, AutoTokenizer, GPT2LMHeadModel\n",
        "tokenizer = AutoTokenizer.from_pretrained('bolbolzaban/gpt2-persian')\n",
        "model = GPT2LMHeadModel.from_pretrained('bolbolzaban/gpt2-persian')\n",
        "generator = pipeline('text-generation', model, tokenizer=tokenizer, config={'max_length':512}, device='cuda')\n",
        "sample = generator('در یک اتفاق شگفت انگیز، پژوهشگران')"
      ],
      "metadata": {
        "id": "vR82OMPfloYQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}