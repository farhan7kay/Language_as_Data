{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-12-11T15:52:20.124641Z",
     "iopub.status.busy": "2024-12-11T15:52:20.124279Z",
     "iopub.status.idle": "2024-12-11T15:52:39.089098Z",
     "shell.execute_reply": "2024-12-11T15:52:39.088037Z",
     "shell.execute_reply.started": "2024-12-11T15:52:20.124609Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tokenizers in /opt/conda/lib/python3.10/site-packages (0.20.3)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (1.2.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /opt/conda/lib/python3.10/site-packages (from tokenizers) (0.26.2)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.24.3)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (3.15.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (2024.6.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (6.0.2)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (4.12.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface-hub<1.0,>=0.16.4->tokenizers) (3.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers) (2024.6.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: hazm in /opt/conda/lib/python3.10/site-packages (0.10.0)\n",
      "Requirement already satisfied: fasttext-wheel<0.10.0,>=0.9.2 in /opt/conda/lib/python3.10/site-packages (from hazm) (0.9.2)\n",
      "Requirement already satisfied: flashtext<3.0,>=2.7 in /opt/conda/lib/python3.10/site-packages (from hazm) (2.7)\n",
      "Requirement already satisfied: gensim<5.0.0,>=4.3.1 in /opt/conda/lib/python3.10/site-packages (from hazm) (4.3.3)\n",
      "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in /opt/conda/lib/python3.10/site-packages (from hazm) (3.9.1)\n",
      "Requirement already satisfied: numpy==1.24.3 in /opt/conda/lib/python3.10/site-packages (from hazm) (1.24.3)\n",
      "Requirement already satisfied: python-crfsuite<0.10.0,>=0.9.9 in /opt/conda/lib/python3.10/site-packages (from hazm) (0.9.11)\n",
      "Requirement already satisfied: scikit-learn<2.0.0,>=1.2.2 in /opt/conda/lib/python3.10/site-packages (from hazm) (1.2.2)\n",
      "Requirement already satisfied: pybind11>=2.2 in /opt/conda/lib/python3.10/site-packages (from fasttext-wheel<0.10.0,>=0.9.2->hazm) (2.13.6)\n",
      "Requirement already satisfied: setuptools>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from fasttext-wheel<0.10.0,>=0.9.2->hazm) (70.0.0)\n",
      "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /opt/conda/lib/python3.10/site-packages (from gensim<5.0.0,>=4.3.1->hazm) (1.13.1)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /opt/conda/lib/python3.10/site-packages (from gensim<5.0.0,>=4.3.1->hazm) (7.0.4)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.10/site-packages (from nltk<4.0.0,>=3.8.1->hazm) (8.1.7)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.10/site-packages (from nltk<4.0.0,>=3.8.1->hazm) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.10/site-packages (from nltk<4.0.0,>=3.8.1->hazm) (2024.5.15)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from nltk<4.0.0,>=3.8.1->hazm) (4.66.4)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn<2.0.0,>=1.2.2->hazm) (3.5.0)\n",
      "Requirement already satisfied: wrapt in /opt/conda/lib/python3.10/site-packages (from smart-open>=1.8.1->gensim<5.0.0,>=4.3.1->hazm) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to /usr/share/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "! pip install tokenizers scikit-learn\n",
    "! pip install hazm\n",
    "\n",
    "from tokenizers import Tokenizer\n",
    "from tokenizers import trainers\n",
    "from tokenizers.normalizers import StripAccents, Lowercase, Sequence\n",
    "from tokenizers.pre_tokenizers import Whitespace\n",
    "from tokenizers.trainers import BpeTrainer, UnigramTrainer\n",
    "from tokenizers.models import BPE, Unigram\n",
    "\n",
    "from transformers import pipeline, AutoTokenizer, GPT2LMHeadModel\n",
    "\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tokenizers\n",
    "\n",
    "import re\n",
    "from hazm import *\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T15:52:39.091267Z",
     "iopub.status.busy": "2024-12-11T15:52:39.090930Z",
     "iopub.status.idle": "2024-12-11T15:52:43.906150Z",
     "shell.execute_reply": "2024-12-11T15:52:43.904989Z",
     "shell.execute_reply.started": "2024-12-11T15:52:39.091215Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-12-11 15:52:40--  https://downloads.wortschatz-leipzig.de/corpora/fas_news_2020_100K.tar.gz\n",
      "Resolving downloads.wortschatz-leipzig.de (downloads.wortschatz-leipzig.de)... 139.18.2.68\n",
      "Connecting to downloads.wortschatz-leipzig.de (downloads.wortschatz-leipzig.de)|139.18.2.68|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 31227186 (30M) [application/x-gzip]\n",
      "Saving to: 'fas_news_2020_100K.tar.gz.1'\n",
      "\n",
      "fas_news_2020_100K. 100%[===================>]  29.78M  46.2MB/s    in 0.6s    \n",
      "\n",
      "2024-12-11 15:52:41 (46.2 MB/s) - 'fas_news_2020_100K.tar.gz.1' saved [31227186/31227186]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fas_news_2020_100K/\n",
      "fas_news_2020_100K/fas_news_2020_100K-inv_w.txt\n",
      "fas_news_2020_100K/fas_news_2020_100K-sources.txt\n",
      "fas_news_2020_100K/fas_news_2020_100K-co_n.txt\n",
      "fas_news_2020_100K/fas_news_2020_100K-import.sql\n",
      "fas_news_2020_100K/fas_news_2020_100K-sentences.txt\n",
      "fas_news_2020_100K/fas_news_2020_100K-co_s.txt\n",
      "fas_news_2020_100K/fas_news_2020_100K-words.txt\n",
      "fas_news_2020_100K/fas_news_2020_100K-inv_so.txt\n"
     ]
    }
   ],
   "source": [
    "!wget https://downloads.wortschatz-leipzig.de/corpora/fas_news_2020_100K.tar.gz\n",
    "!tar --gunzip --extract --verbose --file=fas_news_2020_100K.tar.gz\n",
    "persian_text_path = \"/kaggle/working/fas_news_2020_100K/fas_news_2020_100K-sentences.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T15:52:43.908211Z",
     "iopub.status.busy": "2024-12-11T15:52:43.907895Z",
     "iopub.status.idle": "2024-12-11T15:53:24.925390Z",
     "shell.execute_reply": "2024-12-11T15:53:24.924369Z",
     "shell.execute_reply.started": "2024-12-11T15:52:43.908177Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Example: ['گفتم', 'نه', 'حاجی', 'شما', 'هم', 'بروید', 'دیگر', 'کسی', 'نیست']\n",
      "Validation Data Example: ['در', 'این', 'خصوص', 'مدیرکل', 'دفتر', 'پیشگیری', 'از', 'قاچاق', 'کالا', 'و', 'ارز', 'در', 'واکنش', 'به', 'اعلام', 'آمار', 'قاچاق', 'سیگار', 'در', 'کشور', 'توسط', 'برخی', 'دستگاه', 'ها', 'گفت', 'اعلام', 'رسمی', 'آمار', 'قاچاق', 'سیگار', 'در', 'کشور', 'بر', 'عهده', 'ستاد', 'مبارزه', 'با', 'قاچاق', 'کالا', 'و', 'ارز', 'است']\n",
      "Test Data Example: ['نشان', 'به', 'آن', 'نشان', 'که', 'در', 'حدود', 'کمتر', 'از', '۳۰', 'سال', 'خدمتش', 'همه', 'کیفها', 'پولها', 'چکهای', 'حامل', 'و', 'گوشیهای', 'همراهی', 'که', 'پیدا', 'کرده', 'با', 'پیجویی', 'تمام', 'به', 'صاحبانش', 'برگردانده', 'است']\n"
     ]
    }
   ],
   "source": [
    "# Punctuations and Separators\n",
    "punc = '''()-[]{};،:'\"\\\\, <>./?@#$%^&*_~.'''\n",
    "seperator = ['\\xad', '\\u200e', '\\u200f', '\\u200d', '\\u200c', '\\n']\n",
    "\n",
    "# Hazm Normalizer and Stemmer\n",
    "hazm_normalizer = Normalizer()\n",
    "hazm_stemmer = Stemmer()\n",
    "\n",
    "# Read corpus\n",
    "with open(persian_text_path, \"r\") as f:\n",
    "    sentences = f.readlines()\n",
    "\n",
    "def preprocess_text_with_hazm(text):\n",
    "    # Normalize using Hazm e.g. اصلاح نويسه ها -> اصلاح نویسه‌ها\n",
    "    text = hazm_normalizer.normalize(text)\n",
    "\n",
    "    # Remove unwanted separators\n",
    "    for sep in seperator:\n",
    "        text = text.replace(sep, \" \")\n",
    "\n",
    "    # Remove all punctuation\n",
    "    text = re.sub(r'[^\\u0600-\\u06FF0-9\\s]+', '', text) \n",
    "    text = text.replace(',', '')  \n",
    "    text = text.replace('،', '')\n",
    "    text = re.sub(r\"^\\d+\\s*\", \"\", text)\n",
    "\n",
    "    # Tokenize using Hazm for more accurate Persian tokenization\n",
    "    tokens = word_tokenize(text)\n",
    "\n",
    "    # Add <s> and </s> tags to the sentence\n",
    "    # tokens = ['<s>'] + tokens + ['</s>']\n",
    "\n",
    "    # Stemming using hazm e.g  کتاب‌ها -> کتاب‌\n",
    "    # tokens = [hazm_stemmer.stem(token) for token in tokens]\n",
    "\n",
    "    return tokens\n",
    "\n",
    "# Preprocess all sentences\n",
    "cleaned_sentences = [preprocess_text_with_hazm(sentence) for sentence in sentences]\n",
    "\n",
    "# Split into training, validation, and testing datasets (80%, 10%, 10%)\n",
    "train_corpus, temp_corpus = train_test_split(cleaned_sentences, test_size=0.2, random_state=42)\n",
    "val_corpus, test_corpus = train_test_split(temp_corpus, test_size=0.5, random_state=42)\n",
    "\n",
    "# Example\n",
    "print(\"Training Data Example:\", train_corpus[0])\n",
    "print(\"Validation Data Example:\", val_corpus[0])\n",
    "print(\"Test Data Example:\", test_corpus[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T15:53:24.927537Z",
     "iopub.status.busy": "2024-12-11T15:53:24.927193Z",
     "iopub.status.idle": "2024-12-11T15:53:26.927386Z",
     "shell.execute_reply": "2024-12-11T15:53:26.926474Z",
     "shell.execute_reply.started": "2024-12-11T15:53:24.927507Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Most common 3-grams:\n",
      "('گزارش', 'همشهری', 'آنلاین'): 1115\n",
      "('همشهری', 'آنلاین', 'نقل'): 770\n",
      "('وی', 'ادامه', 'داد'): 510\n",
      "('دانشگاه', 'علوم', 'پزشکی'): 397\n",
      "('مجلس', 'شورای', 'اسلامی'): 384\n",
      "('جمهوری', 'اسلامی', 'ایران'): 284\n",
      "('شیوع', 'ویروس', 'کرونا'): 271\n",
      "('۲۴', 'ساعت', 'گذشته'): 253\n",
      "('جان', 'خود', 'دست'): 172\n",
      "('خبر', 'داد', 'گفت'): 165\n"
     ]
    }
   ],
   "source": [
    "from nltk import ngrams\n",
    "from collections import Counter\n",
    "\n",
    "def ngram_counts(corpus, n, i):\n",
    "    ngram_list = []\n",
    "\n",
    "    stopwords = ['به', 'از', 'را', 'و', 'برای', 'این', 'که', 'با', 'در', 'چون', 'اگر', 'ها', 'نه', 'اینکه', 'یا', 'هم', 'تا', 'که', 'آن', 'باید', 'شده', 'چرا', 'همچنین', 'کردن', 'شد', 'می']\n",
    "    filtered_corpus = [\n",
    "        [word for word in sentence if word not in stopwords]\n",
    "        for sentence in corpus\n",
    "    ]\n",
    "\n",
    "    for sentence in filtered_corpus:\n",
    "        sentence_ngrams = list(ngrams(sentence, n))\n",
    "        ngram_list.extend(sentence_ngrams)\n",
    "\n",
    "    ngram_counts = Counter(ngram_list)\n",
    "\n",
    "    most_common_ngrams = ngram_counts.most_common(i)\n",
    "\n",
    "    print(f\"\\nMost common {n}-grams:\")\n",
    "    for ngram, count in most_common_ngrams:\n",
    "        print(f\"{ngram}: {count}\")\n",
    "\n",
    "ngram_counts(train_corpus, 3, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T15:53:26.928712Z",
     "iopub.status.busy": "2024-12-11T15:53:26.928436Z",
     "iopub.status.idle": "2024-12-11T15:53:29.231930Z",
     "shell.execute_reply": "2024-12-11T15:53:29.230963Z",
     "shell.execute_reply.started": "2024-12-11T15:53:26.928685Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Most common 2-grams:\n",
      "('ادامه', 'داد'): 1317\n",
      "('همشهری', 'آنلاین'): 1180\n",
      "('ویروس', 'کرونا'): 1177\n",
      "('گزارش', 'همشهری'): 1131\n",
      "('بر', 'اساس'): 1078\n",
      "('اعلام', 'کرد'): 969\n",
      "('وی', 'افزود'): 955\n",
      "('خبر', 'داد'): 930\n",
      "('وجود', 'دارد'): 836\n",
      "('تصریح', 'کرد'): 778\n",
      "('آنلاین', 'نقل'): 771\n",
      "('کووید', '۱۹'): 706\n",
      "('ممکن', 'است'): 675\n",
      "('تاکید', 'کرد'): 670\n",
      "('بیان', 'کرد'): 666\n",
      "('نشان', 'دهد'): 648\n",
      "('وی', 'ادامه'): 642\n",
      "('اظهار', 'کرد'): 620\n",
      "('حال', 'حاضر'): 548\n",
      "('سال', 'گذشته'): 531\n"
     ]
    }
   ],
   "source": [
    "ngram_counts(train_corpus, 2, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T15:53:29.233205Z",
     "iopub.status.busy": "2024-12-11T15:53:29.232937Z",
     "iopub.status.idle": "2024-12-11T15:53:29.240738Z",
     "shell.execute_reply": "2024-12-11T15:53:29.239893Z",
     "shell.execute_reply.started": "2024-12-11T15:53:29.233179Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PADDING:\n",
      "['<s>', '<s>', 'گفتم', 'نه', 'حاجی', 'شما', 'هم', 'بروید', 'دیگر', 'کسی', 'نیست', '</s>', '</s>', '<s>', '<s>', 'در', 'این', 'غربال', 'گری', 'ها', 'کیس', 'های', 'مشکوکی', 'با', 'علامت', 'تب', 'داشتیم', 'که', 'خدا', 'را', 'شکر', 'ورزشکاری', 'نبود', 'که', 'با', 'کرونا', 'درگیر', 'باشد', 'اما', 'در', 'بین', 'همکاران', 'بودند', 'کسانی', 'که', 'مبتلا', 'شدند', '</s>', '</s>', '<s>', '<s>', 'حضرت', 'رسول', 'در', 'حلقه', 'اصحاب', 'نشسته_بودند', '</s>', '</s>', '<s>', '<s>', 'این', 'اتفاق', 'باعث', 'شد', 'تا', 'نقش', 'ایالات', 'متحده', 'به', 'عنوان', 'جایگزین', 'طالبان', 'در', 'افغانستان', 'حذف', 'و', 'جای', 'آن', 'را', 'دولتی', 'بگیرد', 'که', 'بومی', 'و', 'از', 'میان', 'سیاستمداران', 'افغان', 'انتخاب', 'شده_است', '</s>', '</s>', '<s>', '<s>', 'وی', 'اضافه', 'کرد', 'همه', 'بخشهای', 'سازمان', 'در', 'مقابله', 'با', 'کرونا', 'و', 'حفظ', 'آرامش', 'مردم', 'از', 'هیچ', 'چیز', 'دریغ', 'نمی', 'کنند', 'و', 'تلاش', 'دارند', 'تا', 'آخرین', 'لحظه', 'کار', 'کنند', 'و', 'حتی', 'از', 'جان', 'خود', 'هم', 'می', 'گذرند', '</s>', '</s>', '<s>', '<s>', 'در', 'روایات', 'ما', 'به', 'طور', 'مکرر', 'از', 'دو', 'غیبت', 'آن', 'حضرت', 'سخن', 'به', 'میان', 'آمده', 'و', 'از', 'سالها', 'پیش', 'از', 'تولد', 'امام', 'مهدی', 'ع', 'بر', 'این', 'موضوع', 'تصریح', 'شده_است', 'که', 'حضرتش', 'دو', 'غیبت', 'خواهند_داشت', 'که', 'هر', 'یک', 'با', 'دیگری', 'متفاوت', 'است', '</s>', '</s>', '<s>', '<s>', 'نکته', 'مهم', 'این', 'است', 'که', 'نباید', 'انتظار', 'کار', 'ویژهای', 'را', 'در', 'مدت', 'کوتاه', 'داشت', 'اما', 'این', 'ریلگذاری', 'ما', 'را', 'به', 'نقطه', 'خوبی', 'خواهد_رساند', '</s>', '</s>', '<s>', '<s>', 'ارتفاع', 'پست', 'ابراهیم', 'حاتمیکیا', 'هم', 'پسزمینه', 'جنگ', 'دارد', 'و', 'پیامدهای', 'جنگ', 'را', 'بر', 'زندگی', 'مردم', 'خوزستان', 'روایت', 'می', 'کند', 'و', 'سرانجام', 'بمب', '؛', 'یک', 'عاشقانه', 'پیمان', 'معادی', 'که', 'داستان', 'آن', 'در', 'دوران', 'موشکباران', 'شهرها', 'روایت', 'می', 'شود', '</s>', '</s>', '<s>', '<s>', 'وی', 'ادامه', 'داد', 'این', 'مسیر', 'به', 'علت', 'پایین', 'آمدن', 'چند', 'قطعه', 'سنگ', 'بزرگ', 'بر', 'اثر', 'برخورد', 'صاعقه', 'با', 'کوه', 'مسدود', 'شده_است', 'و', 'در', 'سایه', 'تلاش', 'راهدارای', 'و', 'جابهجایی', 'سنگهای', 'کوچک', 'این', 'راه', 'روستایی', 'به', 'صورت', 'موقت', 'و', 'کنارگذر', 'بازگشایی', 'شده_است', '</s>', '</s>', '<s>', '<s>', 'اساسا', 'حمایت', 'از', 'بخش', 'کشاورزی', 'و', 'غذا', 'به', 'لحاظ', 'مبانی', 'تئوریک', 'اجتناب', 'ناپذیر', 'است', '</s>', '</s>']\n",
      "\n",
      "\n",
      "NGRAMS:\n",
      "[('<s>',), ('<s>', '<s>'), ('<s>', '<s>', 'گفتم'), ('<s>',), ('<s>', 'گفتم'), ('<s>', 'گفتم', 'نه'), ('گفتم',), ('گفتم', 'نه'), ('گفتم', 'نه', 'حاجی'), ('نه',), ('نه', 'حاجی'), ('نه', 'حاجی', 'شما'), ('حاجی',), ('حاجی', 'شما'), ('حاجی', 'شما', 'هم'), ('شما',), ('شما', 'هم'), ('شما', 'هم', 'بروید'), ('هم',), ('هم', 'بروید'), ('هم', 'بروید', 'دیگر'), ('بروید',), ('بروید', 'دیگر'), ('بروید', 'دیگر', 'کسی'), ('دیگر',), ('دیگر', 'کسی'), ('دیگر', 'کسی', 'نیست'), ('کسی',), ('کسی', 'نیست'), ('کسی', 'نیست', '</s>'), ('نیست',), ('نیست', '</s>'), ('نیست', '</s>', '</s>'), ('</s>',), ('</s>', '</s>'), ('</s>',)]\n",
      "\n",
      "[('<s>',), ('<s>', '<s>'), ('<s>', '<s>', 'در'), ('<s>',), ('<s>', 'در'), ('<s>', 'در', 'این'), ('در',), ('در', 'این'), ('در', 'این', 'غربال'), ('این',), ('این', 'غربال'), ('این', 'غربال', 'گری'), ('غربال',), ('غربال', 'گری'), ('غربال', 'گری', 'ها'), ('گری',), ('گری', 'ها'), ('گری', 'ها', 'کیس'), ('ها',), ('ها', 'کیس'), ('ها', 'کیس', 'های'), ('کیس',), ('کیس', 'های'), ('کیس', 'های', 'مشکوکی'), ('های',), ('های', 'مشکوکی'), ('های', 'مشکوکی', 'با'), ('مشکوکی',), ('مشکوکی', 'با'), ('مشکوکی', 'با', 'علامت'), ('با',), ('با', 'علامت'), ('با', 'علامت', 'تب'), ('علامت',), ('علامت', 'تب'), ('علامت', 'تب', 'داشتیم'), ('تب',), ('تب', 'داشتیم'), ('تب', 'داشتیم', 'که'), ('داشتیم',), ('داشتیم', 'که'), ('داشتیم', 'که', 'خدا'), ('که',), ('که', 'خدا'), ('که', 'خدا', 'را'), ('خدا',), ('خدا', 'را'), ('خدا', 'را', 'شکر'), ('را',), ('را', 'شکر'), ('را', 'شکر', 'ورزشکاری'), ('شکر',), ('شکر', 'ورزشکاری'), ('شکر', 'ورزشکاری', 'نبود'), ('ورزشکاری',), ('ورزشکاری', 'نبود'), ('ورزشکاری', 'نبود', 'که'), ('نبود',), ('نبود', 'که'), ('نبود', 'که', 'با'), ('که',), ('که', 'با'), ('که', 'با', 'کرونا'), ('با',), ('با', 'کرونا'), ('با', 'کرونا', 'درگیر'), ('کرونا',), ('کرونا', 'درگیر'), ('کرونا', 'درگیر', 'باشد'), ('درگیر',), ('درگیر', 'باشد'), ('درگیر', 'باشد', 'اما'), ('باشد',), ('باشد', 'اما'), ('باشد', 'اما', 'در'), ('اما',), ('اما', 'در'), ('اما', 'در', 'بین'), ('در',), ('در', 'بین'), ('در', 'بین', 'همکاران'), ('بین',), ('بین', 'همکاران'), ('بین', 'همکاران', 'بودند'), ('همکاران',), ('همکاران', 'بودند'), ('همکاران', 'بودند', 'کسانی'), ('بودند',), ('بودند', 'کسانی'), ('بودند', 'کسانی', 'که'), ('کسانی',), ('کسانی', 'که'), ('کسانی', 'که', 'مبتلا'), ('که',), ('که', 'مبتلا'), ('که', 'مبتلا', 'شدند'), ('مبتلا',), ('مبتلا', 'شدند'), ('مبتلا', 'شدند', '</s>'), ('شدند',), ('شدند', '</s>'), ('شدند', '</s>', '</s>'), ('</s>',), ('</s>', '</s>'), ('</s>',)]\n",
      "\n",
      "[('<s>',), ('<s>', '<s>'), ('<s>', '<s>', 'حضرت'), ('<s>',), ('<s>', 'حضرت'), ('<s>', 'حضرت', 'رسول'), ('حضرت',), ('حضرت', 'رسول'), ('حضرت', 'رسول', 'در'), ('رسول',), ('رسول', 'در'), ('رسول', 'در', 'حلقه'), ('در',), ('در', 'حلقه'), ('در', 'حلقه', 'اصحاب'), ('حلقه',), ('حلقه', 'اصحاب'), ('حلقه', 'اصحاب', 'نشسته_بودند'), ('اصحاب',), ('اصحاب', 'نشسته_بودند'), ('اصحاب', 'نشسته_بودند', '</s>'), ('نشسته_بودند',), ('نشسته_بودند', '</s>'), ('نشسته_بودند', '</s>', '</s>'), ('</s>',), ('</s>', '</s>'), ('</s>',)]\n",
      "\n",
      "[('<s>',), ('<s>', '<s>'), ('<s>', '<s>', 'این'), ('<s>',), ('<s>', 'این'), ('<s>', 'این', 'اتفاق'), ('این',), ('این', 'اتفاق'), ('این', 'اتفاق', 'باعث'), ('اتفاق',), ('اتفاق', 'باعث'), ('اتفاق', 'باعث', 'شد'), ('باعث',), ('باعث', 'شد'), ('باعث', 'شد', 'تا'), ('شد',), ('شد', 'تا'), ('شد', 'تا', 'نقش'), ('تا',), ('تا', 'نقش'), ('تا', 'نقش', 'ایالات'), ('نقش',), ('نقش', 'ایالات'), ('نقش', 'ایالات', 'متحده'), ('ایالات',), ('ایالات', 'متحده'), ('ایالات', 'متحده', 'به'), ('متحده',), ('متحده', 'به'), ('متحده', 'به', 'عنوان'), ('به',), ('به', 'عنوان'), ('به', 'عنوان', 'جایگزین'), ('عنوان',), ('عنوان', 'جایگزین'), ('عنوان', 'جایگزین', 'طالبان'), ('جایگزین',), ('جایگزین', 'طالبان'), ('جایگزین', 'طالبان', 'در'), ('طالبان',), ('طالبان', 'در'), ('طالبان', 'در', 'افغانستان'), ('در',), ('در', 'افغانستان'), ('در', 'افغانستان', 'حذف'), ('افغانستان',), ('افغانستان', 'حذف'), ('افغانستان', 'حذف', 'و'), ('حذف',), ('حذف', 'و'), ('حذف', 'و', 'جای'), ('و',), ('و', 'جای'), ('و', 'جای', 'آن'), ('جای',), ('جای', 'آن'), ('جای', 'آن', 'را'), ('آن',), ('آن', 'را'), ('آن', 'را', 'دولتی'), ('را',), ('را', 'دولتی'), ('را', 'دولتی', 'بگیرد'), ('دولتی',), ('دولتی', 'بگیرد'), ('دولتی', 'بگیرد', 'که'), ('بگیرد',), ('بگیرد', 'که'), ('بگیرد', 'که', 'بومی'), ('که',), ('که', 'بومی'), ('که', 'بومی', 'و'), ('بومی',), ('بومی', 'و'), ('بومی', 'و', 'از'), ('و',), ('و', 'از'), ('و', 'از', 'میان'), ('از',), ('از', 'میان'), ('از', 'میان', 'سیاستمداران'), ('میان',), ('میان', 'سیاستمداران'), ('میان', 'سیاستمداران', 'افغان'), ('سیاستمداران',), ('سیاستمداران', 'افغان'), ('سیاستمداران', 'افغان', 'انتخاب'), ('افغان',), ('افغان', 'انتخاب'), ('افغان', 'انتخاب', 'شده_است'), ('انتخاب',), ('انتخاب', 'شده_است'), ('انتخاب', 'شده_است', '</s>'), ('شده_است',), ('شده_است', '</s>'), ('شده_است', '</s>', '</s>'), ('</s>',), ('</s>', '</s>'), ('</s>',)]\n",
      "\n",
      "[('<s>',), ('<s>', '<s>'), ('<s>', '<s>', 'وی'), ('<s>',), ('<s>', 'وی'), ('<s>', 'وی', 'اضافه'), ('وی',), ('وی', 'اضافه'), ('وی', 'اضافه', 'کرد'), ('اضافه',), ('اضافه', 'کرد'), ('اضافه', 'کرد', 'همه'), ('کرد',), ('کرد', 'همه'), ('کرد', 'همه', 'بخشهای'), ('همه',), ('همه', 'بخشهای'), ('همه', 'بخشهای', 'سازمان'), ('بخشهای',), ('بخشهای', 'سازمان'), ('بخشهای', 'سازمان', 'در'), ('سازمان',), ('سازمان', 'در'), ('سازمان', 'در', 'مقابله'), ('در',), ('در', 'مقابله'), ('در', 'مقابله', 'با'), ('مقابله',), ('مقابله', 'با'), ('مقابله', 'با', 'کرونا'), ('با',), ('با', 'کرونا'), ('با', 'کرونا', 'و'), ('کرونا',), ('کرونا', 'و'), ('کرونا', 'و', 'حفظ'), ('و',), ('و', 'حفظ'), ('و', 'حفظ', 'آرامش'), ('حفظ',), ('حفظ', 'آرامش'), ('حفظ', 'آرامش', 'مردم'), ('آرامش',), ('آرامش', 'مردم'), ('آرامش', 'مردم', 'از'), ('مردم',), ('مردم', 'از'), ('مردم', 'از', 'هیچ'), ('از',), ('از', 'هیچ'), ('از', 'هیچ', 'چیز'), ('هیچ',), ('هیچ', 'چیز'), ('هیچ', 'چیز', 'دریغ'), ('چیز',), ('چیز', 'دریغ'), ('چیز', 'دریغ', 'نمی'), ('دریغ',), ('دریغ', 'نمی'), ('دریغ', 'نمی', 'کنند'), ('نمی',), ('نمی', 'کنند'), ('نمی', 'کنند', 'و'), ('کنند',), ('کنند', 'و'), ('کنند', 'و', 'تلاش'), ('و',), ('و', 'تلاش'), ('و', 'تلاش', 'دارند'), ('تلاش',), ('تلاش', 'دارند'), ('تلاش', 'دارند', 'تا'), ('دارند',), ('دارند', 'تا'), ('دارند', 'تا', 'آخرین'), ('تا',), ('تا', 'آخرین'), ('تا', 'آخرین', 'لحظه'), ('آخرین',), ('آخرین', 'لحظه'), ('آخرین', 'لحظه', 'کار'), ('لحظه',), ('لحظه', 'کار'), ('لحظه', 'کار', 'کنند'), ('کار',), ('کار', 'کنند'), ('کار', 'کنند', 'و'), ('کنند',), ('کنند', 'و'), ('کنند', 'و', 'حتی'), ('و',), ('و', 'حتی'), ('و', 'حتی', 'از'), ('حتی',), ('حتی', 'از'), ('حتی', 'از', 'جان'), ('از',), ('از', 'جان'), ('از', 'جان', 'خود'), ('جان',), ('جان', 'خود'), ('جان', 'خود', 'هم'), ('خود',), ('خود', 'هم'), ('خود', 'هم', 'می'), ('هم',), ('هم', 'می'), ('هم', 'می', 'گذرند'), ('می',), ('می', 'گذرند'), ('می', 'گذرند', '</s>'), ('گذرند',), ('گذرند', '</s>'), ('گذرند', '</s>', '</s>'), ('</s>',), ('</s>', '</s>'), ('</s>',)]\n",
      "\n",
      "[('<s>',), ('<s>', '<s>'), ('<s>', '<s>', 'در'), ('<s>',), ('<s>', 'در'), ('<s>', 'در', 'روایات'), ('در',), ('در', 'روایات'), ('در', 'روایات', 'ما'), ('روایات',), ('روایات', 'ما'), ('روایات', 'ما', 'به'), ('ما',), ('ما', 'به'), ('ما', 'به', 'طور'), ('به',), ('به', 'طور'), ('به', 'طور', 'مکرر'), ('طور',), ('طور', 'مکرر'), ('طور', 'مکرر', 'از'), ('مکرر',), ('مکرر', 'از'), ('مکرر', 'از', 'دو'), ('از',), ('از', 'دو'), ('از', 'دو', 'غیبت'), ('دو',), ('دو', 'غیبت'), ('دو', 'غیبت', 'آن'), ('غیبت',), ('غیبت', 'آن'), ('غیبت', 'آن', 'حضرت'), ('آن',), ('آن', 'حضرت'), ('آن', 'حضرت', 'سخن'), ('حضرت',), ('حضرت', 'سخن'), ('حضرت', 'سخن', 'به'), ('سخن',), ('سخن', 'به'), ('سخن', 'به', 'میان'), ('به',), ('به', 'میان'), ('به', 'میان', 'آمده'), ('میان',), ('میان', 'آمده'), ('میان', 'آمده', 'و'), ('آمده',), ('آمده', 'و'), ('آمده', 'و', 'از'), ('و',), ('و', 'از'), ('و', 'از', 'سالها'), ('از',), ('از', 'سالها'), ('از', 'سالها', 'پیش'), ('سالها',), ('سالها', 'پیش'), ('سالها', 'پیش', 'از'), ('پیش',), ('پیش', 'از'), ('پیش', 'از', 'تولد'), ('از',), ('از', 'تولد'), ('از', 'تولد', 'امام'), ('تولد',), ('تولد', 'امام'), ('تولد', 'امام', 'مهدی'), ('امام',), ('امام', 'مهدی'), ('امام', 'مهدی', 'ع'), ('مهدی',), ('مهدی', 'ع'), ('مهدی', 'ع', 'بر'), ('ع',), ('ع', 'بر'), ('ع', 'بر', 'این'), ('بر',), ('بر', 'این'), ('بر', 'این', 'موضوع'), ('این',), ('این', 'موضوع'), ('این', 'موضوع', 'تصریح'), ('موضوع',), ('موضوع', 'تصریح'), ('موضوع', 'تصریح', 'شده_است'), ('تصریح',), ('تصریح', 'شده_است'), ('تصریح', 'شده_است', 'که'), ('شده_است',), ('شده_است', 'که'), ('شده_است', 'که', 'حضرتش'), ('که',), ('که', 'حضرتش'), ('که', 'حضرتش', 'دو'), ('حضرتش',), ('حضرتش', 'دو'), ('حضرتش', 'دو', 'غیبت'), ('دو',), ('دو', 'غیبت'), ('دو', 'غیبت', 'خواهند_داشت'), ('غیبت',), ('غیبت', 'خواهند_داشت'), ('غیبت', 'خواهند_داشت', 'که'), ('خواهند_داشت',), ('خواهند_داشت', 'که'), ('خواهند_داشت', 'که', 'هر'), ('که',), ('که', 'هر'), ('که', 'هر', 'یک'), ('هر',), ('هر', 'یک'), ('هر', 'یک', 'با'), ('یک',), ('یک', 'با'), ('یک', 'با', 'دیگری'), ('با',), ('با', 'دیگری'), ('با', 'دیگری', 'متفاوت'), ('دیگری',), ('دیگری', 'متفاوت'), ('دیگری', 'متفاوت', 'است'), ('متفاوت',), ('متفاوت', 'است'), ('متفاوت', 'است', '</s>'), ('است',), ('است', '</s>'), ('است', '</s>', '</s>'), ('</s>',), ('</s>', '</s>'), ('</s>',)]\n",
      "\n",
      "[('<s>',), ('<s>', '<s>'), ('<s>', '<s>', 'نکته'), ('<s>',), ('<s>', 'نکته'), ('<s>', 'نکته', 'مهم'), ('نکته',), ('نکته', 'مهم'), ('نکته', 'مهم', 'این'), ('مهم',), ('مهم', 'این'), ('مهم', 'این', 'است'), ('این',), ('این', 'است'), ('این', 'است', 'که'), ('است',), ('است', 'که'), ('است', 'که', 'نباید'), ('که',), ('که', 'نباید'), ('که', 'نباید', 'انتظار'), ('نباید',), ('نباید', 'انتظار'), ('نباید', 'انتظار', 'کار'), ('انتظار',), ('انتظار', 'کار'), ('انتظار', 'کار', 'ویژهای'), ('کار',), ('کار', 'ویژهای'), ('کار', 'ویژهای', 'را'), ('ویژهای',), ('ویژهای', 'را'), ('ویژهای', 'را', 'در'), ('را',), ('را', 'در'), ('را', 'در', 'مدت'), ('در',), ('در', 'مدت'), ('در', 'مدت', 'کوتاه'), ('مدت',), ('مدت', 'کوتاه'), ('مدت', 'کوتاه', 'داشت'), ('کوتاه',), ('کوتاه', 'داشت'), ('کوتاه', 'داشت', 'اما'), ('داشت',), ('داشت', 'اما'), ('داشت', 'اما', 'این'), ('اما',), ('اما', 'این'), ('اما', 'این', 'ریلگذاری'), ('این',), ('این', 'ریلگذاری'), ('این', 'ریلگذاری', 'ما'), ('ریلگذاری',), ('ریلگذاری', 'ما'), ('ریلگذاری', 'ما', 'را'), ('ما',), ('ما', 'را'), ('ما', 'را', 'به'), ('را',), ('را', 'به'), ('را', 'به', 'نقطه'), ('به',), ('به', 'نقطه'), ('به', 'نقطه', 'خوبی'), ('نقطه',), ('نقطه', 'خوبی'), ('نقطه', 'خوبی', 'خواهد_رساند'), ('خوبی',), ('خوبی', 'خواهد_رساند'), ('خوبی', 'خواهد_رساند', '</s>'), ('خواهد_رساند',), ('خواهد_رساند', '</s>'), ('خواهد_رساند', '</s>', '</s>'), ('</s>',), ('</s>', '</s>'), ('</s>',)]\n",
      "\n",
      "[('<s>',), ('<s>', '<s>'), ('<s>', '<s>', 'ارتفاع'), ('<s>',), ('<s>', 'ارتفاع'), ('<s>', 'ارتفاع', 'پست'), ('ارتفاع',), ('ارتفاع', 'پست'), ('ارتفاع', 'پست', 'ابراهیم'), ('پست',), ('پست', 'ابراهیم'), ('پست', 'ابراهیم', 'حاتمیکیا'), ('ابراهیم',), ('ابراهیم', 'حاتمیکیا'), ('ابراهیم', 'حاتمیکیا', 'هم'), ('حاتمیکیا',), ('حاتمیکیا', 'هم'), ('حاتمیکیا', 'هم', 'پسزمینه'), ('هم',), ('هم', 'پسزمینه'), ('هم', 'پسزمینه', 'جنگ'), ('پسزمینه',), ('پسزمینه', 'جنگ'), ('پسزمینه', 'جنگ', 'دارد'), ('جنگ',), ('جنگ', 'دارد'), ('جنگ', 'دارد', 'و'), ('دارد',), ('دارد', 'و'), ('دارد', 'و', 'پیامدهای'), ('و',), ('و', 'پیامدهای'), ('و', 'پیامدهای', 'جنگ'), ('پیامدهای',), ('پیامدهای', 'جنگ'), ('پیامدهای', 'جنگ', 'را'), ('جنگ',), ('جنگ', 'را'), ('جنگ', 'را', 'بر'), ('را',), ('را', 'بر'), ('را', 'بر', 'زندگی'), ('بر',), ('بر', 'زندگی'), ('بر', 'زندگی', 'مردم'), ('زندگی',), ('زندگی', 'مردم'), ('زندگی', 'مردم', 'خوزستان'), ('مردم',), ('مردم', 'خوزستان'), ('مردم', 'خوزستان', 'روایت'), ('خوزستان',), ('خوزستان', 'روایت'), ('خوزستان', 'روایت', 'می'), ('روایت',), ('روایت', 'می'), ('روایت', 'می', 'کند'), ('می',), ('می', 'کند'), ('می', 'کند', 'و'), ('کند',), ('کند', 'و'), ('کند', 'و', 'سرانجام'), ('و',), ('و', 'سرانجام'), ('و', 'سرانجام', 'بمب'), ('سرانجام',), ('سرانجام', 'بمب'), ('سرانجام', 'بمب', '؛'), ('بمب',), ('بمب', '؛'), ('بمب', '؛', 'یک'), ('؛',), ('؛', 'یک'), ('؛', 'یک', 'عاشقانه'), ('یک',), ('یک', 'عاشقانه'), ('یک', 'عاشقانه', 'پیمان'), ('عاشقانه',), ('عاشقانه', 'پیمان'), ('عاشقانه', 'پیمان', 'معادی'), ('پیمان',), ('پیمان', 'معادی'), ('پیمان', 'معادی', 'که'), ('معادی',), ('معادی', 'که'), ('معادی', 'که', 'داستان'), ('که',), ('که', 'داستان'), ('که', 'داستان', 'آن'), ('داستان',), ('داستان', 'آن'), ('داستان', 'آن', 'در'), ('آن',), ('آن', 'در'), ('آن', 'در', 'دوران'), ('در',), ('در', 'دوران'), ('در', 'دوران', 'موشکباران'), ('دوران',), ('دوران', 'موشکباران'), ('دوران', 'موشکباران', 'شهرها'), ('موشکباران',), ('موشکباران', 'شهرها'), ('موشکباران', 'شهرها', 'روایت'), ('شهرها',), ('شهرها', 'روایت'), ('شهرها', 'روایت', 'می'), ('روایت',), ('روایت', 'می'), ('روایت', 'می', 'شود'), ('می',), ('می', 'شود'), ('می', 'شود', '</s>'), ('شود',), ('شود', '</s>'), ('شود', '</s>', '</s>'), ('</s>',), ('</s>', '</s>'), ('</s>',)]\n",
      "\n",
      "[('<s>',), ('<s>', '<s>'), ('<s>', '<s>', 'وی'), ('<s>',), ('<s>', 'وی'), ('<s>', 'وی', 'ادامه'), ('وی',), ('وی', 'ادامه'), ('وی', 'ادامه', 'داد'), ('ادامه',), ('ادامه', 'داد'), ('ادامه', 'داد', 'این'), ('داد',), ('داد', 'این'), ('داد', 'این', 'مسیر'), ('این',), ('این', 'مسیر'), ('این', 'مسیر', 'به'), ('مسیر',), ('مسیر', 'به'), ('مسیر', 'به', 'علت'), ('به',), ('به', 'علت'), ('به', 'علت', 'پایین'), ('علت',), ('علت', 'پایین'), ('علت', 'پایین', 'آمدن'), ('پایین',), ('پایین', 'آمدن'), ('پایین', 'آمدن', 'چند'), ('آمدن',), ('آمدن', 'چند'), ('آمدن', 'چند', 'قطعه'), ('چند',), ('چند', 'قطعه'), ('چند', 'قطعه', 'سنگ'), ('قطعه',), ('قطعه', 'سنگ'), ('قطعه', 'سنگ', 'بزرگ'), ('سنگ',), ('سنگ', 'بزرگ'), ('سنگ', 'بزرگ', 'بر'), ('بزرگ',), ('بزرگ', 'بر'), ('بزرگ', 'بر', 'اثر'), ('بر',), ('بر', 'اثر'), ('بر', 'اثر', 'برخورد'), ('اثر',), ('اثر', 'برخورد'), ('اثر', 'برخورد', 'صاعقه'), ('برخورد',), ('برخورد', 'صاعقه'), ('برخورد', 'صاعقه', 'با'), ('صاعقه',), ('صاعقه', 'با'), ('صاعقه', 'با', 'کوه'), ('با',), ('با', 'کوه'), ('با', 'کوه', 'مسدود'), ('کوه',), ('کوه', 'مسدود'), ('کوه', 'مسدود', 'شده_است'), ('مسدود',), ('مسدود', 'شده_است'), ('مسدود', 'شده_است', 'و'), ('شده_است',), ('شده_است', 'و'), ('شده_است', 'و', 'در'), ('و',), ('و', 'در'), ('و', 'در', 'سایه'), ('در',), ('در', 'سایه'), ('در', 'سایه', 'تلاش'), ('سایه',), ('سایه', 'تلاش'), ('سایه', 'تلاش', 'راهدارای'), ('تلاش',), ('تلاش', 'راهدارای'), ('تلاش', 'راهدارای', 'و'), ('راهدارای',), ('راهدارای', 'و'), ('راهدارای', 'و', 'جابهجایی'), ('و',), ('و', 'جابهجایی'), ('و', 'جابهجایی', 'سنگهای'), ('جابهجایی',), ('جابهجایی', 'سنگهای'), ('جابهجایی', 'سنگهای', 'کوچک'), ('سنگهای',), ('سنگهای', 'کوچک'), ('سنگهای', 'کوچک', 'این'), ('کوچک',), ('کوچک', 'این'), ('کوچک', 'این', 'راه'), ('این',), ('این', 'راه'), ('این', 'راه', 'روستایی'), ('راه',), ('راه', 'روستایی'), ('راه', 'روستایی', 'به'), ('روستایی',), ('روستایی', 'به'), ('روستایی', 'به', 'صورت'), ('به',), ('به', 'صورت'), ('به', 'صورت', 'موقت'), ('صورت',), ('صورت', 'موقت'), ('صورت', 'موقت', 'و'), ('موقت',), ('موقت', 'و'), ('موقت', 'و', 'کنارگذر'), ('و',), ('و', 'کنارگذر'), ('و', 'کنارگذر', 'بازگشایی'), ('کنارگذر',), ('کنارگذر', 'بازگشایی'), ('کنارگذر', 'بازگشایی', 'شده_است'), ('بازگشایی',), ('بازگشایی', 'شده_است'), ('بازگشایی', 'شده_است', '</s>'), ('شده_است',), ('شده_است', '</s>'), ('شده_است', '</s>', '</s>'), ('</s>',), ('</s>', '</s>'), ('</s>',)]\n",
      "\n",
      "[('<s>',), ('<s>', '<s>'), ('<s>', '<s>', 'اساسا'), ('<s>',), ('<s>', 'اساسا'), ('<s>', 'اساسا', 'حمایت'), ('اساسا',), ('اساسا', 'حمایت'), ('اساسا', 'حمایت', 'از'), ('حمایت',), ('حمایت', 'از'), ('حمایت', 'از', 'بخش'), ('از',), ('از', 'بخش'), ('از', 'بخش', 'کشاورزی'), ('بخش',), ('بخش', 'کشاورزی'), ('بخش', 'کشاورزی', 'و'), ('کشاورزی',), ('کشاورزی', 'و'), ('کشاورزی', 'و', 'غذا'), ('و',), ('و', 'غذا'), ('و', 'غذا', 'به'), ('غذا',), ('غذا', 'به'), ('غذا', 'به', 'لحاظ'), ('به',), ('به', 'لحاظ'), ('به', 'لحاظ', 'مبانی'), ('لحاظ',), ('لحاظ', 'مبانی'), ('لحاظ', 'مبانی', 'تئوریک'), ('مبانی',), ('مبانی', 'تئوریک'), ('مبانی', 'تئوریک', 'اجتناب'), ('تئوریک',), ('تئوریک', 'اجتناب'), ('تئوریک', 'اجتناب', 'ناپذیر'), ('اجتناب',), ('اجتناب', 'ناپذیر'), ('اجتناب', 'ناپذیر', 'است'), ('ناپذیر',), ('ناپذیر', 'است'), ('ناپذیر', 'است', '</s>'), ('است',), ('است', '</s>'), ('است', '</s>', '</s>'), ('</s>',), ('</s>', '</s>'), ('</s>',)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from nltk import word_tokenize\n",
    "from nltk.lm import MLE\n",
    "from nltk.lm.preprocessing import pad_both_ends, padded_everygram_pipeline\n",
    "from nltk.lm.preprocessing import padded_everygram_pipeline\n",
    "\n",
    "# The n-gram size\n",
    "n = 3\n",
    "\n",
    "ngram_data, padded = padded_everygram_pipeline(n, train_corpus[0:10])\n",
    "\n",
    "# Padding adds special tokens (start symbol <s>) and (end symbol </s>) to the text to signify sentence boundaries.\n",
    "# This ensures that n-grams near the edges of a sentence (e.g., start or end) still form complete n-grams\n",
    "\n",
    "print(\"PADDING:\")\n",
    "print(list(padded))\n",
    "\n",
    "# Unigrams: Individual words or tokens, e.g., ('<s>',), ('i',).\n",
    "# Bigrams: Pairs of tokens, e.g., ('<s>', '<s>'), ('<s>', 'i').\n",
    "# Trigrams: Groups of three tokens, e.g., ('<s>', '<s>', 'i'), ('<s>', 'i', 'j').\n",
    "# Padding ensures valid n-grams even at sentence start/end.\n",
    "\n",
    "print(\"\\n\\nNGRAMS:\")\n",
    "for ngrams in ngram_data:\n",
    "    print(list(ngrams))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T15:53:29.242050Z",
     "iopub.status.busy": "2024-12-11T15:53:29.241799Z",
     "iopub.status.idle": "2024-12-11T15:54:02.224218Z",
     "shell.execute_reply": "2024-12-11T15:54:02.223189Z",
     "shell.execute_reply.started": "2024-12-11T15:53:29.242025Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from nltk.lm import MLE\n",
    "\n",
    "n=3\n",
    "\n",
    "# Train data is an iterator over the pre-processed input\n",
    "train_data, padded_sents = padded_everygram_pipeline(n, train_corpus)\n",
    "\n",
    "model = MLE(n)\n",
    "model.fit(train_data, padded_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T15:54:02.225683Z",
     "iopub.status.busy": "2024-12-11T15:54:02.225412Z",
     "iopub.status.idle": "2024-12-11T15:54:02.265202Z",
     "shell.execute_reply": "2024-12-11T15:54:02.264194Z",
     "shell.execute_reply.started": "2024-12-11T15:54:02.225656Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Vocabulary:<Vocabulary with cutoff=1 unk_label='<UNK>' and 55596 items>\n",
      "\n",
      "\n",
      "Most Common Vocabs:[('<s>', 160000), ('</s>', 160000), ('و', 80719), ('در', 68527), ('به', 57179), ('از', 46674), ('این', 36084), ('که', 35697), ('می', 30555), ('را', 28863), ('با', 27374), ('است', 18993), ('برای', 13186), ('کرد', 10405), ('های', 9607), ('شود', 9191), ('یک', 8464), ('هم', 8270), ('آن', 7960), ('تا', 7281), ('گفت', 7094), ('شد', 7079), ('خود', 6456), ('بر', 6087), ('کند', 5926), ('وی', 5505), ('ایران', 5451), ('ما', 5314), ('سال', 5265), ('کشور', 5088), ('ها', 5024), ('نیز', 4921), ('باید', 4874), ('اما', 4793), ('دارد', 4758), ('کنند', 4755), ('کرونا', 4622), ('بود', 4471), ('او', 4449), ('؟', 4187), ('شده', 4133), ('مردم', 4115), ('داد', 4090), ('استان', 3984), ('قرار', 3791), ('روز', 3528), ('یا', 3503), ('اینکه', 3433), ('آنها', 3430), ('نمی', 3360)]\n",
      "\n",
      "\n",
      "Least Common Vocabs:[('ورشوه', 1), ('چکارمیکنن', 1), ('روچه', 1), ('روو', 1), ('آمادگیاش', 1), ('بوردو', 1), ('۶۱۳', 1), ('نینوی', 1), ('سرطانزادیی', 1), ('چاپگرهای', 1), ('حقا', 1), ('جهانپوری', 1), ('مقابلت', 1), ('سیداحد', 1), ('یوزباشی', 1), ('آبرومندانهتر', 1), ('سرگیرند', 1), ('کوچولوهای', 1), ('بهانهگیر', 1), ('دزدیده_شد', 1), ('پایگاهایش', 1), ('حتیالامکان', 1), ('کنگیها', 1), ('گچپزان', 1), ('بسته_نشد', 1), ('گزارشهایشان', 1), ('رسمیتر', 1), ('علنیتر', 1), ('دفترآیتالله', 1), ('دشنام', 1), ('نامتناسب', 1), ('غیرقابلتصور', 1), ('پایانناپذیر', 1), ('ادعاهایمان', 1), ('پران', 1), ('نگرشهای', 1), ('خواهد_نقش', 1), ('۰۲۵۳۷۸۴۱۱۳۰', 1), ('۰۲۵۳۷۸۴۱۱۳۱', 1), ('سوختکی', 1), ('پرسشگر', 1), ('ایولین', 1), ('دروازهبانان', 1), ('نفعمان', 1), ('کاردستیمان', 1), ('پرچمهایی', 1), ('تورات', 1), ('ونژاد', 1), ('علیفر', 1), ('نفروشد', 1)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nVocabulary:{model.vocab}\\n\")\n",
    "print(f\"\\nMost Common Vocabs:{model.vocab.counts.most_common(50)}\\n\")\n",
    "print(f\"\\nLeast Common Vocabs:{model.vocab.counts.most_common()[-50:]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-09T18:52:59.569574Z",
     "iopub.status.busy": "2024-12-09T18:52:59.569242Z",
     "iopub.status.idle": "2024-12-09T18:52:59.902485Z",
     "shell.execute_reply": "2024-12-09T18:52:59.901588Z",
     "shell.execute_reply.started": "2024-12-09T18:52:59.569547Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<NgramCounter with 3 ngram orders and 6485628 ngrams>\n",
      "1033\n",
      "475\n",
      "397\n"
     ]
    }
   ],
   "source": [
    "print(model.counts)\n",
    "#('دانشگاه', 'علوم', 'پزشکی'): 397\n",
    "\n",
    "# counts for unigrams:\n",
    "print(model.counts['پزشکی']) # i.e. Count('not')\n",
    "\n",
    "# count for bigrams\n",
    "print(model.counts[['علوم']]['پزشکی']) # i.e. Count('not'|'was')\n",
    "\n",
    "# count for trigrams\n",
    "print(model.counts[['دانشگاه', 'علوم']]['پزشکی']) # i.e. Count('not'|'emma was')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T19:13:08.731069Z",
     "iopub.status.busy": "2024-12-11T19:13:08.730398Z",
     "iopub.status.idle": "2024-12-11T19:13:08.970854Z",
     "shell.execute_reply": "2024-12-11T19:13:08.969900Z",
     "shell.execute_reply.started": "2024-12-11T19:13:08.731026Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_corpus' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m all_tokens \u001b[38;5;241m=\u001b[39m [tok \u001b[38;5;28;01mfor\u001b[39;00m sent \u001b[38;5;129;01min\u001b[39;00m \u001b[43mtrain_corpus\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m tok \u001b[38;5;129;01min\u001b[39;00m sent]\n\u001b[1;32m      2\u001b[0m num_tokens \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(all_tokens)\n\u001b[1;32m      3\u001b[0m num_sentences \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(train_corpus)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_corpus' is not defined"
     ]
    }
   ],
   "source": [
    "all_tokens = [tok for sent in train_corpus for tok in sent]\n",
    "num_tokens = len(all_tokens)\n",
    "num_sentences = len(train_corpus)\n",
    "\n",
    "model_score = model.score('دانشگاه')\n",
    "probability = model.counts['دانشگاه']/num_tokens\n",
    "\n",
    "\n",
    "print(\"\\nProbability of the word 'دانشگاه'\")\n",
    "print(\"{:.5f}\".format(model_score))\n",
    "print(\"{:.5f}\".format(probability))\n",
    "\n",
    "print(\"\\nAdjust for padding tokens\")\n",
    "all_padding_tokens = num_sentences * (n-1) * 2\n",
    "print(num_tokens, all_padding_tokens)\n",
    "\n",
    "adjusted_probability = model.counts['دانشگاه']/(num_tokens + all_padding_tokens)\n",
    "print(\"{:.5f}\".format(adjusted_probability))\n",
    "\n",
    "print(\"\\nProbabilities padding tokens\")\n",
    "print(\"{:.5f}\".format(model.score('<s>')))\n",
    "print(\"{:.5f}\".format(model.score('</s>')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T19:13:13.882267Z",
     "iopub.status.busy": "2024-12-11T19:13:13.881932Z",
     "iopub.status.idle": "2024-12-11T19:13:13.900927Z",
     "shell.execute_reply": "2024-12-11T19:13:13.899784Z",
     "shell.execute_reply.started": "2024-12-11T19:13:13.882237Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# bigram\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mscore(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mپزشکی\u001b[39m\u001b[38;5;124m'\u001b[39m, [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mعلوم\u001b[39m\u001b[38;5;124m'\u001b[39m]))  \u001b[38;5;66;03m# P('not'|'is')\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# trigram\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(model\u001b[38;5;241m.\u001b[39mscore(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mپزشکی\u001b[39m\u001b[38;5;124m'\u001b[39m, [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mدانشگاه\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mعلوم\u001b[39m\u001b[38;5;124m'\u001b[39m]))  \u001b[38;5;66;03m# P('not'|'emma is')\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# bigram\n",
    "print(model.score('پزشکی', ['علوم']))  # P('not'|'is')\n",
    "\n",
    "# trigram\n",
    "print(model.score('پزشکی', ['دانشگاه', 'علوم']))  # P('not'|'emma is')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-09T18:53:00.071091Z",
     "iopub.status.busy": "2024-12-09T18:53:00.070838Z",
     "iopub.status.idle": "2024-12-09T18:53:00.079399Z",
     "shell.execute_reply": "2024-12-09T18:53:00.078664Z",
     "shell.execute_reply.started": "2024-12-09T18:53:00.071067Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09771689497716896\n",
      "-3.3552481680873885\n"
     ]
    }
   ],
   "source": [
    "# To avoid underflow when working with many small score values, we usually work with log probabilities instead.\n",
    "# This can be done with the `logscore` method.\n",
    "\n",
    "#('هزار', 'نفر'): 690\n",
    "print(model.score('نفر', ['هزار']))\n",
    "print(model.logscore('نفر', ['هزار']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T19:13:23.666480Z",
     "iopub.status.busy": "2024-12-11T19:13:23.665889Z",
     "iopub.status.idle": "2024-12-11T19:13:23.683363Z",
     "shell.execute_reply": "2024-12-11T19:13:23.682257Z",
     "shell.execute_reply.started": "2024-12-11T19:13:23.666445Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# The vocabulary helps us handle words that have not occurred during training.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# If we lookup the vocab on unseen sentences not from the training data,\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# it automatically replace words not in the vocabulary with `<UNK>`.\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mvocab\u001b[38;5;241m.\u001b[39mlookup(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mدر دانشگاه علوم پزشکی موژان قدم می زند\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39msplit()))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# The vocabulary helps us handle words that have not occurred during training.\n",
    "# If we lookup the vocab on unseen sentences not from the training data,\n",
    "# it automatically replace words not in the vocabulary with `<UNK>`.\n",
    "\n",
    "print(model.vocab.lookup('در دانشگاه علوم پزشکی موژان قدم می زند'.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-09T18:53:00.090995Z",
     "iopub.status.busy": "2024-12-09T18:53:00.090754Z",
     "iopub.status.idle": "2024-12-09T18:53:00.103989Z",
     "shell.execute_reply": "2024-12-09T18:53:00.103265Z",
     "shell.execute_reply.started": "2024-12-09T18:53:00.090971Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "0.0 -inf\n",
      "0.0 -inf\n"
     ]
    }
   ],
   "source": [
    "# Items that are not seen during training are mapped to the vocabulary's \"unknown label\" token.  This is \"<UNK>\" by default.\n",
    "print(model.score(\"<UNK>\") == model.score(\"موژان\"))\n",
    "\n",
    "# The MLE model does not apply any smoothing, so the probability for UNK is 0\n",
    "print(model.score(\"<UNK>\"),model.logscore(\"<UNK>\") )\n",
    "\n",
    "# As a consequence, the probability for a phrase containing an unknown word is also 0.\n",
    "print(model.score('موژان', ['علوم', 'پزشکی']), model.logscore('موژان', ['علوم', 'پزشکی']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-09T18:53:00.105229Z",
     "iopub.status.busy": "2024-12-09T18:53:00.104900Z",
     "iopub.status.idle": "2024-12-09T18:54:20.173357Z",
     "shell.execute_reply": "2024-12-09T18:54:20.172448Z",
     "shell.execute_reply.started": "2024-12-09T18:53:00.105190Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00025673627072228473\n",
      "0.0003950376546530393\n",
      "1.7834531219346898e-05\n",
      "\n",
      "-11.927425250778018\n",
      "-11.305722203241844\n",
      "-15.774967179372865\n"
     ]
    }
   ],
   "source": [
    "from nltk.lm import Laplace\n",
    "n = 5\n",
    "train_data, padded_sents = padded_everygram_pipeline(n, train_corpus)\n",
    "smoothed_model_small =  Laplace(n)\n",
    "smoothed_model_small.fit(train_data, padded_sents)\n",
    "\n",
    "print(smoothed_model_small.score('علوم'))\n",
    "print(smoothed_model_small.score('پزشکی'))\n",
    "print(smoothed_model_small.score('موژان', ['علوم', 'پزشکی']))\n",
    "print()\n",
    "print(smoothed_model_small.logscore('علوم'))\n",
    "print(smoothed_model_small.logscore('پزشکی'))\n",
    "print(smoothed_model_small.logscore('موژان', ['علوم', 'پزشکی']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-09T18:54:20.175014Z",
     "iopub.status.busy": "2024-12-09T18:54:20.174622Z",
     "iopub.status.idle": "2024-12-09T18:54:20.182616Z",
     "shell.execute_reply": "2024-12-09T18:54:20.181745Z",
     "shell.execute_reply.started": "2024-12-09T18:54:20.174972Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['شیراز',\n",
       " 'در',\n",
       " 'پاسخ',\n",
       " 'به',\n",
       " 'پرسش',\n",
       " 'یکی',\n",
       " 'از',\n",
       " 'دانشجویان',\n",
       " 'مبنی',\n",
       " 'بر',\n",
       " 'آنکه',\n",
       " 'آیا',\n",
       " 'شما',\n",
       " 'هویدا',\n",
       " 'را',\n",
       " 'پیش',\n",
       " 'از',\n",
       " 'محاکمه',\n",
       " 'زدید',\n",
       " 'گفت',\n",
       " 'این',\n",
       " 'دروغ',\n",
       " 'است',\n",
       " '</s>',\n",
       " '</s>',\n",
       " '</s>',\n",
       " '</s>',\n",
       " '</s>',\n",
       " '</s>',\n",
       " '</s>',\n",
       " '</s>',\n",
       " '</s>',\n",
       " '</s>',\n",
       " '</s>',\n",
       " '</s>',\n",
       " '</s>',\n",
       " '</s>',\n",
       " '</s>',\n",
       " '</s>',\n",
       " '</s>']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smoothed_model_small.generate(text_seed=[\"در\", \"دانشگاه\", \"علوم\", \"پزشکی\"], num_words=40, random_seed=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-09T18:54:20.184040Z",
     "iopub.status.busy": "2024-12-09T18:54:20.183746Z",
     "iopub.status.idle": "2024-12-09T18:54:30.868406Z",
     "shell.execute_reply": "2024-12-09T18:54:30.867573Z",
     "shell.execute_reply.started": "2024-12-09T18:54:20.184013Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "136.84879397221403\n",
      "['بیشتر', 'استفاده', 'شود']\n"
     ]
    }
   ],
   "source": [
    "test_data, _ = padded_everygram_pipeline(n, val_corpus)\n",
    "\n",
    "perplexity = []\n",
    "for test in test_data:\n",
    "  perplexity.append(smoothed_model_small.perplexity(test))\n",
    "\n",
    "values = []\n",
    "for i in range(len(perplexity)):\n",
    "  if not np.isinf(perplexity[i]):\n",
    "    values.append(i)\n",
    "\n",
    "valid_perplexity = [perplexity[i] for i in values]\n",
    "idx = np.argpartition(valid_perplexity, 10)\n",
    "\n",
    "min = np.argmin(valid_perplexity)\n",
    "print(perplexity[min])\n",
    "print(val_corpus[min])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-09T18:54:30.870236Z",
     "iopub.status.busy": "2024-12-09T18:54:30.869603Z",
     "iopub.status.idle": "2024-12-09T18:54:30.875039Z",
     "shell.execute_reply": "2024-12-09T18:54:30.874111Z",
     "shell.execute_reply.started": "2024-12-09T18:54:30.870195Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Convert the list to a NumPy array\n",
    "values_array = np.array(perplexity)\n",
    "\n",
    "# Get the indices that would sort the array\n",
    "sorted_indices = np.argsort(values_array)\n",
    "\n",
    "# Get the first 10 indices of the smallest values\n",
    "top_20_indices = sorted_indices[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-09T18:54:30.876318Z",
     "iopub.status.busy": "2024-12-09T18:54:30.876066Z",
     "iopub.status.idle": "2024-12-09T18:54:30.889969Z",
     "shell.execute_reply": "2024-12-09T18:54:30.889229Z",
     "shell.execute_reply.started": "2024-12-09T18:54:30.876293Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(['بیشتر', 'استفاده', 'شود']):136.84879397221403\n",
      "(['۴', 'درصد', 'بوده_است']):137.37757536063077\n",
      "(['در', 'نظر', 'گرفتهایم']):155.21181914518752\n",
      "(['۲', 'درصد', 'اعلام', 'شد']):159.41539629904034\n",
      "(['۹', 'درصد', 'افزایش', 'است']):167.88098852565022\n",
      "(['۸', 'درصد', 'افزایش', 'داشته_است']):175.70886198671326\n",
      "(['۹', 'درصد', 'اعلام', 'شد']):183.26984989234003\n",
      "(['به', 'گزارش', 'همشهری', 'آنلاین', 'به', 'نقل', 'از', 'نشریه', 'آ']):188.5691340823012\n",
      "(['اینجا', 'چطور', 'است', '؟']):193.56459410705116\n",
      "(['آن', 'را', 'پیدا', 'کنید']):193.70443425101107\n",
      "(['۶', 'درصد', 'افزایش', 'داشته_است']):200.6723100682942\n",
      "(['این', 'سیاست', 'استکباری', 'است']):201.01668563197362\n",
      "(['۶', 'درصد', 'رشد', 'داشته_است']):204.0636579908888\n",
      "(['این', 'خسارت', 'همچنان', 'ادامه', 'دارد']):204.44801120950063\n",
      "(['در', 'همین', 'رابطه', 'بخوانید', '؛']):206.89433492071743\n",
      "(['۵', 'درصد', 'رشد', 'نشان', 'می', 'دهد']):212.98259222906185\n",
      "(['این', 'زمان', 'زیادی', 'نیست']):214.94726810950934\n",
      "(['در', 'جلسات', 'اطلاعاتی', 'مطرح', 'می', 'شود']):216.3339858482399\n",
      "(['۶', 'درصد', 'برآورد', 'شده_است']):218.54417523894674\n",
      "(['۵', 'متقاضی', 'وجود', 'دارد']):218.71649941201267\n"
     ]
    }
   ],
   "source": [
    "for i in top_20_indices:\n",
    "  print(\"({0}):{1}\".format(val_corpus[i], perplexity[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run from this cell ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T13:32:57.301592Z",
     "iopub.status.busy": "2024-12-11T13:32:57.300764Z",
     "iopub.status.idle": "2024-12-11T13:33:05.515434Z",
     "shell.execute_reply": "2024-12-11T13:33:05.514280Z",
     "shell.execute_reply.started": "2024-12-11T13:32:57.301547Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tiktoken\n",
      "  Downloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /opt/conda/lib/python3.10/site-packages (from tiktoken) (2024.5.15)\n",
      "Requirement already satisfied: requests>=2.26.0 in /opt/conda/lib/python3.10/site-packages (from tiktoken) (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (2024.6.2)\n",
      "Downloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m31.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tiktoken\n",
      "Successfully installed tiktoken-0.8.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T13:33:05.517478Z",
     "iopub.status.busy": "2024-12-11T13:33:05.517028Z",
     "iopub.status.idle": "2024-12-11T13:33:05.534631Z",
     "shell.execute_reply": "2024-12-11T13:33:05.533701Z",
     "shell.execute_reply.started": "2024-12-11T13:33:05.517431Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from importlib.metadata import version\n",
    "import math\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T13:33:05.536599Z",
     "iopub.status.busy": "2024-12-11T13:33:05.536309Z",
     "iopub.status.idle": "2024-12-11T13:33:05.968105Z",
     "shell.execute_reply": "2024-12-11T13:33:05.967239Z",
     "shell.execute_reply.started": "2024-12-11T13:33:05.536564Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of character: 19998594\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "formatted_text = \"\\n\".join([f\"{i+1}\\t{sentence}\" for i, sentence in enumerate(cleaned_sentences)])\n",
    "\n",
    "print(\"Total number of character:\", len(formatted_text))\n",
    "print(type(formatted_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T13:54:58.841731Z",
     "iopub.status.busy": "2024-12-11T13:54:58.840946Z",
     "iopub.status.idle": "2024-12-11T13:55:31.840604Z",
     "shell.execute_reply": "2024-12-11T13:55:31.839621Z",
     "shell.execute_reply.started": "2024-12-11T13:54:58.841695Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of tokens: 13856684\n",
      "First 10 tokens: [5, 43, 24935, 43, 24940, 24941, 17, 17, 17, 43]\n"
     ]
    }
   ],
   "source": [
    "with open(persian_text_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    raw_text = f.read()\n",
    "    \n",
    "# Initialize the tokenizer\n",
    "# tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "tokenizer = AutoTokenizer.from_pretrained('bolbolzaban/gpt2-persian')\n",
    "\n",
    "# Tokenize the text\n",
    "token_ids = tokenizer.encode(formatted_text)\n",
    "\n",
    "print(\"Total number of tokens:\", len(token_ids))\n",
    "print(\"First 10 tokens:\", token_ids[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T13:55:47.485668Z",
     "iopub.status.busy": "2024-12-11T13:55:47.485290Z",
     "iopub.status.idle": "2024-12-11T13:55:48.479279Z",
     "shell.execute_reply": "2024-12-11T13:55:48.478310Z",
     "shell.execute_reply.started": "2024-12-11T13:55:47.485631Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "class GPTDataset(Dataset):\n",
    "    def __init__(self, txt, tokenizer, context_length):\n",
    "        self.input_ids = []\n",
    "        self.target_ids = []\n",
    "\n",
    "        # Tokenize the entire text\n",
    "        token_ids = tokenizer.encode(txt)\n",
    "\n",
    "        # Use a sliding window to chunk the book into overlapping sequences of context_length\n",
    "        for i in range(0, len(token_ids) - context_length):\n",
    "            input_sequence = token_ids[i:i + context_length]\n",
    "            \n",
    "            #shift to the right\n",
    "            target_sequence = token_ids[i + 1: i + context_length + 1]\n",
    "\n",
    "            # input and output are represented as tensors\n",
    "            self.input_ids.append(torch.tensor(input_sequence))\n",
    "            self.target_ids.append(torch.tensor(target_sequence))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.input_ids[idx], self.target_ids[idx]\n",
    "\n",
    "def create_dataloader(txt, batch_size=8, context_length=4, shuffle=True, drop_last=True,\n",
    "                         num_workers=0):\n",
    "\n",
    "    # Initialize the tokenizer\n",
    "    # tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "    tokenizer = AutoTokenizer.from_pretrained('bolbolzaban/gpt2-persian')\n",
    "\n",
    "    # Create dataset\n",
    "    dataset = GPTDataset(txt, tokenizer, context_length)\n",
    "    train, dev, test = torch.utils.data.random_split(dataset, [0.8,0.1,0.1])\n",
    "    \n",
    "    # Create dataloader\n",
    "    train_dataloader = DataLoader(\n",
    "        train,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        drop_last=drop_last,\n",
    "        num_workers=num_workers\n",
    "    )\n",
    "\n",
    "    dev_dataloader = DataLoader(\n",
    "        dev,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        drop_last=drop_last,\n",
    "        num_workers=num_workers\n",
    "    )\n",
    "    test_dataloader = DataLoader(\n",
    "        test,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        drop_last=drop_last,\n",
    "        num_workers=num_workers\n",
    "    )\n",
    "    return train_dataloader, dev_dataloader, test_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-09T18:54:51.958205Z",
     "iopub.status.busy": "2024-12-09T18:54:51.957946Z",
     "iopub.status.idle": "2024-12-09T18:54:51.974124Z",
     "shell.execute_reply": "2024-12-09T18:54:51.973528Z",
     "shell.execute_reply.started": "2024-12-09T18:54:51.958180Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class SimpleLanguageModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, context_length):\n",
    "        super(SimpleLanguageModel, self).__init__()\n",
    "        self.token_embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.position_embedding = nn.Embedding(context_length, embedding_dim)\n",
    "        self.linear = nn.Linear(embedding_dim, vocab_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        positions = torch.arange(0, x.size(1), device=x.device).unsqueeze(0)\n",
    "        token_embeds = self.token_embedding(x)\n",
    "        position_embeds = self.position_embedding(positions)\n",
    "        \n",
    "        embeddings = token_embeds + position_embeds\n",
    "        logits = self.linear(embeddings)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T13:41:52.081912Z",
     "iopub.status.busy": "2024-12-11T13:41:52.081560Z",
     "iopub.status.idle": "2024-12-11T13:41:52.088396Z",
     "shell.execute_reply": "2024-12-11T13:41:52.087414Z",
     "shell.execute_reply.started": "2024-12-11T13:41:52.081882Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class RegularizedLanguageModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, context_length, dropout=0.2):\n",
    "        super(RegularizedLanguageModel, self).__init__()\n",
    "        self.token_embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.position_embedding = nn.Embedding(context_length, embedding_dim)\n",
    "        # This is new!\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear = nn.Linear(embedding_dim, vocab_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        positions = torch.arange(0, x.size(1), device=x.device).unsqueeze(0)\n",
    "        token_embeds = self.token_embedding(x)\n",
    "        position_embeds = self.position_embedding(positions)\n",
    "        \n",
    "        embeddings = token_embeds + position_embeds\n",
    "        embeddings = self.dropout(embeddings)\n",
    "        logits = self.linear(embeddings)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T13:38:30.743207Z",
     "iopub.status.busy": "2024-12-11T13:38:30.742538Z",
     "iopub.status.idle": "2024-12-11T13:38:30.801894Z",
     "shell.execute_reply": "2024-12-11T13:38:30.800909Z",
     "shell.execute_reply.started": "2024-12-11T13:38:30.743172Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# Setting up the device (make sure device returns \"cuda\" to use of the GPUs on kaggle)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T13:41:55.243696Z",
     "iopub.status.busy": "2024-12-11T13:41:55.242766Z",
     "iopub.status.idle": "2024-12-11T13:44:47.646575Z",
     "shell.execute_reply": "2024-12-11T13:44:47.645560Z",
     "shell.execute_reply.started": "2024-12-11T13:41:55.243641Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# Parameters\n",
    "batch_size = 128\n",
    "context_length = 32  # Context size for training\n",
    "# vocab_size = tokenizer.n_vocab\n",
    "vocab_size = 30000\n",
    "embedding_dim = 128\n",
    "\n",
    "# Create the DataLoader\n",
    "train_dataloader, dev_dataloader, test_dataloader = create_dataloader(\n",
    "    formatted_text[:9999297], batch_size=batch_size, \n",
    "    context_length=context_length, shuffle=True\n",
    ")\n",
    "\n",
    "# Initialize the model\n",
    "model = RegularizedLanguageModel(vocab_size, embedding_dim, context_length).to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop parameters\n",
    "num_epochs = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2024-12-11T13:45:47.359870Z",
     "iopub.status.busy": "2024-12-11T13:45:47.359515Z",
     "iopub.status.idle": "2024-12-11T13:50:01.450481Z",
     "shell.execute_reply": "2024-12-11T13:50:01.449288Z",
     "shell.execute_reply.started": "2024-12-11T13:45:47.359842Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], Step [0/43387], Loss: 10.6929\n",
      "Epoch [1/1], Step [20/43387], Loss: 8.1887\n",
      "Epoch [1/1], Step [40/43387], Loss: 5.9823\n",
      "Epoch [1/1], Step [60/43387], Loss: 4.6425\n",
      "Epoch [1/1], Step [80/43387], Loss: 4.0541\n",
      "Epoch [1/1], Step [100/43387], Loss: 3.6689\n",
      "Epoch [1/1], Step [120/43387], Loss: 3.2971\n",
      "Epoch [1/1], Step [140/43387], Loss: 3.3030\n",
      "Epoch [1/1], Step [160/43387], Loss: 3.0011\n",
      "Epoch [1/1], Step [180/43387], Loss: 2.6843\n",
      "Epoch [1/1], Step [200/43387], Loss: 2.6016\n",
      "Epoch [1/1], Step [220/43387], Loss: 2.4525\n",
      "Epoch [1/1], Step [240/43387], Loss: 2.5156\n",
      "Epoch [1/1], Step [260/43387], Loss: 2.3168\n",
      "Epoch [1/1], Step [280/43387], Loss: 2.2799\n",
      "Epoch [1/1], Step [300/43387], Loss: 2.3448\n",
      "Epoch [1/1], Step [320/43387], Loss: 2.2748\n",
      "Epoch [1/1], Step [340/43387], Loss: 2.2344\n",
      "Epoch [1/1], Step [360/43387], Loss: 2.1899\n",
      "Epoch [1/1], Step [380/43387], Loss: 2.2021\n",
      "Epoch [1/1], Step [400/43387], Loss: 2.1556\n",
      "Epoch [1/1], Step [420/43387], Loss: 2.2297\n",
      "Epoch [1/1], Step [440/43387], Loss: 2.1098\n",
      "Epoch [1/1], Step [460/43387], Loss: 2.1103\n",
      "Epoch [1/1], Step [480/43387], Loss: 2.1428\n",
      "Epoch [1/1], Step [500/43387], Loss: 2.1239\n",
      "Epoch [1/1], Step [520/43387], Loss: 2.0474\n",
      "Epoch [1/1], Step [540/43387], Loss: 2.0617\n",
      "Epoch [1/1], Step [560/43387], Loss: 2.0522\n",
      "Epoch [1/1], Step [580/43387], Loss: 2.1150\n",
      "Epoch [1/1], Step [600/43387], Loss: 2.0758\n",
      "Epoch [1/1], Step [620/43387], Loss: 2.0906\n",
      "Epoch [1/1], Step [640/43387], Loss: 2.1185\n",
      "Epoch [1/1], Step [660/43387], Loss: 2.0659\n",
      "Epoch [1/1], Step [680/43387], Loss: 2.0342\n",
      "Epoch [1/1], Step [700/43387], Loss: 2.0505\n",
      "Epoch [1/1], Step [720/43387], Loss: 2.0522\n",
      "Epoch [1/1], Step [740/43387], Loss: 2.0514\n",
      "Epoch [1/1], Step [760/43387], Loss: 2.0763\n",
      "Epoch [1/1], Step [780/43387], Loss: 2.0220\n",
      "Epoch [1/1], Step [800/43387], Loss: 2.0011\n",
      "Epoch [1/1], Step [820/43387], Loss: 1.9445\n",
      "Epoch [1/1], Step [840/43387], Loss: 2.0179\n",
      "Epoch [1/1], Step [860/43387], Loss: 2.0233\n",
      "Epoch [1/1], Step [880/43387], Loss: 1.9620\n",
      "Epoch [1/1], Step [900/43387], Loss: 2.0441\n",
      "Epoch [1/1], Step [920/43387], Loss: 2.0139\n",
      "Epoch [1/1], Step [940/43387], Loss: 2.0488\n",
      "Epoch [1/1], Step [960/43387], Loss: 2.0056\n",
      "Epoch [1/1], Step [980/43387], Loss: 1.9701\n",
      "Epoch [1/1], Step [1000/43387], Loss: 1.9830\n",
      "Epoch [1/1], Step [1020/43387], Loss: 1.9800\n",
      "Epoch [1/1], Step [1040/43387], Loss: 2.0653\n",
      "Epoch [1/1], Step [1060/43387], Loss: 2.0366\n",
      "Epoch [1/1], Step [1080/43387], Loss: 2.0007\n",
      "Epoch [1/1], Step [1100/43387], Loss: 2.0220\n",
      "Epoch [1/1], Step [1120/43387], Loss: 2.0447\n",
      "Epoch [1/1], Step [1140/43387], Loss: 2.0362\n",
      "Epoch [1/1], Step [1160/43387], Loss: 1.9557\n",
      "Epoch [1/1], Step [1180/43387], Loss: 1.9802\n",
      "Epoch [1/1], Step [1200/43387], Loss: 2.0480\n",
      "Epoch [1/1], Step [1220/43387], Loss: 2.0406\n",
      "Epoch [1/1], Step [1240/43387], Loss: 1.9891\n",
      "Epoch [1/1], Step [1260/43387], Loss: 1.9517\n",
      "Epoch [1/1], Step [1280/43387], Loss: 2.0115\n",
      "Epoch [1/1], Step [1300/43387], Loss: 1.9782\n",
      "Epoch [1/1], Step [1320/43387], Loss: 1.9547\n",
      "Epoch [1/1], Step [1340/43387], Loss: 1.9455\n",
      "Epoch [1/1], Step [1360/43387], Loss: 1.9840\n",
      "Epoch [1/1], Step [1380/43387], Loss: 2.0161\n",
      "Epoch [1/1], Step [1400/43387], Loss: 1.9231\n",
      "Epoch [1/1], Step [1420/43387], Loss: 1.9890\n",
      "Epoch [1/1], Step [1440/43387], Loss: 1.9958\n",
      "Epoch [1/1], Step [1460/43387], Loss: 1.9440\n",
      "Epoch [1/1], Step [1480/43387], Loss: 1.9603\n",
      "Epoch [1/1], Step [1500/43387], Loss: 1.9564\n",
      "Epoch [1/1], Step [1520/43387], Loss: 2.0141\n",
      "Epoch [1/1], Step [1540/43387], Loss: 1.9610\n",
      "Epoch [1/1], Step [1560/43387], Loss: 2.0159\n",
      "Epoch [1/1], Step [1580/43387], Loss: 1.9691\n",
      "Epoch [1/1], Step [1600/43387], Loss: 1.9356\n",
      "Epoch [1/1], Step [1620/43387], Loss: 1.9973\n",
      "Epoch [1/1], Step [1640/43387], Loss: 1.9426\n",
      "Epoch [1/1], Step [1660/43387], Loss: 1.9257\n",
      "Epoch [1/1], Step [1680/43387], Loss: 2.0227\n",
      "Epoch [1/1], Step [1700/43387], Loss: 1.9339\n",
      "Epoch [1/1], Step [1720/43387], Loss: 1.9606\n",
      "Epoch [1/1], Step [1740/43387], Loss: 1.9700\n",
      "Epoch [1/1], Step [1760/43387], Loss: 1.9689\n",
      "Epoch [1/1], Step [1780/43387], Loss: 1.9569\n",
      "Epoch [1/1], Step [1800/43387], Loss: 1.9407\n",
      "Epoch [1/1], Step [1820/43387], Loss: 1.9975\n",
      "Epoch [1/1], Step [1840/43387], Loss: 1.9519\n",
      "Epoch [1/1], Step [1860/43387], Loss: 1.9482\n",
      "Epoch [1/1], Step [1880/43387], Loss: 1.8944\n",
      "Epoch [1/1], Step [1900/43387], Loss: 1.9166\n",
      "Epoch [1/1], Step [1920/43387], Loss: 1.9148\n",
      "Epoch [1/1], Step [1940/43387], Loss: 1.9335\n",
      "Epoch [1/1], Step [1960/43387], Loss: 2.0013\n",
      "Epoch [1/1], Step [1980/43387], Loss: 1.9018\n",
      "Epoch [1/1], Step [2000/43387], Loss: 1.9908\n",
      "Epoch [1/1], Step [2020/43387], Loss: 2.0006\n",
      "Epoch [1/1], Step [2040/43387], Loss: 1.9341\n",
      "Epoch [1/1], Step [2060/43387], Loss: 1.9543\n",
      "Epoch [1/1], Step [2080/43387], Loss: 1.9577\n",
      "Epoch [1/1], Step [2100/43387], Loss: 1.9239\n",
      "Epoch [1/1], Step [2120/43387], Loss: 1.9272\n",
      "Epoch [1/1], Step [2140/43387], Loss: 1.9527\n",
      "Epoch [1/1], Step [2160/43387], Loss: 1.9669\n",
      "Epoch [1/1], Step [2180/43387], Loss: 1.9314\n",
      "Epoch [1/1], Step [2200/43387], Loss: 1.9056\n",
      "Epoch [1/1], Step [2220/43387], Loss: 1.9443\n",
      "Epoch [1/1], Step [2240/43387], Loss: 1.9812\n",
      "Epoch [1/1], Step [2260/43387], Loss: 1.9756\n",
      "Epoch [1/1], Step [2280/43387], Loss: 1.9384\n",
      "Epoch [1/1], Step [2300/43387], Loss: 1.9002\n",
      "Epoch [1/1], Step [2320/43387], Loss: 1.9037\n",
      "Epoch [1/1], Step [2340/43387], Loss: 1.9130\n",
      "Epoch [1/1], Step [2360/43387], Loss: 1.9281\n",
      "Epoch [1/1], Step [2380/43387], Loss: 1.9253\n",
      "Epoch [1/1], Step [2400/43387], Loss: 1.8929\n",
      "Epoch [1/1], Step [2420/43387], Loss: 1.9345\n",
      "Epoch [1/1], Step [2440/43387], Loss: 1.9443\n",
      "Epoch [1/1], Step [2460/43387], Loss: 1.9412\n",
      "Epoch [1/1], Step [2480/43387], Loss: 1.9491\n",
      "Epoch [1/1], Step [2500/43387], Loss: 1.9137\n",
      "Epoch [1/1], Step [2520/43387], Loss: 1.9644\n",
      "Epoch [1/1], Step [2540/43387], Loss: 1.9731\n",
      "Epoch [1/1], Step [2560/43387], Loss: 1.9489\n",
      "Epoch [1/1], Step [2580/43387], Loss: 1.9416\n",
      "Epoch [1/1], Step [2600/43387], Loss: 1.9527\n",
      "Epoch [1/1], Step [2620/43387], Loss: 1.9934\n",
      "Epoch [1/1], Step [2640/43387], Loss: 1.9541\n",
      "Epoch [1/1], Step [2660/43387], Loss: 1.9566\n",
      "Epoch [1/1], Step [2680/43387], Loss: 1.8813\n",
      "Epoch [1/1], Step [2700/43387], Loss: 1.8827\n",
      "Epoch [1/1], Step [2720/43387], Loss: 1.8733\n",
      "Epoch [1/1], Step [2740/43387], Loss: 1.9745\n",
      "Epoch [1/1], Step [2760/43387], Loss: 1.9122\n",
      "Epoch [1/1], Step [2780/43387], Loss: 1.9466\n",
      "Epoch [1/1], Step [2800/43387], Loss: 1.9729\n",
      "Epoch [1/1], Step [2820/43387], Loss: 1.9028\n",
      "Epoch [1/1], Step [2840/43387], Loss: 1.9234\n",
      "Epoch [1/1], Step [2860/43387], Loss: 1.9472\n",
      "Epoch [1/1], Step [2880/43387], Loss: 1.9135\n",
      "Epoch [1/1], Step [2900/43387], Loss: 1.9347\n",
      "Epoch [1/1], Step [2920/43387], Loss: 1.9474\n",
      "Epoch [1/1], Step [2940/43387], Loss: 1.9235\n",
      "Epoch [1/1], Step [2960/43387], Loss: 1.8778\n",
      "Epoch [1/1], Step [2980/43387], Loss: 1.9382\n",
      "Epoch [1/1], Step [3000/43387], Loss: 1.9378\n",
      "Epoch [1/1], Step [3020/43387], Loss: 1.8795\n",
      "Epoch [1/1], Step [3040/43387], Loss: 1.9291\n",
      "Epoch [1/1], Step [3060/43387], Loss: 1.9271\n",
      "Epoch [1/1], Step [3080/43387], Loss: 1.9341\n",
      "Epoch [1/1], Step [3100/43387], Loss: 1.9408\n",
      "Epoch [1/1], Step [3120/43387], Loss: 1.9283\n",
      "Epoch [1/1], Step [3140/43387], Loss: 1.8964\n",
      "Epoch [1/1], Step [3160/43387], Loss: 1.9199\n",
      "Epoch [1/1], Step [3180/43387], Loss: 1.9530\n",
      "Epoch [1/1], Step [3200/43387], Loss: 1.9268\n",
      "Epoch [1/1], Step [3220/43387], Loss: 1.8547\n",
      "Epoch [1/1], Step [3240/43387], Loss: 1.9230\n",
      "Epoch [1/1], Step [3260/43387], Loss: 1.8906\n",
      "Epoch [1/1], Step [3280/43387], Loss: 1.9095\n",
      "Epoch [1/1], Step [3300/43387], Loss: 1.9081\n",
      "Epoch [1/1], Step [3320/43387], Loss: 1.9132\n",
      "Epoch [1/1], Step [3340/43387], Loss: 1.9469\n",
      "Epoch [1/1], Step [3360/43387], Loss: 1.9218\n",
      "Epoch [1/1], Step [3380/43387], Loss: 1.8796\n",
      "Epoch [1/1], Step [3400/43387], Loss: 1.9317\n",
      "Epoch [1/1], Step [3420/43387], Loss: 1.8990\n",
      "Epoch [1/1], Step [3440/43387], Loss: 1.9274\n",
      "Epoch [1/1], Step [3460/43387], Loss: 1.9613\n",
      "Epoch [1/1], Step [3480/43387], Loss: 1.9397\n",
      "Epoch [1/1], Step [3500/43387], Loss: 1.9238\n",
      "Epoch [1/1], Step [3520/43387], Loss: 1.9238\n",
      "Epoch [1/1], Step [3540/43387], Loss: 1.9030\n",
      "Epoch [1/1], Step [3560/43387], Loss: 1.8925\n",
      "Epoch [1/1], Step [3580/43387], Loss: 1.9309\n",
      "Epoch [1/1], Step [3600/43387], Loss: 1.8972\n",
      "Epoch [1/1], Step [3620/43387], Loss: 1.9103\n",
      "Epoch [1/1], Step [3640/43387], Loss: 1.9145\n",
      "Epoch [1/1], Step [3660/43387], Loss: 1.9184\n",
      "Epoch [1/1], Step [3680/43387], Loss: 1.9242\n",
      "Epoch [1/1], Step [3700/43387], Loss: 1.8941\n",
      "Epoch [1/1], Step [3720/43387], Loss: 1.9140\n",
      "Epoch [1/1], Step [3740/43387], Loss: 1.9128\n",
      "Epoch [1/1], Step [3760/43387], Loss: 1.8958\n",
      "Epoch [1/1], Step [3780/43387], Loss: 1.8598\n",
      "Epoch [1/1], Step [3800/43387], Loss: 1.8756\n",
      "Epoch [1/1], Step [3820/43387], Loss: 1.9079\n",
      "Epoch [1/1], Step [3840/43387], Loss: 1.9167\n",
      "Epoch [1/1], Step [3860/43387], Loss: 1.8694\n",
      "Epoch [1/1], Step [3880/43387], Loss: 1.8955\n",
      "Epoch [1/1], Step [3900/43387], Loss: 1.8814\n",
      "Epoch [1/1], Step [3920/43387], Loss: 1.9409\n",
      "Epoch [1/1], Step [3940/43387], Loss: 1.8935\n",
      "Epoch [1/1], Step [3960/43387], Loss: 1.8723\n",
      "Epoch [1/1], Step [3980/43387], Loss: 1.8743\n",
      "Epoch [1/1], Step [4000/43387], Loss: 1.9162\n",
      "Epoch [1/1], Step [4020/43387], Loss: 1.9069\n",
      "Epoch [1/1], Step [4040/43387], Loss: 1.9530\n",
      "Epoch [1/1], Step [4060/43387], Loss: 1.8938\n",
      "Epoch [1/1], Step [4080/43387], Loss: 1.9109\n",
      "Epoch [1/1], Step [4100/43387], Loss: 1.9180\n",
      "Epoch [1/1], Step [4120/43387], Loss: 1.8682\n",
      "Epoch [1/1], Step [4140/43387], Loss: 1.8740\n",
      "Epoch [1/1], Step [4160/43387], Loss: 1.9168\n",
      "Epoch [1/1], Step [4180/43387], Loss: 1.9067\n",
      "Epoch [1/1], Step [4200/43387], Loss: 1.8968\n",
      "Epoch [1/1], Step [4220/43387], Loss: 1.9549\n",
      "Epoch [1/1], Step [4240/43387], Loss: 1.9034\n",
      "Epoch [1/1], Step [4260/43387], Loss: 1.9107\n",
      "Epoch [1/1], Step [4280/43387], Loss: 1.8620\n",
      "Epoch [1/1], Step [4300/43387], Loss: 1.9079\n",
      "Epoch [1/1], Step [4320/43387], Loss: 1.9111\n",
      "Epoch [1/1], Step [4340/43387], Loss: 1.8914\n",
      "Epoch [1/1], Step [4360/43387], Loss: 1.8961\n",
      "Epoch [1/1], Step [4380/43387], Loss: 1.8889\n",
      "Epoch [1/1], Step [4400/43387], Loss: 1.9004\n",
      "Epoch [1/1], Step [4420/43387], Loss: 1.9062\n",
      "Epoch [1/1], Step [4440/43387], Loss: 1.8942\n",
      "Epoch [1/1], Step [4460/43387], Loss: 1.8917\n",
      "Epoch [1/1], Step [4480/43387], Loss: 1.8704\n",
      "Epoch [1/1], Step [4500/43387], Loss: 1.8780\n",
      "Epoch [1/1], Step [4520/43387], Loss: 1.8853\n",
      "Epoch [1/1], Step [4540/43387], Loss: 1.8961\n",
      "Epoch [1/1], Step [4560/43387], Loss: 1.8779\n",
      "Epoch [1/1], Step [4580/43387], Loss: 1.9032\n",
      "Epoch [1/1], Step [4600/43387], Loss: 1.8837\n",
      "Epoch [1/1], Step [4620/43387], Loss: 1.8573\n",
      "Epoch [1/1], Step [4640/43387], Loss: 1.8595\n",
      "Epoch [1/1], Step [4660/43387], Loss: 1.8817\n",
      "Epoch [1/1], Step [4680/43387], Loss: 1.8855\n",
      "Epoch [1/1], Step [4700/43387], Loss: 1.9209\n",
      "Epoch [1/1], Step [4720/43387], Loss: 1.9099\n",
      "Epoch [1/1], Step [4740/43387], Loss: 1.8947\n",
      "Epoch [1/1], Step [4760/43387], Loss: 1.8851\n",
      "Epoch [1/1], Step [4780/43387], Loss: 1.9151\n",
      "Epoch [1/1], Step [4800/43387], Loss: 1.8566\n",
      "Epoch [1/1], Step [4820/43387], Loss: 1.8820\n",
      "Epoch [1/1], Step [4840/43387], Loss: 1.8535\n",
      "Epoch [1/1], Step [4860/43387], Loss: 1.8641\n",
      "Epoch [1/1], Step [4880/43387], Loss: 1.8680\n",
      "Epoch [1/1], Step [4900/43387], Loss: 1.8755\n",
      "Epoch [1/1], Step [4920/43387], Loss: 1.9213\n",
      "Epoch [1/1], Step [4940/43387], Loss: 1.8695\n",
      "Epoch [1/1], Step [4960/43387], Loss: 1.9354\n",
      "Epoch [1/1], Step [4980/43387], Loss: 1.8839\n",
      "Epoch [1/1], Step [5000/43387], Loss: 1.9151\n",
      "Epoch [1/1], Step [5020/43387], Loss: 1.8818\n",
      "Epoch [1/1], Step [5040/43387], Loss: 1.8339\n",
      "Epoch [1/1], Step [5060/43387], Loss: 1.9024\n",
      "Epoch [1/1], Step [5080/43387], Loss: 1.9157\n",
      "Epoch [1/1], Step [5100/43387], Loss: 1.8874\n",
      "Epoch [1/1], Step [5120/43387], Loss: 1.9273\n",
      "Epoch [1/1], Step [5140/43387], Loss: 1.8881\n",
      "Epoch [1/1], Step [5160/43387], Loss: 1.8817\n",
      "Epoch [1/1], Step [5180/43387], Loss: 1.8529\n",
      "Epoch [1/1], Step [5200/43387], Loss: 1.9035\n",
      "Epoch [1/1], Step [5220/43387], Loss: 1.8949\n",
      "Epoch [1/1], Step [5240/43387], Loss: 1.8690\n",
      "Epoch [1/1], Step [5260/43387], Loss: 1.8772\n",
      "Epoch [1/1], Step [5280/43387], Loss: 1.8732\n",
      "Epoch [1/1], Step [5300/43387], Loss: 1.9251\n",
      "Epoch [1/1], Step [5320/43387], Loss: 1.9367\n",
      "Epoch [1/1], Step [5340/43387], Loss: 1.8766\n",
      "Epoch [1/1], Step [5360/43387], Loss: 1.8776\n",
      "Epoch [1/1], Step [5380/43387], Loss: 1.8765\n",
      "Epoch [1/1], Step [5400/43387], Loss: 1.9053\n",
      "Epoch [1/1], Step [5420/43387], Loss: 1.9047\n",
      "Epoch [1/1], Step [5440/43387], Loss: 1.8479\n",
      "Epoch [1/1], Step [5460/43387], Loss: 1.9157\n",
      "Epoch [1/1], Step [5480/43387], Loss: 1.8820\n",
      "Epoch [1/1], Step [5500/43387], Loss: 1.8843\n",
      "Epoch [1/1], Step [5520/43387], Loss: 1.8989\n",
      "Epoch [1/1], Step [5540/43387], Loss: 1.8800\n",
      "Epoch [1/1], Step [5560/43387], Loss: 1.8404\n",
      "Epoch [1/1], Step [5580/43387], Loss: 1.8661\n",
      "Epoch [1/1], Step [5600/43387], Loss: 1.8942\n",
      "Epoch [1/1], Step [5620/43387], Loss: 1.9055\n",
      "Epoch [1/1], Step [5640/43387], Loss: 1.8944\n",
      "Epoch [1/1], Step [5660/43387], Loss: 1.8404\n",
      "Epoch [1/1], Step [5680/43387], Loss: 1.9121\n",
      "Epoch [1/1], Step [5700/43387], Loss: 1.8611\n",
      "Epoch [1/1], Step [5720/43387], Loss: 1.8658\n",
      "Epoch [1/1], Step [5740/43387], Loss: 1.8940\n",
      "Epoch [1/1], Step [5760/43387], Loss: 1.9015\n",
      "Epoch [1/1], Step [5780/43387], Loss: 1.8748\n",
      "Epoch [1/1], Step [5800/43387], Loss: 1.8734\n",
      "Epoch [1/1], Step [5820/43387], Loss: 1.8584\n",
      "Epoch [1/1], Step [5840/43387], Loss: 1.8666\n",
      "Epoch [1/1], Step [5860/43387], Loss: 1.8973\n",
      "Epoch [1/1], Step [5880/43387], Loss: 1.8493\n",
      "Epoch [1/1], Step [5900/43387], Loss: 1.8618\n",
      "Epoch [1/1], Step [5920/43387], Loss: 1.8731\n",
      "Epoch [1/1], Step [5940/43387], Loss: 1.8922\n",
      "Epoch [1/1], Step [5960/43387], Loss: 1.9043\n",
      "Epoch [1/1], Step [5980/43387], Loss: 1.8932\n",
      "Epoch [1/1], Step [6000/43387], Loss: 1.9137\n",
      "Epoch [1/1], Step [6020/43387], Loss: 1.8729\n",
      "Epoch [1/1], Step [6040/43387], Loss: 1.8278\n",
      "Epoch [1/1], Step [6060/43387], Loss: 1.8882\n",
      "Epoch [1/1], Step [6080/43387], Loss: 1.8989\n",
      "Epoch [1/1], Step [6100/43387], Loss: 1.8691\n",
      "Epoch [1/1], Step [6120/43387], Loss: 1.8639\n",
      "Epoch [1/1], Step [6140/43387], Loss: 1.8821\n",
      "Epoch [1/1], Step [6160/43387], Loss: 1.8545\n",
      "Epoch [1/1], Step [6180/43387], Loss: 1.8672\n",
      "Epoch [1/1], Step [6200/43387], Loss: 1.8758\n",
      "Epoch [1/1], Step [6220/43387], Loss: 1.8842\n",
      "Epoch [1/1], Step [6240/43387], Loss: 1.9153\n",
      "Epoch [1/1], Step [6260/43387], Loss: 1.8847\n",
      "Epoch [1/1], Step [6280/43387], Loss: 1.8521\n",
      "Epoch [1/1], Step [6300/43387], Loss: 1.8774\n",
      "Epoch [1/1], Step [6320/43387], Loss: 1.8475\n",
      "Epoch [1/1], Step [6340/43387], Loss: 1.8868\n",
      "Epoch [1/1], Step [6360/43387], Loss: 1.8528\n",
      "Epoch [1/1], Step [6380/43387], Loss: 1.8557\n",
      "Epoch [1/1], Step [6400/43387], Loss: 1.8973\n",
      "Epoch [1/1], Step [6420/43387], Loss: 1.9106\n",
      "Epoch [1/1], Step [6440/43387], Loss: 1.8564\n",
      "Epoch [1/1], Step [6460/43387], Loss: 1.8582\n",
      "Epoch [1/1], Step [6480/43387], Loss: 1.9019\n",
      "Epoch [1/1], Step [6500/43387], Loss: 1.8473\n",
      "Epoch [1/1], Step [6520/43387], Loss: 1.8419\n",
      "Epoch [1/1], Step [6540/43387], Loss: 1.8826\n",
      "Epoch [1/1], Step [6560/43387], Loss: 1.8637\n",
      "Epoch [1/1], Step [6580/43387], Loss: 1.8691\n",
      "Epoch [1/1], Step [6600/43387], Loss: 1.8614\n",
      "Epoch [1/1], Step [6620/43387], Loss: 1.8883\n",
      "Epoch [1/1], Step [6640/43387], Loss: 1.8222\n",
      "Epoch [1/1], Step [6660/43387], Loss: 1.8715\n",
      "Epoch [1/1], Step [6680/43387], Loss: 1.8674\n",
      "Epoch [1/1], Step [6700/43387], Loss: 1.8319\n",
      "Epoch [1/1], Step [6720/43387], Loss: 1.8287\n",
      "Epoch [1/1], Step [6740/43387], Loss: 1.8477\n",
      "Epoch [1/1], Step [6760/43387], Loss: 1.8771\n",
      "Epoch [1/1], Step [6780/43387], Loss: 1.8543\n",
      "Epoch [1/1], Step [6800/43387], Loss: 1.8894\n",
      "Epoch [1/1], Step [6820/43387], Loss: 1.8815\n",
      "Epoch [1/1], Step [6840/43387], Loss: 1.8528\n",
      "Epoch [1/1], Step [6860/43387], Loss: 1.8781\n",
      "Epoch [1/1], Step [6880/43387], Loss: 1.8828\n",
      "Epoch [1/1], Step [6900/43387], Loss: 1.8875\n",
      "Epoch [1/1], Step [6920/43387], Loss: 1.8805\n",
      "Epoch [1/1], Step [6940/43387], Loss: 1.8741\n",
      "Epoch [1/1], Step [6960/43387], Loss: 1.8705\n",
      "Epoch [1/1], Step [6980/43387], Loss: 1.8532\n",
      "Epoch [1/1], Step [7000/43387], Loss: 1.8681\n",
      "Epoch [1/1], Step [7020/43387], Loss: 1.8494\n",
      "Epoch [1/1], Step [7040/43387], Loss: 1.8360\n",
      "Epoch [1/1], Step [7060/43387], Loss: 1.8548\n",
      "Epoch [1/1], Step [7080/43387], Loss: 1.9209\n",
      "Epoch [1/1], Step [7100/43387], Loss: 1.9175\n",
      "Epoch [1/1], Step [7120/43387], Loss: 1.8596\n",
      "Epoch [1/1], Step [7140/43387], Loss: 1.9202\n",
      "Epoch [1/1], Step [7160/43387], Loss: 1.8824\n",
      "Epoch [1/1], Step [7180/43387], Loss: 1.8929\n",
      "Epoch [1/1], Step [7200/43387], Loss: 1.8274\n",
      "Epoch [1/1], Step [7220/43387], Loss: 1.8865\n",
      "Epoch [1/1], Step [7240/43387], Loss: 1.8520\n",
      "Epoch [1/1], Step [7260/43387], Loss: 1.8343\n",
      "Epoch [1/1], Step [7280/43387], Loss: 1.8253\n",
      "Epoch [1/1], Step [7300/43387], Loss: 1.8512\n",
      "Epoch [1/1], Step [7320/43387], Loss: 1.9010\n",
      "Epoch [1/1], Step [7340/43387], Loss: 1.8565\n",
      "Epoch [1/1], Step [7360/43387], Loss: 1.8601\n",
      "Epoch [1/1], Step [7380/43387], Loss: 1.9132\n",
      "Epoch [1/1], Step [7400/43387], Loss: 1.8562\n",
      "Epoch [1/1], Step [7420/43387], Loss: 1.9083\n",
      "Epoch [1/1], Step [7440/43387], Loss: 1.8602\n",
      "Epoch [1/1], Step [7460/43387], Loss: 1.8730\n",
      "Epoch [1/1], Step [7480/43387], Loss: 1.8080\n",
      "Epoch [1/1], Step [7500/43387], Loss: 1.8996\n",
      "Epoch [1/1], Step [7520/43387], Loss: 1.8281\n",
      "Epoch [1/1], Step [7540/43387], Loss: 1.8466\n",
      "Epoch [1/1], Step [7560/43387], Loss: 1.8337\n",
      "Epoch [1/1], Step [7580/43387], Loss: 1.8638\n",
      "Epoch [1/1], Step [7600/43387], Loss: 1.8855\n",
      "Epoch [1/1], Step [7620/43387], Loss: 1.8925\n",
      "Epoch [1/1], Step [7640/43387], Loss: 1.8935\n",
      "Epoch [1/1], Step [7660/43387], Loss: 1.8686\n",
      "Epoch [1/1], Step [7680/43387], Loss: 1.8307\n",
      "Epoch [1/1], Step [7700/43387], Loss: 1.8181\n",
      "Epoch [1/1], Step [7720/43387], Loss: 1.8391\n",
      "Epoch [1/1], Step [7740/43387], Loss: 1.8333\n",
      "Epoch [1/1], Step [7760/43387], Loss: 1.8362\n",
      "Epoch [1/1], Step [7780/43387], Loss: 1.8869\n",
      "Epoch [1/1], Step [7800/43387], Loss: 1.8385\n",
      "Epoch [1/1], Step [7820/43387], Loss: 1.9025\n",
      "Epoch [1/1], Step [7840/43387], Loss: 1.8406\n",
      "Epoch [1/1], Step [7860/43387], Loss: 1.8141\n",
      "Epoch [1/1], Step [7880/43387], Loss: 1.8746\n",
      "Epoch [1/1], Step [7900/43387], Loss: 1.8249\n",
      "Epoch [1/1], Step [7920/43387], Loss: 1.8509\n",
      "Epoch [1/1], Step [7940/43387], Loss: 1.8550\n",
      "Epoch [1/1], Step [7960/43387], Loss: 1.8578\n",
      "Epoch [1/1], Step [7980/43387], Loss: 1.8716\n",
      "Epoch [1/1], Step [8000/43387], Loss: 1.8416\n",
      "Epoch [1/1], Step [8020/43387], Loss: 1.8727\n",
      "Epoch [1/1], Step [8040/43387], Loss: 1.8424\n",
      "Epoch [1/1], Step [8060/43387], Loss: 1.8848\n",
      "Epoch [1/1], Step [8080/43387], Loss: 1.8442\n",
      "Epoch [1/1], Step [8100/43387], Loss: 1.8823\n",
      "Epoch [1/1], Step [8120/43387], Loss: 1.8629\n",
      "Epoch [1/1], Step [8140/43387], Loss: 1.8652\n",
      "Epoch [1/1], Step [8160/43387], Loss: 1.8508\n",
      "Epoch [1/1], Step [8180/43387], Loss: 1.8313\n",
      "Epoch [1/1], Step [8200/43387], Loss: 1.8332\n",
      "Epoch [1/1], Step [8220/43387], Loss: 1.8793\n",
      "Epoch [1/1], Step [8240/43387], Loss: 1.9288\n",
      "Epoch [1/1], Step [8260/43387], Loss: 1.8359\n",
      "Epoch [1/1], Step [8280/43387], Loss: 1.8755\n",
      "Epoch [1/1], Step [8300/43387], Loss: 1.8289\n",
      "Epoch [1/1], Step [8320/43387], Loss: 1.8274\n",
      "Epoch [1/1], Step [8340/43387], Loss: 1.8711\n",
      "Epoch [1/1], Step [8360/43387], Loss: 1.8784\n",
      "Epoch [1/1], Step [8380/43387], Loss: 1.8640\n",
      "Epoch [1/1], Step [8400/43387], Loss: 1.8740\n",
      "Epoch [1/1], Step [8420/43387], Loss: 1.8425\n",
      "Epoch [1/1], Step [8440/43387], Loss: 1.8702\n",
      "Epoch [1/1], Step [8460/43387], Loss: 1.8747\n",
      "Epoch [1/1], Step [8480/43387], Loss: 1.8726\n",
      "Epoch [1/1], Step [8500/43387], Loss: 1.8229\n",
      "Epoch [1/1], Step [8520/43387], Loss: 1.8513\n",
      "Epoch [1/1], Step [8540/43387], Loss: 1.8678\n",
      "Epoch [1/1], Step [8560/43387], Loss: 1.8770\n",
      "Epoch [1/1], Step [8580/43387], Loss: 1.8381\n",
      "Epoch [1/1], Step [8600/43387], Loss: 1.8144\n",
      "Epoch [1/1], Step [8620/43387], Loss: 1.8120\n",
      "Epoch [1/1], Step [8640/43387], Loss: 1.8609\n",
      "Epoch [1/1], Step [8660/43387], Loss: 1.8272\n",
      "Epoch [1/1], Step [8680/43387], Loss: 1.8895\n",
      "Epoch [1/1], Step [8700/43387], Loss: 1.8711\n",
      "Epoch [1/1], Step [8720/43387], Loss: 1.8564\n",
      "Epoch [1/1], Step [8740/43387], Loss: 1.8831\n",
      "Epoch [1/1], Step [8760/43387], Loss: 1.8977\n",
      "Epoch [1/1], Step [8780/43387], Loss: 1.8594\n",
      "Epoch [1/1], Step [8800/43387], Loss: 1.8323\n",
      "Epoch [1/1], Step [8820/43387], Loss: 1.8160\n",
      "Epoch [1/1], Step [8840/43387], Loss: 1.8481\n",
      "Epoch [1/1], Step [8860/43387], Loss: 1.8476\n",
      "Epoch [1/1], Step [8880/43387], Loss: 1.8890\n",
      "Epoch [1/1], Step [8900/43387], Loss: 1.8598\n",
      "Epoch [1/1], Step [8920/43387], Loss: 1.8422\n",
      "Epoch [1/1], Step [8940/43387], Loss: 1.8435\n",
      "Epoch [1/1], Step [8960/43387], Loss: 1.8470\n",
      "Epoch [1/1], Step [8980/43387], Loss: 1.8945\n",
      "Epoch [1/1], Step [9000/43387], Loss: 1.8903\n",
      "Epoch [1/1], Step [9020/43387], Loss: 1.8789\n",
      "Epoch [1/1], Step [9040/43387], Loss: 1.8227\n",
      "Epoch [1/1], Step [9060/43387], Loss: 1.8904\n",
      "Epoch [1/1], Step [9080/43387], Loss: 1.8361\n",
      "Epoch [1/1], Step [9100/43387], Loss: 1.8635\n",
      "Epoch [1/1], Step [9120/43387], Loss: 1.7990\n",
      "Epoch [1/1], Step [9140/43387], Loss: 1.8503\n",
      "Epoch [1/1], Step [9160/43387], Loss: 1.8542\n",
      "Epoch [1/1], Step [9180/43387], Loss: 1.8236\n",
      "Epoch [1/1], Step [9200/43387], Loss: 1.9180\n",
      "Epoch [1/1], Step [9220/43387], Loss: 1.8828\n",
      "Epoch [1/1], Step [9240/43387], Loss: 1.8524\n",
      "Epoch [1/1], Step [9260/43387], Loss: 1.7932\n",
      "Epoch [1/1], Step [9280/43387], Loss: 1.8640\n",
      "Epoch [1/1], Step [9300/43387], Loss: 1.9252\n",
      "Epoch [1/1], Step [9320/43387], Loss: 1.8172\n",
      "Epoch [1/1], Step [9340/43387], Loss: 1.8719\n",
      "Epoch [1/1], Step [9360/43387], Loss: 1.8714\n",
      "Epoch [1/1], Step [9380/43387], Loss: 1.8199\n",
      "Epoch [1/1], Step [9400/43387], Loss: 1.8498\n",
      "Epoch [1/1], Step [9420/43387], Loss: 1.8420\n",
      "Epoch [1/1], Step [9440/43387], Loss: 1.8527\n",
      "Epoch [1/1], Step [9460/43387], Loss: 1.8564\n",
      "Epoch [1/1], Step [9480/43387], Loss: 1.8496\n",
      "Epoch [1/1], Step [9500/43387], Loss: 1.8508\n",
      "Epoch [1/1], Step [9520/43387], Loss: 1.8623\n",
      "Epoch [1/1], Step [9540/43387], Loss: 1.8715\n",
      "Epoch [1/1], Step [9560/43387], Loss: 1.8344\n",
      "Epoch [1/1], Step [9580/43387], Loss: 1.8475\n",
      "Epoch [1/1], Step [9600/43387], Loss: 1.8481\n",
      "Epoch [1/1], Step [9620/43387], Loss: 1.8819\n",
      "Epoch [1/1], Step [9640/43387], Loss: 1.8508\n",
      "Epoch [1/1], Step [9660/43387], Loss: 1.8522\n",
      "Epoch [1/1], Step [9680/43387], Loss: 1.8717\n",
      "Epoch [1/1], Step [9700/43387], Loss: 1.8291\n",
      "Epoch [1/1], Step [9720/43387], Loss: 1.8544\n",
      "Epoch [1/1], Step [9740/43387], Loss: 1.8911\n",
      "Epoch [1/1], Step [9760/43387], Loss: 1.8411\n",
      "Epoch [1/1], Step [9780/43387], Loss: 1.8418\n",
      "Epoch [1/1], Step [9800/43387], Loss: 1.8212\n",
      "Epoch [1/1], Step [9820/43387], Loss: 1.8409\n",
      "Epoch [1/1], Step [9840/43387], Loss: 1.8800\n",
      "Epoch [1/1], Step [9860/43387], Loss: 1.8255\n",
      "Epoch [1/1], Step [9880/43387], Loss: 1.8590\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 44\u001b[0m\n\u001b[1;32m     41\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# Accumulate the loss over batches\u001b[39;00m\n\u001b[0;32m---> 44\u001b[0m total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;66;03m# Monitor progress every twenty batches\u001b[39;00m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_idx \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m20\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "num_epochs = 1\n",
    "train_losses = []\n",
    "perplexities = []\n",
    "\n",
    "# Go through learning epochs\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    model.train()\n",
    "    \n",
    "    # Read in data in batches\n",
    "    for batch_idx, (x, y) in enumerate(train_dataloader):\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        # Reset the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Apply the forward pass\n",
    "        logits = model(x)\n",
    "\n",
    "        # Reshape logits and labels\n",
    "        token_logits = logits.view(-1, vocab_size)\n",
    "        token_labels = y.view(-1)\n",
    "\n",
    "        # To understand what is happening during reshaping, print out logits.shape and token_logits.shape\n",
    "        # and the same for y\n",
    "        # print(logits.shape, token_logits.shape)\n",
    "        # print(y.shape, token_labels.shape)\n",
    "        # print(y[0])\n",
    "        # print(token_labels[0:10])\n",
    "\n",
    "        # Calculate the loss\n",
    "        loss = criterion(token_logits,token_labels)\n",
    "\n",
    "        # Apply the backward step (calculate the gradients) \n",
    "        loss.backward()\n",
    "\n",
    "        # Adjust the weights\n",
    "        optimizer.step()\n",
    "\n",
    "        # Accumulate the loss over batches\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Monitor progress every twenty batches\n",
    "        if batch_idx % 20 == 0:\n",
    "            print(f\"Epoch [{epoch+1}/{num_epochs}], Step [{batch_idx}/{len(train_dataloader)}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "    # Calculate average cross-entropy loss and perplexity\n",
    "    avg_loss = total_loss / len(train_dataloader)\n",
    "    perplexity = math.exp(avg_loss)\n",
    "    \n",
    "    # Monitor developments over learning process\n",
    "    train_losses.append(avg_loss)\n",
    "    perplexities.append(perplexity)\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}] Average Loss: {avg_loss:.4f}, Perplexity: {perplexity:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2024-12-11T13:50:08.470450Z",
     "iopub.status.busy": "2024-12-11T13:50:08.470064Z",
     "iopub.status.idle": "2024-12-11T13:50:08.897922Z",
     "shell.execute_reply": "2024-12-11T13:50:08.897046Z",
     "shell.execute_reply.started": "2024-12-11T13:50:08.470416Z"
    },
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting the Loss and Perplexity\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_losses, label='Training Loss', linestyle='dashed', marker=\"o\")\n",
    "plt.title('Simple Model - Training Loss over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(perplexities, label='Perplexity', linestyle='dashed', marker=\"o\")\n",
    "plt.title('Simple Model - Perplexity over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Perplexity')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T13:50:11.766030Z",
     "iopub.status.busy": "2024-12-11T13:50:11.765419Z",
     "iopub.status.idle": "2024-12-11T13:51:04.573927Z",
     "shell.execute_reply": "2024-12-11T13:51:04.572950Z",
     "shell.execute_reply.started": "2024-12-11T13:50:11.765996Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity of base model: 6.25\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "total_loss = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for x, y in dev_dataloader:\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        logits = model(x)\n",
    "        loss = criterion(logits.view(-1, vocab_size), y.view(-1))\n",
    "        total_loss += loss.item()\n",
    "\n",
    "avg_loss = total_loss / len(dev_dataloader)\n",
    "perplexity_simple = math.exp(avg_loss)\n",
    "print(f\"Perplexity of base model: {perplexity_simple:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2024-12-11T15:44:20.367200Z",
     "iopub.status.busy": "2024-12-11T15:44:20.366870Z",
     "iopub.status.idle": "2024-12-11T15:44:20.450297Z",
     "shell.execute_reply": "2024-12-11T15:44:20.449049Z",
     "shell.execute_reply.started": "2024-12-11T15:44:20.367173Z"
    },
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "tuple indices must be integers or slices, not tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[56], line 20\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m generated_text\n\u001b[1;32m     19\u001b[0m start_text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m من در راه\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 20\u001b[0m generated_text \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_text\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGenerated Text:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(generated_text)\n",
      "Cell \u001b[0;32mIn[56], line 11\u001b[0m, in \u001b[0;36mgenerate_text\u001b[0;34m(model, tokenizer, start_text, context_length, temperature)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m     10\u001b[0m logits \u001b[38;5;241m=\u001b[39m model(context)\n\u001b[0;32m---> 11\u001b[0m next_token_logits \u001b[38;5;241m=\u001b[39m \u001b[43mlogits\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m/\u001b[39m temperature\n\u001b[1;32m     12\u001b[0m probabilities \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msoftmax(next_token_logits, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     13\u001b[0m next_token_id \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmultinomial(probabilities, num_samples\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/utils/generic.py:433\u001b[0m, in \u001b[0;36mModelOutput.__getitem__\u001b[0;34m(self, k)\u001b[0m\n\u001b[1;32m    431\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m inner_dict[k]\n\u001b[1;32m    432\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 433\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_tuple\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: tuple indices must be integers or slices, not tuple"
     ]
    }
   ],
   "source": [
    "def generate_text(model, tokenizer, start_text, context_length=15, temperature=1.0):\n",
    "    model.eval()\n",
    "    generated = tokenizer.encode(start_text)\n",
    "    context = torch.tensor(generated, dtype=torch.long, device=device).unsqueeze(0)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for _ in range(context_length):\n",
    "            if context.size(1) >= context_length:\n",
    "                break\n",
    "            logits = model(context)\n",
    "            next_token_logits = logits[0, -1, :] / temperature\n",
    "            probabilities = torch.softmax(next_token_logits, dim=-1)\n",
    "            next_token_id = torch.multinomial(probabilities, num_samples=1)\n",
    "            context = torch.cat([context, next_token_id.unsqueeze(0)], dim=1)\n",
    "    \n",
    "    generated_text = tokenizer.decode(context[0].tolist())\n",
    "    return generated_text\n",
    "\n",
    "start_text = \" من در راه\"\n",
    "generated_text = generate_text(model, tokenizer, start_text, context_length=20)\n",
    "print(\"Generated Text:\\n\")\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T13:56:42.671833Z",
     "iopub.status.busy": "2024-12-11T13:56:42.671467Z",
     "iopub.status.idle": "2024-12-11T13:56:42.707464Z",
     "shell.execute_reply": "2024-12-11T13:56:42.706673Z",
     "shell.execute_reply.started": "2024-12-11T13:56:42.671798Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class ConvolutionalLanguageModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, context_length, num_heads=4, num_layers=2, dropout=0.2):\n",
    "        super(ConvolutionalLanguageModel, self).__init__()\n",
    "        self.token_embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.position_embedding = nn.Embedding(context_length, embedding_dim)\n",
    "        \n",
    "        # Convolutional block\n",
    "        self.conv1 = nn.Conv1d(in_channels=embedding_dim, out_channels=embedding_dim, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv1d(in_channels=embedding_dim, out_channels=embedding_dim, kernel_size=5, padding=2)\n",
    "        self.batch_norm = nn.BatchNorm1d(embedding_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        # Transformer encoder\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=embedding_dim, \n",
    "            nhead=num_heads, \n",
    "            dim_feedforward=embedding_dim * 4,\n",
    "            dropout=dropout,\n",
    "            batch_first=True,\n",
    "        )\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        \n",
    "        self.layer_norm = nn.LayerNorm(embedding_dim)\n",
    "        self.linear = nn.Linear(embedding_dim, vocab_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        positions = torch.arange(0, x.size(1), device=x.device).unsqueeze(0)\n",
    "        token_embeds = self.token_embedding(x)\n",
    "        position_embeds = self.position_embedding(positions)\n",
    "        \n",
    "        embeddings = token_embeds + position_embeds\n",
    "        embeddings = self.dropout(embeddings)\n",
    "\n",
    "        # Convolutional processing\n",
    "        embeddings = embeddings.transpose(1, 2)  # Convert to [batch_size, embedding_dim, seq_len]\n",
    "        embeddings = self.conv1(embeddings)\n",
    "        embeddings = self.relu(self.batch_norm(embeddings))\n",
    "        embeddings = self.conv2(embeddings)\n",
    "        embeddings = embeddings.transpose(1, 2)  # Convert back to [batch_size, seq_len, embedding_dim]\n",
    "\n",
    "        # Transformer processing\n",
    "        embeddings = self.layer_norm(embeddings)\n",
    "        transformer_output = self.transformer(embeddings)\n",
    "        logits = self.linear(transformer_output)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T15:44:57.354177Z",
     "iopub.status.busy": "2024-12-11T15:44:57.353827Z",
     "iopub.status.idle": "2024-12-11T15:44:57.430443Z",
     "shell.execute_reply": "2024-12-11T15:44:57.429571Z",
     "shell.execute_reply.started": "2024-12-11T15:44:57.354146Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# Parameters\n",
    "batch_size = 128\n",
    "context_length = 32  # Context size for training\n",
    "# vocab_size = tokenizer.n_vocab\n",
    "vocab_size = 30000\n",
    "embedding_dim = 128\n",
    "\n",
    "# Create the DataLoader\n",
    "# train_dataloader, dev_dataloader, test_dataloader = create_dataloader(\n",
    "#     formatted_text[:9999297], batch_size=batch_size, \n",
    "#     context_length=context_length, shuffle=True\n",
    "# )\n",
    "\n",
    "# Initialize the model\n",
    "model = ConvolutionalLanguageModel(vocab_size, embedding_dim, context_length).to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop parameters\n",
    "num_epochs = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2024-12-11T15:45:01.450906Z",
     "iopub.status.busy": "2024-12-11T15:45:01.450104Z",
     "iopub.status.idle": "2024-12-11T15:45:47.939599Z",
     "shell.execute_reply": "2024-12-11T15:45:47.938458Z",
     "shell.execute_reply.started": "2024-12-11T15:45:01.450870Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], Step [0/43387], Loss: 10.2914, Token Logits: torch.Size([4096, 30000]), Token Labels: torch.Size([4096]), y: torch.Size([128, 32]), logits: torch.Size([128, 32, 30000])\n",
      "Epoch [1/1], Step [20/43387], Loss: 3.5169, Token Logits: torch.Size([4096, 30000]), Token Labels: torch.Size([4096]), y: torch.Size([128, 32]), logits: torch.Size([128, 32, 30000])\n",
      "Epoch [1/1], Step [40/43387], Loss: 2.0791, Token Logits: torch.Size([4096, 30000]), Token Labels: torch.Size([4096]), y: torch.Size([128, 32]), logits: torch.Size([128, 32, 30000])\n",
      "Epoch [1/1], Step [60/43387], Loss: 1.8317, Token Logits: torch.Size([4096, 30000]), Token Labels: torch.Size([4096]), y: torch.Size([128, 32]), logits: torch.Size([128, 32, 30000])\n",
      "Epoch [1/1], Step [80/43387], Loss: 1.6235, Token Logits: torch.Size([4096, 30000]), Token Labels: torch.Size([4096]), y: torch.Size([128, 32]), logits: torch.Size([128, 32, 30000])\n",
      "Epoch [1/1], Step [100/43387], Loss: 1.3843, Token Logits: torch.Size([4096, 30000]), Token Labels: torch.Size([4096]), y: torch.Size([128, 32]), logits: torch.Size([128, 32, 30000])\n",
      "Epoch [1/1], Step [120/43387], Loss: 1.1859, Token Logits: torch.Size([4096, 30000]), Token Labels: torch.Size([4096]), y: torch.Size([128, 32]), logits: torch.Size([128, 32, 30000])\n",
      "Epoch [1/1], Step [140/43387], Loss: 1.0123, Token Logits: torch.Size([4096, 30000]), Token Labels: torch.Size([4096]), y: torch.Size([128, 32]), logits: torch.Size([128, 32, 30000])\n",
      "Epoch [1/1], Step [160/43387], Loss: 0.9671, Token Logits: torch.Size([4096, 30000]), Token Labels: torch.Size([4096]), y: torch.Size([128, 32]), logits: torch.Size([128, 32, 30000])\n",
      "Epoch [1/1], Step [180/43387], Loss: 0.7730, Token Logits: torch.Size([4096, 30000]), Token Labels: torch.Size([4096]), y: torch.Size([128, 32]), logits: torch.Size([128, 32, 30000])\n",
      "Epoch [1/1], Step [200/43387], Loss: 0.7273, Token Logits: torch.Size([4096, 30000]), Token Labels: torch.Size([4096]), y: torch.Size([128, 32]), logits: torch.Size([128, 32, 30000])\n",
      "Epoch [1/1], Step [220/43387], Loss: 0.6005, Token Logits: torch.Size([4096, 30000]), Token Labels: torch.Size([4096]), y: torch.Size([128, 32]), logits: torch.Size([128, 32, 30000])\n",
      "Epoch [1/1], Step [240/43387], Loss: 0.5760, Token Logits: torch.Size([4096, 30000]), Token Labels: torch.Size([4096]), y: torch.Size([128, 32]), logits: torch.Size([128, 32, 30000])\n",
      "Epoch [1/1], Step [260/43387], Loss: 0.5046, Token Logits: torch.Size([4096, 30000]), Token Labels: torch.Size([4096]), y: torch.Size([128, 32]), logits: torch.Size([128, 32, 30000])\n",
      "Epoch [1/1], Step [280/43387], Loss: 0.4228, Token Logits: torch.Size([4096, 30000]), Token Labels: torch.Size([4096]), y: torch.Size([128, 32]), logits: torch.Size([128, 32, 30000])\n",
      "Epoch [1/1], Step [300/43387], Loss: 0.3972, Token Logits: torch.Size([4096, 30000]), Token Labels: torch.Size([4096]), y: torch.Size([128, 32]), logits: torch.Size([128, 32, 30000])\n",
      "Epoch [1/1], Step [320/43387], Loss: 0.3279, Token Logits: torch.Size([4096, 30000]), Token Labels: torch.Size([4096]), y: torch.Size([128, 32]), logits: torch.Size([128, 32, 30000])\n",
      "Epoch [1/1], Step [340/43387], Loss: 0.3430, Token Logits: torch.Size([4096, 30000]), Token Labels: torch.Size([4096]), y: torch.Size([128, 32]), logits: torch.Size([128, 32, 30000])\n",
      "Epoch [1/1], Step [360/43387], Loss: 0.2715, Token Logits: torch.Size([4096, 30000]), Token Labels: torch.Size([4096]), y: torch.Size([128, 32]), logits: torch.Size([128, 32, 30000])\n",
      "Epoch [1/1], Step [380/43387], Loss: 0.2643, Token Logits: torch.Size([4096, 30000]), Token Labels: torch.Size([4096]), y: torch.Size([128, 32]), logits: torch.Size([128, 32, 30000])\n",
      "Epoch [1/1], Step [400/43387], Loss: 0.2357, Token Logits: torch.Size([4096, 30000]), Token Labels: torch.Size([4096]), y: torch.Size([128, 32]), logits: torch.Size([128, 32, 30000])\n",
      "Epoch [1/1], Step [420/43387], Loss: 0.2350, Token Logits: torch.Size([4096, 30000]), Token Labels: torch.Size([4096]), y: torch.Size([128, 32]), logits: torch.Size([128, 32, 30000])\n",
      "Epoch [1/1], Step [440/43387], Loss: 0.2287, Token Logits: torch.Size([4096, 30000]), Token Labels: torch.Size([4096]), y: torch.Size([128, 32]), logits: torch.Size([128, 32, 30000])\n",
      "Epoch [1/1], Step [460/43387], Loss: 0.2044, Token Logits: torch.Size([4096, 30000]), Token Labels: torch.Size([4096]), y: torch.Size([128, 32]), logits: torch.Size([128, 32, 30000])\n",
      "Epoch [1/1], Step [480/43387], Loss: 0.1997, Token Logits: torch.Size([4096, 30000]), Token Labels: torch.Size([4096]), y: torch.Size([128, 32]), logits: torch.Size([128, 32, 30000])\n",
      "Epoch [1/1], Step [500/43387], Loss: 0.1399, Token Logits: torch.Size([4096, 30000]), Token Labels: torch.Size([4096]), y: torch.Size([128, 32]), logits: torch.Size([128, 32, 30000])\n",
      "Epoch [1/1], Step [520/43387], Loss: 0.1642, Token Logits: torch.Size([4096, 30000]), Token Labels: torch.Size([4096]), y: torch.Size([128, 32]), logits: torch.Size([128, 32, 30000])\n",
      "Epoch [1/1], Step [540/43387], Loss: 0.1377, Token Logits: torch.Size([4096, 30000]), Token Labels: torch.Size([4096]), y: torch.Size([128, 32]), logits: torch.Size([128, 32, 30000])\n",
      "Epoch [1/1], Step [560/43387], Loss: 0.1476, Token Logits: torch.Size([4096, 30000]), Token Labels: torch.Size([4096]), y: torch.Size([128, 32]), logits: torch.Size([128, 32, 30000])\n",
      "Epoch [1/1], Step [580/43387], Loss: 0.1566, Token Logits: torch.Size([4096, 30000]), Token Labels: torch.Size([4096]), y: torch.Size([128, 32]), logits: torch.Size([128, 32, 30000])\n",
      "Epoch [1/1], Step [600/43387], Loss: 0.1430, Token Logits: torch.Size([4096, 30000]), Token Labels: torch.Size([4096]), y: torch.Size([128, 32]), logits: torch.Size([128, 32, 30000])\n",
      "Epoch [1/1], Step [620/43387], Loss: 0.1016, Token Logits: torch.Size([4096, 30000]), Token Labels: torch.Size([4096]), y: torch.Size([128, 32]), logits: torch.Size([128, 32, 30000])\n",
      "Epoch [1/1], Step [640/43387], Loss: 0.1158, Token Logits: torch.Size([4096, 30000]), Token Labels: torch.Size([4096]), y: torch.Size([128, 32]), logits: torch.Size([128, 32, 30000])\n",
      "Epoch [1/1], Step [660/43387], Loss: 0.0979, Token Logits: torch.Size([4096, 30000]), Token Labels: torch.Size([4096]), y: torch.Size([128, 32]), logits: torch.Size([128, 32, 30000])\n",
      "Epoch [1/1], Step [680/43387], Loss: 0.1016, Token Logits: torch.Size([4096, 30000]), Token Labels: torch.Size([4096]), y: torch.Size([128, 32]), logits: torch.Size([128, 32, 30000])\n",
      "Epoch [1/1], Step [700/43387], Loss: 0.1023, Token Logits: torch.Size([4096, 30000]), Token Labels: torch.Size([4096]), y: torch.Size([128, 32]), logits: torch.Size([128, 32, 30000])\n",
      "Epoch [1/1], Step [720/43387], Loss: 0.1152, Token Logits: torch.Size([4096, 30000]), Token Labels: torch.Size([4096]), y: torch.Size([128, 32]), logits: torch.Size([128, 32, 30000])\n",
      "Epoch [1/1], Step [740/43387], Loss: 0.0887, Token Logits: torch.Size([4096, 30000]), Token Labels: torch.Size([4096]), y: torch.Size([128, 32]), logits: torch.Size([128, 32, 30000])\n",
      "Epoch [1/1], Step [760/43387], Loss: 0.0798, Token Logits: torch.Size([4096, 30000]), Token Labels: torch.Size([4096]), y: torch.Size([128, 32]), logits: torch.Size([128, 32, 30000])\n",
      "Epoch [1/1], Step [780/43387], Loss: 0.1128, Token Logits: torch.Size([4096, 30000]), Token Labels: torch.Size([4096]), y: torch.Size([128, 32]), logits: torch.Size([128, 32, 30000])\n",
      "Epoch [1/1], Step [800/43387], Loss: 0.0945, Token Logits: torch.Size([4096, 30000]), Token Labels: torch.Size([4096]), y: torch.Size([128, 32]), logits: torch.Size([128, 32, 30000])\n",
      "Epoch [1/1], Step [820/43387], Loss: 0.0966, Token Logits: torch.Size([4096, 30000]), Token Labels: torch.Size([4096]), y: torch.Size([128, 32]), logits: torch.Size([128, 32, 30000])\n",
      "Epoch [1/1], Step [840/43387], Loss: 0.0787, Token Logits: torch.Size([4096, 30000]), Token Labels: torch.Size([4096]), y: torch.Size([128, 32]), logits: torch.Size([128, 32, 30000])\n",
      "Epoch [1/1], Step [860/43387], Loss: 0.0697, Token Logits: torch.Size([4096, 30000]), Token Labels: torch.Size([4096]), y: torch.Size([128, 32]), logits: torch.Size([128, 32, 30000])\n",
      "Epoch [1/1], Step [880/43387], Loss: 0.0880, Token Logits: torch.Size([4096, 30000]), Token Labels: torch.Size([4096]), y: torch.Size([128, 32]), logits: torch.Size([128, 32, 30000])\n",
      "Epoch [1/1], Step [900/43387], Loss: 0.0640, Token Logits: torch.Size([4096, 30000]), Token Labels: torch.Size([4096]), y: torch.Size([128, 32]), logits: torch.Size([128, 32, 30000])\n",
      "Epoch [1/1], Step [920/43387], Loss: 0.0582, Token Logits: torch.Size([4096, 30000]), Token Labels: torch.Size([4096]), y: torch.Size([128, 32]), logits: torch.Size([128, 32, 30000])\n",
      "Epoch [1/1], Step [940/43387], Loss: 0.0950, Token Logits: torch.Size([4096, 30000]), Token Labels: torch.Size([4096]), y: torch.Size([128, 32]), logits: torch.Size([128, 32, 30000])\n",
      "Epoch [1/1], Step [960/43387], Loss: 0.0736, Token Logits: torch.Size([4096, 30000]), Token Labels: torch.Size([4096]), y: torch.Size([128, 32]), logits: torch.Size([128, 32, 30000])\n",
      "Epoch [1/1], Step [980/43387], Loss: 0.0824, Token Logits: torch.Size([4096, 30000]), Token Labels: torch.Size([4096]), y: torch.Size([128, 32]), logits: torch.Size([128, 32, 30000])\n",
      "Epoch [1/1], Step [1000/43387], Loss: 0.0771, Token Logits: torch.Size([4096, 30000]), Token Labels: torch.Size([4096]), y: torch.Size([128, 32]), logits: torch.Size([128, 32, 30000])\n",
      "Epoch [1/1], Step [1020/43387], Loss: 0.0829, Token Logits: torch.Size([4096, 30000]), Token Labels: torch.Size([4096]), y: torch.Size([128, 32]), logits: torch.Size([128, 32, 30000])\n",
      "Epoch [1/1], Step [1040/43387], Loss: 0.0683, Token Logits: torch.Size([4096, 30000]), Token Labels: torch.Size([4096]), y: torch.Size([128, 32]), logits: torch.Size([128, 32, 30000])\n",
      "Epoch [1/1], Step [1060/43387], Loss: 0.0921, Token Logits: torch.Size([4096, 30000]), Token Labels: torch.Size([4096]), y: torch.Size([128, 32]), logits: torch.Size([128, 32, 30000])\n",
      "Epoch [1/1], Step [1080/43387], Loss: 0.0733, Token Logits: torch.Size([4096, 30000]), Token Labels: torch.Size([4096]), y: torch.Size([128, 32]), logits: torch.Size([128, 32, 30000])\n",
      "Epoch [1/1], Step [1100/43387], Loss: 0.0789, Token Logits: torch.Size([4096, 30000]), Token Labels: torch.Size([4096]), y: torch.Size([128, 32]), logits: torch.Size([128, 32, 30000])\n",
      "Epoch [1/1], Step [1120/43387], Loss: 0.0704, Token Logits: torch.Size([4096, 30000]), Token Labels: torch.Size([4096]), y: torch.Size([128, 32]), logits: torch.Size([128, 32, 30000])\n",
      "Epoch [1/1], Step [1140/43387], Loss: 0.0769, Token Logits: torch.Size([4096, 30000]), Token Labels: torch.Size([4096]), y: torch.Size([128, 32]), logits: torch.Size([128, 32, 30000])\n",
      "Epoch [1/1], Step [1160/43387], Loss: 0.0609, Token Logits: torch.Size([4096, 30000]), Token Labels: torch.Size([4096]), y: torch.Size([128, 32]), logits: torch.Size([128, 32, 30000])\n",
      "Epoch [1/1], Step [1180/43387], Loss: 0.0627, Token Logits: torch.Size([4096, 30000]), Token Labels: torch.Size([4096]), y: torch.Size([128, 32]), logits: torch.Size([128, 32, 30000])\n",
      "Epoch [1/1], Step [1200/43387], Loss: 0.0682, Token Logits: torch.Size([4096, 30000]), Token Labels: torch.Size([4096]), y: torch.Size([128, 32]), logits: torch.Size([128, 32, 30000])\n",
      "Epoch [1/1], Step [1220/43387], Loss: 0.0748, Token Logits: torch.Size([4096, 30000]), Token Labels: torch.Size([4096]), y: torch.Size([128, 32]), logits: torch.Size([128, 32, 30000])\n",
      "Epoch [1/1], Step [1240/43387], Loss: 0.0570, Token Logits: torch.Size([4096, 30000]), Token Labels: torch.Size([4096]), y: torch.Size([128, 32]), logits: torch.Size([128, 32, 30000])\n",
      "Epoch [1/1], Step [1260/43387], Loss: 0.0646, Token Logits: torch.Size([4096, 30000]), Token Labels: torch.Size([4096]), y: torch.Size([128, 32]), logits: torch.Size([128, 32, 30000])\n",
      "Epoch [1/1], Step [1280/43387], Loss: 0.0541, Token Logits: torch.Size([4096, 30000]), Token Labels: torch.Size([4096]), y: torch.Size([128, 32]), logits: torch.Size([128, 32, 30000])\n",
      "Epoch [1/1], Step [1300/43387], Loss: 0.0700, Token Logits: torch.Size([4096, 30000]), Token Labels: torch.Size([4096]), y: torch.Size([128, 32]), logits: torch.Size([128, 32, 30000])\n",
      "Epoch [1/1], Step [1320/43387], Loss: 0.0468, Token Logits: torch.Size([4096, 30000]), Token Labels: torch.Size([4096]), y: torch.Size([128, 32]), logits: torch.Size([128, 32, 30000])\n",
      "Epoch [1/1], Step [1340/43387], Loss: 0.0753, Token Logits: torch.Size([4096, 30000]), Token Labels: torch.Size([4096]), y: torch.Size([128, 32]), logits: torch.Size([128, 32, 30000])\n",
      "Epoch [1/1], Step [1360/43387], Loss: 0.0574, Token Logits: torch.Size([4096, 30000]), Token Labels: torch.Size([4096]), y: torch.Size([128, 32]), logits: torch.Size([128, 32, 30000])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[58], line 44\u001b[0m\n\u001b[1;32m     41\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# Accumulate the loss over batches\u001b[39;00m\n\u001b[0;32m---> 44\u001b[0m total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;66;03m# Monitor progress every twenty batches\u001b[39;00m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_idx \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m20\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "num_epochs = 1\n",
    "train_losses = []\n",
    "perplexities = []\n",
    "\n",
    "# Go through learning epochs\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    model.train()\n",
    "    \n",
    "    # Read in data in batches\n",
    "    for batch_idx, (x, y) in enumerate(train_dataloader):\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        # Reset the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Apply the forward pass\n",
    "        logits = model(x)\n",
    "\n",
    "        # Reshape logits and labels\n",
    "        token_logits = logits.view(-1, vocab_size)\n",
    "        token_labels = y.view(-1)\n",
    "\n",
    "        # To understand what is happening during reshaping, print out logits.shape and token_logits.shape\n",
    "        # and the same for y\n",
    "        # print(logits.shape, token_logits.shape)\n",
    "        # print(y.shape, token_labels.shape)\n",
    "        # print(y[0])\n",
    "        # print(token_labels[0:10])\n",
    "\n",
    "        # Calculate the loss\n",
    "        loss = criterion(token_logits,token_labels)\n",
    "\n",
    "        # Apply the backward step (calculate the gradients) \n",
    "        loss.backward()\n",
    "\n",
    "        # Adjust the weights\n",
    "        optimizer.step()\n",
    "\n",
    "        # Accumulate the loss over batches\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Monitor progress every twenty batches\n",
    "        if batch_idx % 20 == 0:\n",
    "            print(f\"Epoch [{epoch+1}/{num_epochs}], Step [{batch_idx}/{len(train_dataloader)}], Loss: {loss.item():.4f}, Token Logits: {token_logits.shape}, Token Labels: {token_labels.shape}, y: {y.shape}, logits: {logits.shape}\")\n",
    "\n",
    "    # Calculate average cross-entropy loss and perplexity\n",
    "    avg_loss = total_loss / len(train_dataloader)\n",
    "    perplexity = math.exp(avg_loss)\n",
    "    \n",
    "    # Monitor developments over learning process\n",
    "    train_losses.append(avg_loss)\n",
    "    perplexities.append(perplexity)\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}] Average Loss: {avg_loss:.4f}, Perplexity: {perplexity:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T15:45:54.097637Z",
     "iopub.status.busy": "2024-12-11T15:45:54.096801Z",
     "iopub.status.idle": "2024-12-11T15:46:57.323511Z",
     "shell.execute_reply": "2024-12-11T15:46:57.322527Z",
     "shell.execute_reply.started": "2024-12-11T15:45:54.097600Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity of base model: 1.06\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "total_loss = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for x, y in dev_dataloader:\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        logits = model(x)\n",
    "        loss = criterion(logits.view(-1, vocab_size), y.view(-1))\n",
    "        total_loss += loss.item()\n",
    "\n",
    "avg_loss = total_loss / len(dev_dataloader)\n",
    "perplexity_simple = math.exp(avg_loss)\n",
    "print(f\"Perplexity of base model: {perplexity_simple:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T15:48:52.819419Z",
     "iopub.status.busy": "2024-12-11T15:48:52.818548Z",
     "iopub.status.idle": "2024-12-11T15:48:52.884789Z",
     "shell.execute_reply": "2024-12-11T15:48:52.883916Z",
     "shell.execute_reply.started": "2024-12-11T15:48:52.819380Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "next_token_logits: tensor([ 4.3275, -5.4783, -7.5729,  ..., -6.8719, -5.1250, -6.9073],\n",
      "       device='cuda:0'), probabilities: tensor([1.2609e-03, 6.9508e-08, 8.5581e-09,  ..., 1.7252e-08, 9.8970e-08,\n",
      "        1.6651e-08], device='cuda:0'), next_token_id: tensor([24943], device='cuda:0'), context: tensor([[    5,    78,    46,   167,     3, 24943]], device='cuda:0')\n",
      "next_token_logits: tensor([ 3.1330, -5.4079, -6.6491,  ..., -7.7862, -4.7720, -6.5186],\n",
      "       device='cuda:0'), probabilities: tensor([1.6268e-04, 3.1775e-08, 9.1840e-09,  ..., 2.9458e-09, 6.0012e-08,\n",
      "        1.0464e-08], device='cuda:0'), next_token_id: tensor([43], device='cuda:0'), context: tensor([[    5,    78,    46,   167,     3, 24943,    43]], device='cuda:0')\n",
      "next_token_logits: tensor([ 0.1055, -4.6321, -5.2862,  ..., -5.6402, -2.8663, -4.8546],\n",
      "       device='cuda:0'), probabilities: tensor([2.8401e-07, 2.4878e-09, 1.2935e-09,  ..., 9.0783e-10, 1.4545e-08,\n",
      "        1.9915e-09], device='cuda:0'), next_token_id: tensor([24940], device='cuda:0'), context: tensor([[    5,    78,    46,   167,     3, 24943,    43, 24940]],\n",
      "       device='cuda:0')\n",
      "next_token_logits: tensor([ 3.3240, -5.2526, -8.3216,  ..., -6.6782, -5.1706, -7.1684],\n",
      "       device='cuda:0'), probabilities: tensor([4.9648e-06, 9.3570e-10, 4.3481e-11,  ..., 2.2491e-10, 1.0157e-09,\n",
      "        1.3777e-10], device='cuda:0'), next_token_id: tensor([24941], device='cuda:0'), context: tensor([[    5,    78,    46,   167,     3, 24943,    43, 24940, 24941]],\n",
      "       device='cuda:0')\n",
      "next_token_logits: tensor([-2.8222, -6.6183, -7.3264,  ..., -7.6336, -5.5160, -6.5274],\n",
      "       device='cuda:0'), probabilities: tensor([4.7043e-06, 1.0565e-07, 5.2041e-08,  ..., 3.8275e-08, 3.1813e-07,\n",
      "        1.1570e-07], device='cuda:0'), next_token_id: tensor([2072], device='cuda:0'), context: tensor([[    5,    78,    46,   167,     3, 24943,    43, 24940, 24941,  2072]],\n",
      "       device='cuda:0')\n",
      "next_token_logits: tensor([ 0.0626, -5.3548, -7.3845,  ..., -6.7888, -5.7764, -6.7187],\n",
      "       device='cuda:0'), probabilities: tensor([6.5214e-05, 2.8945e-07, 3.8029e-08,  ..., 6.8992e-08, 1.8988e-07,\n",
      "        7.4000e-08], device='cuda:0'), next_token_id: tensor([24941], device='cuda:0'), context: tensor([[    5,    78,    46,   167,     3, 24943,    43, 24940, 24941,  2072,\n",
      "         24941]], device='cuda:0')\n",
      "next_token_logits: tensor([-1.9916, -4.4655, -6.7230,  ..., -5.9018, -3.5018, -5.3119],\n",
      "       device='cuda:0'), probabilities: tensor([1.7535e-08, 1.4774e-09, 1.5455e-10,  ..., 3.5134e-10, 3.8728e-09,\n",
      "        6.3377e-10], device='cuda:0'), next_token_id: tensor([24980], device='cuda:0'), context: tensor([[    5,    78,    46,   167,     3, 24943,    43, 24940, 24941,  2072,\n",
      "         24941, 24980]], device='cuda:0')\n",
      "next_token_logits: tensor([ 0.4979, -4.8970, -5.7556,  ..., -6.7394, -5.3779, -6.2984],\n",
      "       device='cuda:0'), probabilities: tensor([1.5072e-07, 6.8417e-10, 2.8992e-10,  ..., 1.0841e-10, 4.2299e-10,\n",
      "        1.6848e-10], device='cuda:0'), next_token_id: tensor([43], device='cuda:0'), context: tensor([[    5,    78,    46,   167,     3, 24943,    43, 24940, 24941,  2072,\n",
      "         24941, 24980,    43]], device='cuda:0')\n",
      "next_token_logits: tensor([ 3.0569, -4.8404, -8.5381,  ..., -6.1974, -5.2147, -7.2286],\n",
      "       device='cuda:0'), probabilities: tensor([1.9696e-06, 7.3216e-10, 1.8145e-11,  ..., 1.8849e-10, 5.0360e-10,\n",
      "        6.7211e-11], device='cuda:0'), next_token_id: tensor([24941], device='cuda:0'), context: tensor([[    5,    78,    46,   167,     3, 24943,    43, 24940, 24941,  2072,\n",
      "         24941, 24980,    43, 24941]], device='cuda:0')\n",
      "next_token_logits: tensor([-1.4949, -6.2812, -7.3413,  ..., -6.9811, -5.4213, -6.6031],\n",
      "       device='cuda:0'), probabilities: tensor([2.0982e-05, 1.7506e-07, 6.0643e-08,  ..., 8.6937e-08, 4.1364e-07,\n",
      "        1.2687e-07], device='cuda:0'), next_token_id: tensor([15706], device='cuda:0'), context: tensor([[    5,    78,    46,   167,     3, 24943,    43, 24940, 24941,  2072,\n",
      "         24941, 24980,    43, 24941, 15706]], device='cuda:0')\n",
      "next_token_logits: tensor([ 1.1932, -6.0818, -7.9121,  ..., -7.4337, -6.4437, -6.7658],\n",
      "       device='cuda:0'), probabilities: tensor([4.0914e-04, 2.8338e-07, 4.5447e-08,  ..., 7.3331e-08, 1.9734e-07,\n",
      "        1.4299e-07], device='cuda:0'), next_token_id: tensor([3180], device='cuda:0'), context: tensor([[    5,    78,    46,   167,     3, 24943,    43, 24940, 24941,  2072,\n",
      "         24941, 24980,    43, 24941, 15706,  3180]], device='cuda:0')\n",
      "next_token_logits: tensor([ 3.8506, -5.9499, -7.6331,  ..., -7.4360, -5.7900, -7.3472],\n",
      "       device='cuda:0'), probabilities: tensor([2.9028e-03, 1.6087e-07, 2.9886e-08,  ..., 3.6399e-08, 1.8877e-07,\n",
      "        3.9780e-08], device='cuda:0'), next_token_id: tensor([505], device='cuda:0'), context: tensor([[    5,    78,    46,   167,     3, 24943,    43, 24940, 24941,  2072,\n",
      "         24941, 24980,    43, 24941, 15706,  3180,   505]], device='cuda:0')\n",
      "next_token_logits: tensor([ 2.5004, -5.2977, -7.9402,  ..., -7.8604, -5.9039, -6.9548],\n",
      "       device='cuda:0'), probabilities: tensor([9.4182e-05, 3.8662e-08, 2.7523e-09,  ..., 2.9807e-09, 2.1089e-08,\n",
      "        7.3730e-09], device='cuda:0'), next_token_id: tensor([24941], device='cuda:0'), context: tensor([[    5,    78,    46,   167,     3, 24943,    43, 24940, 24941,  2072,\n",
      "         24941, 24980,    43, 24941, 15706,  3180,   505, 24941]],\n",
      "       device='cuda:0')\n",
      "next_token_logits: tensor([-0.4718, -4.3377, -6.5978,  ..., -5.9653, -3.3261, -5.5735],\n",
      "       device='cuda:0'), probabilities: tensor([6.3923e-08, 1.3387e-09, 1.3969e-10,  ..., 2.6293e-10, 3.6816e-09,\n",
      "        3.8905e-10], device='cuda:0'), next_token_id: tensor([24980], device='cuda:0'), context: tensor([[    5,    78,    46,   167,     3, 24943,    43, 24940, 24941,  2072,\n",
      "         24941, 24980,    43, 24941, 15706,  3180,   505, 24941, 24980]],\n",
      "       device='cuda:0')\n",
      "next_token_logits: tensor([ 0.2137, -5.1247, -5.6140,  ..., -6.8269, -5.2022, -6.0652],\n",
      "       device='cuda:0'), probabilities: tensor([5.2827e-08, 2.5374e-10, 1.5556e-10,  ..., 4.6255e-11, 2.3483e-10,\n",
      "        9.9071e-11], device='cuda:0'), next_token_id: tensor([43], device='cuda:0'), context: tensor([[    5,    78,    46,   167,     3, 24943,    43, 24940, 24941,  2072,\n",
      "         24941, 24980,    43, 24941, 15706,  3180,   505, 24941, 24980,    43]],\n",
      "       device='cuda:0')\n",
      "Generated Text:\n",
      "\n",
      "[CLS] من در راه[SEP]5 ['این', 'هستندفیکه', \n"
     ]
    }
   ],
   "source": [
    "def generate_text(model, tokenizer, start_text, context_length=15, temperature=1.0):\n",
    "    model.eval()\n",
    "    generated = tokenizer.encode(start_text)\n",
    "    context = torch.tensor(generated, dtype=torch.long, device=device).unsqueeze(0)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for _ in range(context_length):\n",
    "            if context.size(1) >= context_length:\n",
    "                break\n",
    "            logits = model(context)\n",
    "            next_token_logits = logits[0, -1, :] / temperature\n",
    "            probabilities = torch.softmax(next_token_logits, dim=-1)\n",
    "            next_token_id = torch.multinomial(probabilities, num_samples=1)\n",
    "            context = torch.cat([context, next_token_id.unsqueeze(0)], dim=1)\n",
    "            print(f\"next_token_logits: {next_token_logits}, probabilities: {probabilities}, next_token_id: {next_token_id}, context: {context}\")\n",
    "\n",
    "    \n",
    "    generated_text = tokenizer.decode(context[0].tolist())\n",
    "    return generated_text\n",
    "\n",
    "start_text = \" من در راه\"\n",
    "generated_text = generate_text(model, tokenizer, start_text, context_length=20)\n",
    "print(\"Generated Text:\\n\")\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T15:52:01.938635Z",
     "iopub.status.busy": "2024-12-11T15:52:01.938279Z",
     "iopub.status.idle": "2024-12-11T15:52:01.944229Z",
     "shell.execute_reply": "2024-12-11T15:52:01.943290Z",
     "shell.execute_reply.started": "2024-12-11T15:52:01.938603Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'دنبال'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(503)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# from transformers import pipeline, AutoTokenizer, GPT2LMHeadModel\n",
    "tokenizer = AutoTokenizer.from_pretrained('bolbolzaban/gpt2-persian')\n",
    "model = GPT2LMHeadModel.from_pretrained('bolbolzaban/gpt2-persian')\n",
    "generator = pipeline('text-generation', model, tokenizer=tokenizer, config={'max_length':512}, device='cuda')\n",
    "sample = generator('در یک اتفاق شگفت انگیز، پژوهشگران')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T15:14:19.190835Z",
     "iopub.status.busy": "2024-12-11T15:14:19.190486Z",
     "iopub.status.idle": "2024-12-11T15:14:19.557289Z",
     "shell.execute_reply": "2024-12-11T15:14:19.556416Z",
     "shell.execute_reply.started": "2024-12-11T15:14:19.190803Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'رئیس دانشگاه اعلام کرد به گزارش خبرنگار گروه استان\\u200cهای باشگاه خبرنگاران جوان از یزد ؛ اوقات شرعی امروز یزد به شرح زیر است :'}]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generator('رئیس دانشگاه اعلام کرد')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 30805,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
